Authors,Article Title,Source Title,DOI,Publication Year,Abstract,selection,notes,背景/动机,目的/研究问题,结果,前人的相关工作,预测方式,软件度量/特征,度量/特征选择方法,度量/特征处理方法,是否有报告称软件故障预测的指标显著优于其他指标,数据集,数据集大小,数据集是否公开,数据集所处的开发阶段,数据集编程语言,建模技术,预测粒度,因变量,性能评估,论文评价
"Cotroneo, Domenico; Natella, Roberto; Pietrantuono, Roberto",Predicting aging-related bugs using software complexity metrics,PERFORMANCE EVALUATION,10.1016/j.peva.2012.09.004,2013,"Long-running software systems tend to show degraded performance and an increased failure occurrence rate. This problem, known as Software Aging, which is typically related to the runtime accumulation of error conditions, is caused by the activation of the so-called Aging-Related Bugs (ARBs). This paper aims to predict the location of Aging-Related Bugs in complex software systems, so as to aid their identification during testing. First, we carried out a bug data analysis on three large software projects in order to collect data about ARBs. Then, a set of software complexity metrics were selected and extracted from the three projects. Finally, by using such metrics as predictor variables and machine learning algorithms, we built fault prediction models that can be used to predict which source code files are more prone to Aging-Related Bugs. (c) 2012 Elsevier B.V. All rights reserved.",3,本文旨在预测复杂软件系统中老化相关bug的位置，以便在测试过程中进行识别。首先，我们对三个大型软件项目进行bug数据分析，收集arb数据。然后，从三个项目中选择并提取一组软件复杂性度量。,软件老化是发生在长时间运行的软件系统中的一种现象，随着运行时的增加，其故障率也会增加。这种现象通常与执行过程中错误的累积有关，这会导致资源逐渐耗尽、性能下降，并最终导致系统挂起或崩溃。,与衰老相关的bug (ARBs)，为了研究复杂性度量和arb之间的关系,当采用对数变换的朴素贝叶斯分类器时，可以有效地预测出arb倾向文件(达到较高的arb检测率和较低的误报率)。此外，我们发现在本研究中特别提出的复杂性度量(老化相关度量)有助于实现所有软件项目的良好性能。,,"跨版本
","Program size大小度量
McCabe’s cyclomatic complexity
Halstead metrics
Aging-Related Metrics",这些指标提供了对软件复杂性的粗略估计，它们已被用作易出错模块的简单预测器[33]。此外，我们还考虑了其他众所周知的指标，即McCabe的圈复杂度和Halstead指标[42]。这些指标分别基于代码中路径的数量以及操作数和操作符的数量。我们假设这些指标与arb有关，因为错误传播的复杂性(这是arb的显著特征[4])可能是由于程序的复杂结构。最后，我们引入一组与内存使用相关的指标(老化相关指标，arm)，我们假设这些指标与老化相关，因为大多数arb都与内存管理和数据结构处理相关(另见),,"因为分类性能会受到模型中包含的软件复杂性度量的选择的影响 信息增益属性排序算法
可以观察到，没有一个单独的指标可以单独用于分类，但是当考虑多个指标并让分类器确定如何组合这些指标时，可以获得最佳性能。
而且AllocOps指标本身不足以识别有arb倾向的文件，但是为了获得良好的性能，它必须与非老化相关的指标结合起来。总之，由于ARMs（Aging-Related Metrics (ARMs)）在所有三个项目中都改进了ARB预测(每种情况下都减少了PF，而在CARDAMOM中增加了PD)，因此这些指标可以被认为是预测这类bug的有用支持，应该尽可能采用。","Linux 13.2MLOC 30039 files
MySQL 1.5M LOC 2272 files
CARDAMOM 847K 4185",大,公开,完成,"C
C/C++
C++","朴素贝叶斯
贝叶斯网络
决策树
逻辑回归 ",文件级或者说模块级,故障倾向,"Probability of Detection (PD).
Probability of False alarms (PF)
Balance (Bal)
93.56 35.90 73.25",
"Calikli, Gul; Bener, Ayse Basar",Influence of confirmation biases of developers on software quality: an empirical study,SOFTWARE QUALITY JOURNAL,10.1007/s11219-012-9180-0,2013,"The thought processes of people have a significant impact on software quality, as software is designed, developed and tested by people. Cognitive biases, which are defined as patterned deviations of human thought from the laws of logic and mathematics, are a likely cause of software defects. However, there is little empirical evidence to date to substantiate this assertion. In this research, we focus on a specific cognitive bias, confirmation bias, which is defined as the tendency of people to seek evidence that verifies a hypothesis rather than seeking evidence to falsify a hypothesis. Due to this confirmation bias, developers tend to perform unit tests to make their program work rather than to break their code. Therefore, confirmation bias is believed to be one of the factors that lead to an increased software defect density. In this research, we present a metric scheme that explores the impact of developers' confirmation bias on software defect density. In order to estimate the effectiveness of our metric scheme in the quantification of confirmation bias within the context of software development, we performed an empirical study that addressed the prediction of the defective parts of software. In our empirical study, we used confirmation bias metrics on five datasets obtained from two companies. Our results provide empirical evidence that human thought processes and cognitive aspects deserve further investigation to improve decision making in software development for effective process management and resource allocation.",3,在这项研究中，我们提出了一个度量方案来探索开发人员确认偏差对软件缺陷密度的影响。,由于软件是由人开发和测试的，人们的思维过程可能对软件缺陷密度有重要的影响。因此，考虑到人们的思维过程的信息，在缺陷预测性能方面取得进一步的进展是非常可能的,"我们如何识别与软件开发过程相关的确认偏差的度量?
在预测软件中容易出现缺陷的部分时，确认偏差的度量是如何执行的?
探索认知偏差在软件开发和测试中的影响，
本研究的第一个目标是确定与软件开发过程相关的确认偏差的度量。我们准备了一个确认偏差测试，包括一个互动问题和一个书面问题集
本文的第二个目标是研究这些度量在预测软件中容易出现缺陷的部分时的表现。","我们获得的缺陷预测结果与仅从流失度量和仅从静态代码属性分别学习的缺陷预测器获得的结果一样好。
从长远来看，这项研究的目标是通过考虑与人的思维过程相关的度量来帮助软件开发经理做出具体的资源分配决策。这样的度量方案将帮助管理人员确定测试软件缺陷部分的合适人选。因此，与人的思维过程相关的度量标准的指导可以在很大程度上减少人力资源(HR)相关决策的不确定性。",在认知心理学中，确认偏误被定义为人们倾向于寻找能够证实其假设的证据，而不是寻找能够证伪其假设的证据。确认偏差一词最早由Peter watson在他的规则发现实验[44]中使用，后来在他的选择任务实验[45]中使用。,"跨版本
对于每个数据集，我们分别将确认偏差指标的预测性能与静态代码指标和流失指标的预测性能以及这三种指标类型的所有组合进行比较。","static：mccabe's、LOC metrics、Halstead Metrics
churn 改变指标
confirmation bias metrics确认偏差指标",,确认偏差度量套件中的度量分别从交互式问题和书面问题集中提取。,我们的实证结果表明，人们的思维过程对软件的缺陷倾向有重要的影响，因为使用确认偏差度量建立的缺陷预测模型在所有数据集中给出了与其他度量集一样好的结果,使用了来自两个行业合作伙伴的五个数据集，它们分别来自电信和ERP企业资源规划(领域。,"ERP 3199个文件
Telecom1 826  Telecom2 1481 Telecom3 284  Telecom4 63",私有,完成,JAVA,朴素贝叶斯,文件级,故障密度,"Probability of Detection (pd)
Probability of False Alarms (p f )
Balance (bal)",软件故障预测应考虑人为因素的影响，人类思考对软件的作用，确认偏差指标被认为是与静态和churn指标具有相同预测性能的
"Pizzi, Nick J.",A fuzzy classifier approach to estimating software quality,INFORMATION SCIENCES,10.1016/j.ins.2013.04.027,2013,"With the increasing sophistication of today's software systems, it is often difficult to estimate the overall quality of underlying software components with respect to attributes such as complexity, utility, and extensibility. Many metrics exist in the software engineering literature that attempt to quantify, with varying levels of accuracy, a large swath of qualitative attributes. However, the overall quality of a software object may manifest itself in ways that the simple interpretation of metrics fails to identify. A better strategy is to determine the best, possibly non-linear, subset of many software metrics for accurately estimating software quality. This strategy may be couched in terms of a problem of classification, that is, determine a mapping from a set of software metrics to a set of class labels representing software quality.We implement this strategy using a fuzzy classification approach. The software metrics are automatically computed and presented as features (input) to a classifier, while the class labels (output) are assigned via an expert's (software architect) thorough assessment of the quality of individual software objects. A large collection of classifiers is presented with subsets of the software metric features. Subsets are selected stochastically using a fuzzy logic based sampling method. The classifiers then predict the quality, specifically the class label, of each software object. Fuzzy integration is applied to the results from the most accurate individual classifiers. We empirically evaluate this approach using software objects from a sophisticated algorithm development framework used to develop biomedical data analysis systems. We demonstrate that the sampling method attenuates the effects of confounding features, and the aggregated classification results using fuzzy integration are superior to the predictions from the respective best individual classifiers. (C) 2013 Elsevier Inc. All rights reserved.",3,我们使用一个用于开发生物医学数据分析系统的复杂算法开发框架中的软件对象对这种方法进行了实证评估。,有效的模式分类需要一个高效的分类器与协同的预处理和后处理策略的耦合。在分类问题中经常出现的情况是，只有一部分特征具有区分能力，而其余的特征往往会混淆底层分类器的有效性。在这种情况下，一种明智的预处理策略是识别和选择歧视性特征，并修剪混淆的特征。,我们提出了一个模糊分类系统，带有预测聚合的模糊特征选择(FSPA)，它识别歧视性特征子集(使用基于模糊逻辑的采样规则)，这些特征子集被呈现给分类器集合，其中最佳分类器预测被聚合(使用模糊集成)以产生一致的预测集。为了验证该系统，我们从定量软件工程的角度研究了一个分类问题。,结果表明，基于预测聚合的模糊特征选择是一种有效的模式分类策略。通过使用模糊性能更新规则(预处理)对特征子集进行采样，将其呈现给分类器集合，并使用模糊集成聚合最佳独立结果以产生共识结果(后处理)，我们获得了比任何各自的最佳单个分类器更好的结果,,一个版本,"Borland’s Together software package
软件度量数据集包含n = 52个特征(软件度量)，描述n = 714种模式(软件对象)。",预测聚合模糊特征选择(FSPA);,,"x42 (protected members), x33 (operations), x35 (operands), x37 (remote methods), x19 (method cohesion), x31 (constructors),x34 (overridden methods), and x22 (method invocation coupling).","Scopira[10,47]是一个适用于生物医学数据分析和可视化的开源框架，以可扩展的c++库的形式提供高性能的端到端应用程序开发功能。",714个对象,公开,完成,C++,线性判别分析(LDA)[,类,模块质量,P为正确分类的物体与物体总数的比值;,证明了其特征选择的优越性，排除了混淆特征，减少特征数量，增加了软件质量分类的准确性，但是所用数据集规模较小，且标签为人为判定
"He, Peng; Li, Bing; Ma, Yutao; He, Lulu",Using Software Dependency to Bug Prediction,MATHEMATICAL PROBLEMS IN ENGINEERING,10.1155/2013/869356,2013,"Software maintenance, especially bug prediction, plays an important role in evaluating software quality and balancing development costs. This study attempts to use several quantitative network metrics to explore their relationships with bug prediction in terms of software dependency. Our work consists of four main steps. First, we constructed software dependency networks regarding five dependency scenes at the class-level granularity. Second, we used a set of nine representative and commonly used metrics-namely, centrality, degree, PageRank, and HITS, as well as modularity-to quantify the importance of each class. Third, we identified how these metrics were related to the proneness and severity of fixed bugs in Tomcat and Ant and determined the extent to which they were related. Finally, the significant metrics were considered as predictors for bug proneness and severity. The result suggests that there is a statistically significant relationship between class's importance and bug prediction. Furthermore, betweenness centrality and out-degree metric yield an impressive accuracy for bug prediction and test prioritization. The best accuracy of our prediction for bug proneness and bug severity is up to 54.7% and 66.7% (top 50, Tomcat) and 63.8% and 48.7% (top 100, Ant), respectively, within these two cases.",3,本研究试图使用几个定量的网络度量来探索它们在软件依赖方面与bug预测的关系。,在复杂网络理论与软件工程实践相结合的背景下，bug预测的研究在过去的几年里已经取得了一些新发现。在本文中，我们建议使用网络科学中的一些定量指标来实现复杂系统的错误预测，并进一步增强软件工程实践。,本研究试图使用几个定量的网络度量来探索它们在软件依赖方面与bug预测的关系,结果表明，类的重要性与bug预测之间存在统计学上显著的关系。此外，中间性中心性和出度度量在错误预测和测试优先级方面产生了令人印象深刻的准确性。在这两种情况下，我们对错误倾向和错误严重程度的预测准确率分别高达54.7%和66.7%(前50名，Tomcat)和63.8%和48.7%(前100名，Ant)。,,跨版本,"特征向量中心性(EC)
中间中心性(BC)
亲近中心性(CC)
PageRank(PR)
HITS
degree
模块化比率(MR)",无,无,"通过上述实验，我们了解到BC和outD指标对于表示漏洞的倾向性和严重性非常重要。
结果显示，outD的表现远远好于其他指标，f值几乎是其他指标的两倍多。最好的情况是50个节点的顶部为0.6667。
outD是预测间接类级软件网络的缺陷倾向和缺陷严重程度的最合适的度量。
表3显示了BC、D和outd指标的平均值与软件bug倾向性有显著的相关性。",Tomcat and Ant,"2015个类
1345个类",公开,完成,JAVA,直接通过指标,类,"故障倾向
故障严重程度",F值,探究了网络度量和bug严重度和倾向直接的依赖关系，outd指标有较好的结果，但是与其他文献相比，结果一般，只用网络度量不尽人意
"Wang, Huanjing; Khoshgoftaar, Taghi M.; Liang, Qianhui (Althea)",A STUDY OF SOFTWARE METRIC SELECTION TECHNIQUES: STABILITY ANALYSIS AND DEFECT PREDICTION MODEL PERFORMANCE,INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS,10.1142/S0218213013600105,2013,"Software metrics (features or attributes) are collected during the software development cycle. Metric selection is one of the most important preprocessing steps in the process of building defect prediction models and may improve the final prediction result. However, the addition or removal of program modules (instances or samples) can alter the subsets chosen by a feature selection technique, rendering the previously-selected feature sets invalid. Very limited research have been done considering both stability (or robustness) and defect prediction model performance together in the software engineering domain, despite the importance of both aspects when choosing a feature selection technique. In this paper, we test the stability and classification model performance of eighteen feature selection techniques as the magnitude of change to the datasets and the size of the selected feature subsets are varied. All experiments were conducted on sixteen datasets from three real-world software projects. The experimental results demonstrate that Gain Ratio shows the least stability while two different versions of ReliefF show the most stability, followed by the PRC- and AUC-based threshold-based feature selection techniques. Results also show that the signal-to-noise ranker performed moderately in terms of robustness and was the best ranker in terms of model performance. Finally, we conclude that while for some rankers, stability and classification performance are correlated, this is not true for other rankers, and therefore performance according to one scheme (stability or model performance) cannot be used to predict performance according to the other.",3,在本文中，我们测试了18种特征选择技术的稳定性和分类模型性能，因为数据集的变化幅度和选择的特征子集的大小是不同的。所有的实验都是在来自三个真实世界软件项目的16个数据集上进行的。,在过去的十年中，许多研究都从分类性能的角度考察了特征选择，但很少有研究关注特征选择技术的鲁棒性(或稳定性)。研究特征选择技术稳定性的目的是确定哪些技术提供的特征子集对数据的变化(向数据集添加或删除程序模块)具有鲁棒性。这些健壮的特征选择技术将选择即使在数据集中实例数量发生变化后也可以使用的特征子集。这对于软件质量从业者来说是很重要的，因为它允许他们在收集了额外的数据之后继续使用模型，而不必再次执行特征选择,在本研究中，我们研究了18种不同的特征选择技术的稳定性，包括6种常用的特征选择技术，11种基于阈值的特征选择(TBFS)技术，以及一种相对较新的称为信噪比的技术。我们通过测量使用完整数据集选择的子集与从删除实例的修改数据集选择的子集之间的方差来评估数据集上度量的稳定性。,结果还表明，从数据集中删除的实例数量会影响特征排序技术的稳定性。从给定数据集中删除(或添加)的实例越少，与原始数据集相比，所选特征的变化就越少，因此在该数据集上执行的特征排序将更加稳定。我们研究的主要结论是，仅仅因为一个排序器在稳健性方面表现最好，并不意味着该排序器在模型性能方面优于其他排序器，反之亦然。基于这些结果，我们建议在执行软件质量分析时使用信号噪声排序器来选择软件度量。,,跨版本,每个数据集都有不同的度量,18种特征选择方法,,"稳定性来说，可以看出RF、RFW和PRC的稳定性最好，GR的稳定性最差。
分类性能来说，S2N表现最好，其次是IG和AUC;RF和RFW表现最差，GR次之。
如S2N和基于AUC、PRC和fm的TBFS排名器，在两种方案下都表现出不错的性能。",包括一个非常大的电信软件系统(表示为LLTS)， Eclipse项目，和NASA软件项目KC1,,公开,完成,JAVA/C,"朴素贝叶斯
支持向量机
逻辑回归",文件级,故障倾向,AUC,特征选择方法的稳定性与其导致的分类性能没有直接关系，但是特征选择的确可以提升同一分类器的性能，足以可见特征的重要性
"Okutan, Ahmet; Yildiz, Olcay Taner",Software defect prediction using Bayesian networks,EMPIRICAL SOFTWARE ENGINEERING,10.1007/s10664-012-9218-8,2014,"There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings.",3,定义了另外两个指标，即用于开发人员数量的NOD和用于源代码质量的LOCQ。我们通过检查所选Promise数据存储库数据集的源代码存储库来提取这些指标。在建模的最后，我们了解了整个软件系统的边际缺陷倾向概率，最有效的度量集合，以及度量与缺陷之间的影响关系。,在文献中有许多不同的软件度量被发现并用于缺陷预测。如果我们能够确定最重要的一组度量标准，并更多地关注它们来预测缺陷，而不是处理如此多的度量标准，这将是实际的和容易的。,"我们使用贝叶斯网络来确定软件度量和缺陷倾向性之间的概率影响关系。
我们定义了另外两个度量标准，即NOD代表开发人员的数量，LOCQ代表源代码质量。","表明类响应(RFC)、代码行数(LOC)和缺乏编码质量(LOCQ)是最有效的度量，而对象之间的耦合(CBO)、加权类方法(WMC)和缺乏方法内聚(LCOM)是较不有效的缺陷倾向性度量。此外，子代数(NOC)和继承树深度(DIT)的影响非常有限，而且不可信。另一方面，开发者数量(NOD)和缺陷程度之间存在正相关关系
我们建议项目经理在将多个开发人员分配给一个类或文件时要小心。",首先，贝叶斯网络能够模拟一组变量对网络中另一个变量的概率影响。有了父母的概率，就可以计算出他们孩子的概率。其次，贝叶斯网络可以解决数据缺失问题。,版本内,"Group1 LOC CBO LOCQ 
Group2 WMC RFC 
Group3 LCOMCLCOM3 DIT NOC",,,"RFC、LOC和LOCQ对缺陷倾向更有效。另一方面，NOC和DIT对缺陷的影响是有限的和不可信的 
我们引入了一个新的度量，我们称之为编码质量缺失(LOCQ)，它可以用来预测缺陷，并且与著名的面向对象度量(如CBO和WMC)一样有效。
与LOC、CBO、RFC、LOCQ和wmc相比，LCOM3和LCOM对缺陷倾向的影响较小。",promise中9个,229-858类,公开,完成,JAVA？,贝叶斯网络,类,故障倾向,AUC,
"Liu, Mingxia; Miao, Linsong; Zhang, Daoqiang",Two-Stage Cost-Sensitive Learning for Software Defect Prediction,IEEE TRANSACTIONS ON RELIABILITY,10.1109/TR.2014.2316951,2014,"Software defect prediction (SDP), which classifies software modules into defect-prone and not-defect-prone categories, provides an effective way to maintain high quality software systems. Most existing SDP models attempt to attain lower classification error rates other than lower misclassification costs. However, in many real-world applications, misclassifying defect-prone modules as not-defect-prone ones usually leads to higher costs than misclassifying not-defect-prone modules as defect-prone ones. In this paper, we first propose a new two-stage cost-sensitive learning (TSCS) method for SDP, by utilizing cost information not only in the classification stage but also in the feature selection stage. Then, specifically for the feature selection stage, we develop three novel cost-sensitive feature selection algorithms, namely, Cost-Sensitive Variance Score (CSVS), Cost-Sensitive Laplacian Score (CSLS), and Cost-Sensitive Constraint Score (CSCS), by incorporating cost information into traditional feature selection algorithms. The proposed methods are evaluated on seven real data sets from NASA projects. Experimental results suggest that our TSCS method achieves better performance in software defect prediction compared to existing single-stage cost-sensitive classifiers. Also, our experiments show that the proposed cost-sensitive feature selection methods outperform traditional cost-blind feature selection methods, validating the efficacy of using cost information in the feature selection stage.",3,本文首先提出了一种新的两阶段代价敏感学习(TSCS)方法，该方法不仅利用分类阶段的代价信息，而且利用特征选择阶段的代价信息。然后，针对特征选择阶段，通过将成本信息融入传统特征选择算法，提出了三种新的代价敏感特征选择算法，即代价敏感方差评分(CSVS)、代价敏感拉普拉斯评分(CSLS)和代价敏感约束评分(CSCS)。,"不幸的是，软件缺陷预测仍然是一个难以解决的问题，它面临着两个挑战[22]-[24]:高维数和类不平衡。从软件模块中提取的特性(即软件度量)的数量变得比以前大得多，并且这些特性可能是冗余的或不相关的
特征选择是解决SDP中高维问题的有效方法。
然而，在大多数基于代价敏感学习的SDP研究中，代价信息是在分类阶段而不是在特征选择阶段使用的。但是在特征选择阶段考虑有价值的成本信息可能会进一步提高SDP模型的性能，因为与少数类(即，有缺陷的模块)相关的特征更有可能被选择",本文的目标是通过在分类和特征选择阶段使用成本信息，开发一种两阶段成本敏感(TSCS)学习方法。在成本敏感特征选择方面已经做了很多工作;我们还开发了三种新的代价敏感特征选择算法，在特征选择阶段强调错误分类代价较高的样本，而不强调错误分类代价较低的样本。,实验结果表明，TSCS方法优于单阶段代价敏感学习方法，而代价敏感特征选择方法优于传统的代价盲特征选择方法。,特征选择可以分为三类[25]:1)包装型方法，2)嵌入型方法，3)过滤器型方法。,版本内,,特征选择是解决SDP中高维问题的有效方法。在本文中，我们主要研究滤波器类型的特征选择。在特征选择阶段采用了三种代价敏感型特征选择算法(CSVS、CSLS和CSCS);,,"与神经网络相比，代价敏感型和代价盲型特征选择方法都能显著降低总代价，提高两个数据集的性能，说明特征选择是SDP问题的重要一步。
此外，本文提出的成本敏感特征选择方法在总成本和我们使用的两个数据集上的表现通常优于成本盲特征选择方法。这些结果进一步验证了在特征选择和分类阶段使用成本信息的有效性。",NASA MDP,505-5589个模块,公开,完成,C/JAVA,BPN反向传播神经网络,模块,故障倾向,sensitivity，accuracy，total-cost,
"Couto, Cesar; Pires, Pedro; Valente, Marco Tulio; Bigonha, Roberto S.; Anquetil, Nicolas",Predicting software defects with causality tests,JOURNAL OF SYSTEMS AND SOFTWARE,10.1016/j.jss.2014.01.033,2014,"In this paper, we propose a defect prediction approach centered on more robust evidences towards causality between source code metrics (as predictors) and the occurrence of defects. More specifically, we rely on the Granger causality test to evaluate whether past variations in source code metrics values can be used to forecast changes in time series of defects. Our approach triggers alarms when changes made to the source code of a target system have a high chance of producing defects. We evaluated our approach in several life stages of four Java-based systems. We reached an average precision greater than 50% in three out of the four systems we evaluated. Moreover, by comparing our approach with baselines that are not based on causality tests, it achieved a better precision. (C) 2014 Elsevier Inc. All rights reserved.",3,我们提出了一种缺陷预测方法，该方法集中在源代码度量(作为预测者)和缺陷发生之间的因果关系的更可靠的证据上。,然而，设计用于评估缺陷预测技术的典型实验并没有调查所发现的关系是否表明因果关系，或者它们是否仅仅是统计上的巧合。更具体地说，众所周知，回归模型――bug预测者使用的最常见的统计技术――不能过滤掉虚假关系[11]。,"在本文中，我们提出了一种缺陷预测方法，该方法以源代码度量值的变化(作为预测因子)和缺陷发生之间的因果关系为中心。更具体地说，我们依靠Clive Granger提出的统计假设检验来评估过去对给定时间序列的变化是否有助于预测另一个序列的变化。
我们的中心目标是在源代码中引入缺陷时预测缺陷。更具体地说，我们的目标是识别有更多机会产生缺陷的类的更改",我们的方法在我们评估的四个系统中的三个的几个生命阶段达到了50%的平均精度。此外，通过将我们的方法与不基于因果关系测试的基线进行比较，它获得了更好的精度。最后，正如在以前的研究中所描述的，我们不能确定与大多数缺陷普遍相关的一小组度量标准。,,跨版本,WMC、LCOM、FAN-IN、FAN-OUT、NOA、LOC、NOM,无,,,Eclipse JDT Core、Eclipse PDE UI、Equinox和Lucene,,公开,完成,JAVA,Granger,类级,文件改动导致的故障倾向,"precision
我们的方法在我们评估的四个系统中的三个系统中达到了超过50%的平均精度。
recall
在Eclipse JDT、Eclipse PDE UI、Equinox和Lucene系统中，测得的recall最大值分别为63%、44%、31%和52%。",验证m格兰杰是否会导致C中的缺陷，以及差异(mv - mv ')是否大于或等于度量值变化所识别的阈值。主要是通过所选度量的变化来学习故障特征，然后通过对比新引入的变化度量是否超过所学习到的阈值，来确定该改变是否会引入故障，该方法准确度不是很高。时间序列越多，判别可能越不准确
"Ma, Ying; Zhu, Shunzhi; Qin, Ke; Luo, Guangchun",Combining the requirement information for software defect estimation in design time,INFORMATION PROCESSING LETTERS,10.1016/j.ipl.2014.03.012,2014,"This paper analyzes the ability of requirement metrics for software defect prediction. Statistical significance tests are used to compare six machine learning algorithms on the requirement metrics, design metrics, and combination of both metrics in our analysis. The experimental results show the effectiveness of the predictor built on the combination of the requirement and design metrics in the early phase of the software development process. (C) 2014 Elsevier B.V. All rights reserved.",3,需求度量在软件缺陷预测中的能力。在我们的分析中，统计显著性测试用于比较需求度量、设计度量和这两种度量的组合上的六种机器学习算法。,但后来，他们报告了“天花板效应”，并认为学习缺陷预测的进一步进展可能不是来自更好的算法，而是来自更多的训练数据的信息内容,与之前的工作不同的是，我们比较了从需求度量、设计度量，以及使用朴素贝叶斯、AdaBoost、Bagging、随机森林、逻辑回归和K-Star方法的两者结合构建的缺陷预测器的性能,这一实证研究表明，建立在组合度量上的缺陷预测器可以应用于软件开发过程的早期阶段。我们发现建立在这两个度量组的组合上的模型表现得非常好。据我们所知，这是第一份调查从需求和设计度量的组合中构建的质量预测模型的性能的报告。我们的实验提供了最初的证据，证明结合软件人工度量可以显著地提高缺陷预测模型的有效性。,他们报告了“天花板效应”，并认为学习缺陷预测的进一步进展可能不是来自更好的算法，而是来自更多的训练数据的信息内容,版本内,"requirement metrics
Design metrics
这些数据集有9个需求度量属性和16个设计度量属性。",,,"两个度量组的组合具有更好的性能
我们对特征的有用性进行排序，并在实验中增加不同组特征的数量，如图2所示。我们可以看到，在达到峰值性能前，随着特征数量逐渐增加，基于所有指标构建的模型的性能也逐渐增加",NASA MDP（CM1、PC1）,"505design、114requirement
1107、320模块",公开,完成,C,朴素贝叶斯、AdaBoost、Bagging、随机森林、逻辑回归、K-Star方法,模块,故障倾向,"F值
AUC",
"Gao, Kehan; Khoshgoftaar, Taghi M.; Napolitano, Amri",The Use of Ensemble-Based Data Preprocessing Techniques for Software Defect Prediction,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194014400105,2014,"Software defect prediction models that use software metrics such as code-level measurements and defect data to build classification models are useful tools for identifying potentially-problematic program modules. Effectiveness of detecting such modules is affected by the software measurements used, making data preprocessing an important step during software quality prediction. Generally, there are two problems affecting software measurement data: high dimensionality (where a training dataset has an extremely large number of independent attributes, or features) and class imbalance (where a training dataset has one class with relatively many more members than the other class). In this paper, we present a novel form of ensemble learning based on boosting that incorporates data sampling to alleviate class imbalance and feature (software metric) selection to address high dimensionality. As we adopt two different sampling methods (Random Undersampling (RUS) and Synthetic Minority Oversampling (SMOTE)) in the technique, we have two forms of our new ensemble-based approach: SelectRUSBoost and SelectSMOTEBOOST. To evaluate the effectiveness of these new techniques, we apply them to two groups of datasets from two real-world software systems. In the experiments, four learners and nine feature selection techniques are employed to build our models. We also consider versions of the technique which do not incorporate feature selection, and compare all four techniques (the two different ensemble-based approaches which utilize feature selection and the two versions which use sampling only). The experimental results demonstrate that SelectRUSBoost is generally more effective in improving defect prediction performance than SelectsMOTEBOOst, and that the techniques with feature selection do help for getting better prediction than the techniques without feature selection.",3,在本文中，我们提出了一种基于提升的集成学习的新形式，它结合了数据采样来缓解类失衡和特征(软件度量)选择来解决高维问题。,"然而，许多研究[3,4]表明，软件质量数据集的两个特征会对这些模型的有效性产生负面影响:高维和类不平衡。只有一小部分特征对预测类属性是重要的;其余的要么是不相关的(没有与类变量相关的有用信息)，要么是多余的(具有已经包含在其他特性中的信息)。最近的研究[6]表明，基于滤波器的特征排序技术是处理这一问题的简单、快速和有效的方法。",本文提出了一种集成数据采样、特征选择和集成学习(boosting)的新技术，以减轻高维、不平衡数据对缺陷预测模型的不利影响。,实验结果表明，SelectRUSBoost通常比SelectSMOTEBoost更有效地提高缺陷预测性能，并且具有特征选择的技术确实比不具有特征选择的技术有助于获得更好的预测。,,跨版本,"LLTS数据集由42个软件度量组成，包括24个产品度量、14个过程度量和4个执行度量
所有数据集包含209个软件属性，其中包括208个独立(预测器)属性和一个依赖属性","9种特征排序技术，包括6种标准技术[25]、2种基于阈值的技术[26]和信噪比
卡方(CS)、信息增益(IG)、增益比(GR)、两种解脱(RF和RFW)和对称不确定性(SU)。",该研究再次表明，特征选择确实改善了分类分类模型的预测。SRB的表现明显优于SSB。,"S2N、RF和rfw表现优于其他排序技术。CS、IG、SU、AUC和prc表现为平均水平。GR表现最差。研究还表明，当使用特征选择技术时，与不考虑特征选择的RB或SB技术相比，分类分类模型产生了明显更好的预测。
S2N仍然是表现最好的选手之一，但是RF和RFW这次的表现不如其他选手。","大型遗留电信软件系统(表示为LLTS)
Eclipse","3600-4000模块
377-661包",公开,完成,"类似C
JAVA",多层感知机，k近邻，支持向量机，逻辑回归,"模块
包",故障倾向,AUC,
"He, Peng; Li, Bing; Liu, Xiao; Chen, Jun; Ma, Yutao",An empirical study on software defect prediction with a simplified metric set,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2014.11.006,2015,"Context: Software defect prediction plays a crucial role in estimating the most defect-prone components of software, and a large number of studies have pursued improving prediction accuracy within a project or across projects. However, the rules for making an appropriate decision between within- and cross-project defect prediction when available historical data are insufficient remain unclear.Objective: The objective of this work is to validate the feasibility of the predictor built with a simplified metric set for software defect prediction in different scenarios, and to investigate practical guidelines for the choice of training data, classifier and metric subset of a given project.Method: First, based on six typical classifiers, three types of predictors using the size of software metric set were constructed in three scenarios. Then, we validated the acceptable performance of the predictor based on Top-k metrics in terms of statistical methods. Finally, we attempted to minimize the Top-k metric subset by removing redundant metrics, and we tested the stability of such a minimum metric subset with one-way ANOVA tests.Results: The study has been conducted on 34 releases of 10 open-source projects available at the PROMISE repository. The findings indicate that the predictors built with either Top-k metrics or the minimum metric subset can provide an acceptable result compared with benchmark predictors. The guideline for choosing a suitable simplified metric set in different scenarios is presented in Table 12.Conclusion: The experimental results indicate that (1) the choice of training data for defect prediction should depend on the specific requirement of accuracy; (2) the predictor built with a simplified metric set works well and is very useful in case limited resources are supplied; (3) simple classifiers (e.g., Naive Bayes) also tend to perform well when using a simplified metric set for defect prediction; and (4) in several cases, the minimum metric subset can be identified to facilitate the procedure of general defect prediction with acceptable loss of prediction precision in practice. (C) 2014 Elsevier B.V. All rights reserved.",3,验证用简化的度量集构建的预测器在不同场景下用于软件缺陷预测的可行性，并研究在给定项目中选择训练数据、分类器和度量子集的实际指导方针。方法:首先，基于6种典型分类器，在3种场景下构建3种基于软件度量集大小的预测因子。然后，我们根据统计方法验证了基于Top-k指标的预测器的可接受性能。最后，我们试图通过删除冗余度量来最小化Top-k度量子集，并使用单向方差分析测试了这种最小度量子集的稳定性。,软件缺陷预测在评估软件中最容易出现缺陷的组件方面起着至关重要的作用，并且大量的研究都在追求提高项目内或跨项目的预测准确性。然而，当可用的历史数据不足时，在项目内部和跨项目缺陷预测之间做出适当决策的规则仍然不清楚。,"这项工作的目标是验证用简化的度量集构建的预测器在不同场景下用于软件缺陷预测的可行性，并研究在给定项目中选择训练数据、分类器和度量子集的实际指导方针。
首先，基于六种典型分类器，在三种场景下构建了三种基于软件度量集大小的预测器。然后，我们根据统计方法验证了基于Top-k指标的预测器的可接受性能。最后，我们试图通过删除冗余度量来最小化Top-k度量子集，并使用单向方差分析测试了这种最小度量子集的稳定性。",这项研究是在PROMISE存储库中提供的10个开源项目的34个版本上进行的。研究结果表明，与基准预测器相比，使用Top-k指标或最小度量子集构建的预测器可以提供可接受的结果。表12给出了在不同场景中选择合适的简化度量集的指导原则。结论:实验结果表明:(1)缺陷预测训练数据的选择应根据准确率的具体要求;(2)使用简化度量集构建的预测器效果良好，在资源有限的情况下非常有用;(3)当使用简化的度量集进行缺陷预测时，简单分类器(例如Na?ve Bayes)也倾向于表现良好;(4)在某些情况下，可以识别最小度量子集，以便在实际预测精度损失可接受的情况下进行一般缺陷预测。,,跨版本/跨项目,20个静态度量，包括CK套件(6)、Martin的度量(2)、QMOOM套件(5)、Extended CK套件(4)、McCabe的CC(2)以及LOC。,"特征选择可以大致分为特征排序和特征子集选择，也可以分为过滤器和包装器。过滤器是在不涉及任何学习算法的情况下选择特征子集的算法，而包装器是使用来自分类学习算法的反馈来确定在构建分类模型时要包含哪些特征的算法。
Top-k特征子集 最小特征子集",,从实践的角度来看，度量子集CBO + LOC可能是CPDP最小度量子集的另一种选择，尽管从理论的角度来看，CBO + LOC + LCOM的组合已经被验证为最小度量子集,34个数据集,125-965,公开,完成,JAVA,本研究采用文献[16]中常用的六种分类算法J48（J48是C4.5决策树算法的开源Java实现）、Logistic回归(LR)、Na?ve贝叶斯(NB)、决策表(DT)、支持向量机(SVM)和贝叶斯网络(BN)构建软件缺陷预测模型,类,故障倾向,precison精度、召回率和F-measure,选择特征先根据各特征出现次数，重要性来排序，然后对top-k这k个度量组合，若其相关系数矩阵，某两个度量相关性超过阈值，则排除所有包含这两个度量的组合，最后确定最小度量集
"Yadav, Harikesh Bahadur; Yadav, Dilip Kumar",A fuzzy logic based approach for phase-wise software defects prediction using software metrics,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2015.03.001,2015,"Context: The software defect prediction during software development has recently attracted the attention of many researchers. The software defect density indicator prediction in each phase of software development life cycle (SDLC) is desirable for developing a reliable software product. Software defect prediction at the end of testing phase may not be more beneficial because the changes need to be performed in the previous phases of SDLC may require huge amount of money and effort to be spent in order to achieve target software quality. Therefore, phase-wise software defect density indicator prediction model is of great importance.Objective: In this paper, a fuzzy logic based phase-wise software defect prediction model is proposed using the top most reliability relevant metrics of the each phase of the SDLC.Method: In the proposed model, defect density indicator in requirement analysis, design, coding and testing phase is predicted using nine software metrics of these four phases. The defect density indicator metric predicted at the end of the each phase is also taken as an input to the next phase. Software metrics are assessed in linguistic terms and fuzzy inference system has been employed to develop the model.Results: The predictive accuracy of the proposed model is validated using twenty real software project data. Validation results are satisfactory. Measures based on the mean magnitude of relative error and balanced mean magnitude of relative error decrease significantly as the software project size increases.Conclusion: In this paper, a fuzzy logic based model is proposed for predicting software defect density indicator at each phase of the SDLC. The predicted defects of twenty different software projects are found very near to the actual defects detected during testing. The predicted defect density indicators are very helpful to analyze the defect severity in different artifacts of SDLC of a software project. (C) 2015 Elsevier B.V. All rights reserved.",3,提出了一种基于模糊逻辑的分阶段软件缺陷预测模型，该模型采用SDLC各阶段的最可靠相关度量,软件开发过程中的软件缺陷预测问题近年来引起了许多研究者的关注。软件开发生命周期(SDLC)各个阶段的软件缺陷密度指示器预测是开发可靠的软件产品所需要的。在测试阶段结束时进行软件缺陷预测可能不是更有益的，因为需要在SDLC的前一个阶段执行的更改可能需要花费大量的金钱和精力来实现目标软件质量。因此，分阶段的软件缺陷密度指标预测模型具有重要的意义。,本文提出了一种基于模糊逻辑的分阶段软件缺陷预测模型，该模型利用SDLC各阶段的最顶层可靠性相关度量。方法:在提出的模型中，利用需求分析、设计、编码和测试四个阶段的9个软件度量对缺陷密度指标进行预测。在每个阶段结束时预测的缺陷密度指示器度量也被作为下一阶段的输入。用语言对软件度量进行评估，并采用模糊推理系统建立模型。,用20个实际软件项目数据验证了该模型的预测精度。验证结果令人满意。随着软件项目规模的增加，基于相对误差的平均幅度和平衡相对误差的平均幅度的度量显著减少。结论:本文提出了一种基于模糊逻辑的软件缺陷密度指标预测模型。在20个不同的软件项目中发现的预测缺陷与测试期间检测到的实际缺陷非常接近。预测的缺陷密度指标对于分析软件项目SDLC不同工件中的缺陷严重程度非常有帮助。,,跨版本/各阶段,软件生命周期四个阶段都有对应的度量,专家评估,,,,0.9-154Kloc,私有,四个阶段,C,模糊规则,项目,故障密度/故障数量,"Mean Magnitude of Relative Error (MMRE)
Balanced Mean Magnitude of Relative Error (BMMRE)",对软件开发四个阶段分别进行模糊逻辑预测其故障密度，故障密度乘测试阶段代码行数可以得到故障数量
"Czibula, Gabriela; Marian, Zsuzsanna; Czibula, Istvan Gergely",Detecting software design defects using relational association rule mining,KNOWLEDGE AND INFORMATION SYSTEMS,10.1007/s10115-013-0721-z,2015,"In this paper, we are approaching, from a machine learning perspective, the problem of automatically detecting defective software entities (classes and methods) in existing software systems, a problem of major importance during software maintenance and evolution. In order to improve the internal quality of a software system, identifying faulty entities such as classes, modules, methods is essential for software developers. As defective software entities are hard to identify, machine learning-based classification models are still developed to approach the problem of detecting software design defects. We are proposing a novel method based on relational association rule mining for detecting faulty entities in existing software systems. Relational association rules are a particular type of association rules and describe numerical orderings between attributes that commonly occur over a dataset. Our method is based on the discovery of relational association rules for identifying design defects in software. Experiments on open source software are conducted in order to detect defective classes in object-oriented software systems, and a comparison of our approach with similar existing approaches is provided. The obtained results show that our method is effective for software design defect detection and confirms the potential of our proposal.",3,提出了一种基于关系关联规则挖掘的软件系统故障实体检测方法。,"为了在大量数据中发现相关的模式和规则，人们一直对应用关联规则挖掘感兴趣[46]
从软件度量在度量软件质量中至关重要这一事实出发，使用基于度量的软件系统实体的高维表示，并基于在数据集中发现关系关联规则的思想，",本文提出了一种检测缺陷软件实体的新方法。我们专注于开发一个基于机器学习的计算模型，该模型将足够强大(如实验部分所示)，以捕获与区分包含或不包含内部结构缺陷的软件实体相关的方面。在构建我们的模型时，我们试图利用数据挖掘技术的好处来发现软件系统架构中隐藏的模式。,通过在开源软件系统上对本文提出的技术进行评估，得到的结果证实了将关系关联规则挖掘用于软件设计缺陷检测是有希望的，表明了我们的提出模型的潜力。,,跨项目,"我们选择了16个可以应用于类的指标
CA, CBO, DAC, ICH, INS, LCC, LCOM1, LCOM2, LCOM4, LCOM5, LD, MPC, NOA, NOM, RFC, TCC",为了确定特征之间的依赖关系，使用Pearson相关系数[49]。对于每个软件度量sm，我们计算它的绝对平均相关性avg(sm)作为sm和来自(sm)的其他软件度量之间的相关性的平均值。考,挖掘特征之间的关系，并应用于预测,无,"JHotDraw version 5.1作为训练集
FT P4J 1.5, 1.5.1, 1.6, and 1.6.1. 每个27个类
ISO8583 1.5.2、1.5.3和1.5.4，每个版本都有21个类
Profiler4J
1.0-alpha5 (a5)、1.0-alpha6 (a6)、1.0-alpha7 (a7)和1.0-beta1 (b1)。前两个18后两个15个类
WinRun4J 0.4.0, 0.4.1, 0.4.2, 0.4.3, and 0.4.4.前三个21，后两个24",训练集由173个类、1375个方法和475个属性组成。,公开,完成,JAVA,SDDRAR method,类级,故障倾向,"recall precision
我们的方法在六个考虑的案例研究中获得了0.917的平均检测精度。该方法的平均召回率为0.85，",作为预测的数据集规模太小，不知道该方法在大规模下的表现 从设计优良的软件中提取度量之间的关系，然后应用在需要预测的软件中，比较依赖训练集
"Rana, Zeeshan Ali; Mian, M. Awais; Shamail, Shafay",Improving Recall of software defect prediction models using association mining,KNOWLEDGE-BASED SYSTEMS,10.1016/j.knosys.2015.10.009,2015,Use of software product metrics in defect prediction studies highlights the utility of these metrics. Public availability of software defect data based on the product metrics has resulted in the development of defect prediction models. These models experience a limitation in learning Defect-prone(D) modules because the available datasets are imbalanced. Most of the datasets are dominated by Not Defect-prone (ND) modules as compared to D modules. This affects the ability of classification models to learn the D modules more accurately. This paper presents an association mining based approach that allows the defect prediction models to learn D modules in imbalanced datasets. The proposed algorithm preprocesses data by setting specific metric values as missing and improves the prediction of D modules. The proposed algorithm has been evaluated using 5 public datasets. A Naive Bayes (NB) classifier has been developed before and after the proposed preprocessing. It has been shown that Recall of the classifier after the proposed preprocessing has improved. Stability of the approach has been tested by experimenting the algorithm with different number of bins. The results show that the algorithm has resulted in up to 40% performance gain. (C) 2015 Elsevier B.V. All rights reserved.,3,与D模块相比，大多数数据集由不容易发生缺陷(ND)模块主导。这影响了分类模型更准确地学习D模块的能力。该算法通过将特定度量值设置为缺失值对数据进行预处理，提高了D模块的预测能力。,由于信息含量有限的因素，缺陷预测模型已经达到了一个性能上限，如果信息含量提高，该上限可以被跨越。可以通过收集更有洞察力的数据或访问和组合模型开发时可用的相关特征来改进该信息内容[13]。在大多数公共数据集的情况下，改进信息所需的附加数据是不可用的，以一种有洞察力的和不同的方式使用数据对于提高缺陷预测的质量是有用的。,"本文有效地利用了公共数据集中的可用信息，运用关联挖掘(association mining, AM)来发现软件度量与软件缺陷之间的关联，提高了分类模型在不平衡数据集中的性能。利用该方法对数据集进行预处理，利用预处理后的数据建立缺陷预测模型，并对模型进行召回率方面的性能分析。本研究利用公共数据集提高朴素贝叶斯(NB)分类器缺陷预测的召回率。",当缺失不同数量的项目集时，10个箱子的NB模型的性能有所提高或保持不变。此外，通过开发具有不同箱数的NB分类器，研究了所提出方法的稳定性。研究了不同数量的箱子的召回趋势，这表明当箱子数量从4个增加到20个时，NB分类器的性能也有所提高或保持不变。这种将箱子重新标记为缺失值的方法将D模块的预测提高了40%。在AR4数据集的情况下，观察到的最大性能缺陷(就误报率而言)小于14%。,,版本内,结果生成5组，分别为22、30、38、39和40个属性。,,,,"CM1, PC3, KC3, MC1和AR4",107-9466个模块,公开,完成,JAVA/C/C++,朴素贝叶斯,模块级,故障倾向,"recall 78.6%-85%
False Positive Rate (FPRate)",
"Zhao, Yangyang; Yang, Yibiao; Lu, Hongmin; Zhou, Yuming; Song, Qinbao; Xu, Baowen",An empirical analysis of package-modularization metrics: Implications for software fault-proneness,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2014.09.006,2015,"Context: In a large object-oriented software system, packages play the role of modules which group related classes together to provide well-identified services to the rest of the system. In this context, it is widely believed that modularization has a large influence on the quality of packages. Recently, Sarkar, Kak, and Rama proposed a set of new metrics to characterize the modularization quality of packages from important perspectives such as inter-module call traffic, state access violations, fragile base-class design, programming to interface, and plugin pollution. These package-modularization metrics are quite different from traditional package-level metrics, which measure software quality mainly from size, extensibility, responsibility, independence, abstractness, and instability perspectives. As such, it is expected that these package-modularization metrics should be useful predictors for fault-proneness. However, little is currently known on their actual usefulness for fault-proneness prediction, especially compared with traditional package-level metrics.Objective: In this paper, we examine the role of these new package-modularization metrics for determining software fault-proneness in object-oriented systems.Method: We first use principal component analysis to analyze whether these new package-modularization metrics capture additional information compared with traditional package-level metrics. Second, we employ univariate prediction models to investigate how these new package-modularization metrics are related to fault-proneness. Finally, we build multivariate prediction models to examine the ability of these new package-modularization metrics for predicting fault-prone packages.Results: Our results, based on six open-source object-oriented software systems, show that: (I) these new package-modularization metrics provide new and complementary views of software complexity compared with traditional package-level metrics; (2) most of these new package-modularization metrics have a significant association with fault-proneness in an expected direction; and (3) these new package-modularization metrics can substantially improve the effectiveness of fault-proneness prediction when used with traditional package-level metrics together.Conclusions: The package-modularization metrics proposed by Sarkar, Kak, and Rama are useful for practitioners to develop quality software systems. (C) 2014 Elsevier B.V. All rights reserved.",3,在本文中，我们研究了这些新的包模块化度量在面向对象系统中确定软件故障倾向的作用。,在大型面向对象的软件系统中，包扮演模块的角色，将相关的类组合在一起，为系统的其余部分提供良好识别的服务。在这种情况下，人们普遍认为模块化对包的质量有很大的影响。最近，Sarkar、Kak和Rama提出了一组新的度量标准，从模块间调用流量、状态访问冲突、脆弱的基类设计、接口编程和插件污染等重要角度来描述包的模块化质量。这些包模块化度量标准与传统的包级度量标准非常不同，后者主要从大小、可扩展性、责任、独立性、抽象性和不稳定性的角度度量软件质量。因此，预计这些包模块化度量应该是故障倾向的有用预测器。然而，目前很少有人知道它们对故障倾向预测的实际用途，特别是与传统的包级度量相比。,在本文中，我们研究了这些新的包模块化度量在面向对象系统中确定软件故障倾向的作用。方法:我们首先使用主成分分析来分析与传统的包级度量相比，这些新的包模块化度量是否捕获了额外的信息。其次，我们采用单变量预测模型来研究这些新的封装模块化度量与故障倾向之间的关系。最后，我们建立了多变量预测模型来检验这些新的封装模块化指标预测易故障封装的能力。,"基于六个开源的面向对象软件系统，我们的研究结果表明:(1)与传统的包级度量相比，这些新的包模块化度量提供了新的和互补的软件复杂性视图;(2)大多数新的封装模块化指标在预期方向上与故障倾向有显著的关联;(3)当与传统的包级度量一起使用时，这些新的包模块化度量可以大大提高故障倾向预测的有效性。结论:由Sarkar, Kak和Rama提出的包模块化度量对于从业者开发高质量的软件系统是有用的。",,版本内,"第一类是根据方法调用创建的模块间耦合来度量模块(即我们研究中的包)的质量。
第二类是根据由继承和关联创建的模块间耦合来度量模块的质量。
第三类是衡量模块相对于其他模块化实践的质量。
:(1)11个包模块化度量;(2) 8个传统的包级复杂度指标;(3)一个二进制变量，表示包是否有发布后错误。",,PCA,Sarkar等人的包模块化度量主要从方法调用流量、继承/关联耦合、状态访问冲突、脆弱基类设计、接口编程、大小一致性和插件污染的角度来衡量软件复杂性。考虑到包模块化度量所使用的信息和计数机制的性质，与传统的包级度量相比，它们可以捕获软件复杂性的额外信息，这是可以理解的。与传统的包级度量相比，包模块化度量和传统度量的结合可以解释故障数据中的更多变化。这就是Sarkar等人的包模块化度量可以提高故障倾向预测有效性的确切原因。Sarkar等人的包模块化度量与传统复杂性度量的组合比传统度量的组合具有更好的预测故障倾向的能力。,"Cxf 2.1, Flume 1.4.0, Hbase 0.96.0, Hive 0.12.0, JDT Core 3.4, and Lucene 2.4.0.",38-394KLOC,公开,完成,JAVA,逻辑回归,包级,故障倾向,"CE (cost-effectiveness)是评估故障倾向预测模型的努力感知排序效果最常用的绩效指标
在分类场景中，ER (effort reduction，最初称为“LIR”)是评估故障倾向预测模型的努力感知分类有效性最常用的性能指标[20]。",
"Wang, Huanjing; Khoshgoftaar, Taghi M.; Napolitano, Amri",An Empirical Investigation on Wrapper-Based Feature Selection for Predicting Software Quality,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194015400057,2015,"The basic measurements for software quality control and management are the various project and software metrics collected at various states of a software development life cycle. The software metrics may not all be relevant for predicting the fault proneness of software components, modules, or releases. Thus creating the need for the use of feature (software metric) selection. The goal of feature selection is to find a minimum subset of attributes that can characterize the underlying data with results as well as, or even better than the original data when all available features are considered. As an example of inter-disciplinary research (between data science and software engineering), this study is unique in presenting a large comparative study of wrapper-based feature (or attribute) selection techniques for building defect predictors. In this paper, we investigated thirty wrapper-based feature selection methods to remove irrelevant and redundant software metrics used for building defect predictors. In this study, these thirty wrappers vary based on the choice of search method (Best First or Greedy Stepwise), leaner (Naive Bayes, Support Vector Machine, and Logistic Regression), and performance metric (Overall Accuracy, Area Under ROC (Receiver Operating Characteristic) Curve, Area Under the Precision-Recall Curve, Best Geometric Mean, and Best Arithmetic Mean) used in the defect prediction model evaluation process. The models are trained using the three learners and evaluated using the five performance metrics. The case study is based on software metrics and defect data collected from a real world software project.The results demonstrate that Best Arithmetic Mean is the best performance metric used within the wrapper. Naive Bayes performed significantly better than Logistic Regression and Support Vector Machine as a wrapper learner on slightly and less imbalanced datasets. We also recommend Greedy Stepwise as a search method for wrappers. Moreover, comparing to models built with full datasets, the performances of defect prediction models can be improved when metric subsets are selected through a wrapper subset selector.",3,在本文中，我们研究了30种基于包装的特征选择方法，以去除用于构建缺陷预测器的不相关和冗余的软件度量。,软件度量可能并不都与预测软件组件、模块或版本的错误倾向相关。因此需要使用特性(软件度量)选择。特征选择的目标是找到一个最小的属性子集，当考虑到所有可用的特征时，这些属性子集可以用结果来描述底层数据，甚至比原始数据更好。,在本文中，我们研究了30种基于包装的特征选择方法，以去除用于构建缺陷预测器的不相关和冗余的软件度量。在本研究中，这30个包装器根据在缺陷预测模型评估过程中使用的搜索方法(Best First或Greedy Stepwise)、更精简(Na?ve贝叶斯、支持向量机和逻辑回归)和性能度量(总体精度、ROC曲线下面积、精度-召回曲线下面积、最佳几何平均值和最佳算术平均值)的选择而有所不同。模型使用三个学习器进行训练，并使用五个性能指标进行评估,结果表明，最佳算术平均值是包装器中使用的最佳性能度量。Na?ve作为包装学习器，贝叶斯在稍微不平衡的数据集上的表现明显优于逻辑回归和支持向量机。我们还推荐贪心逐步搜索包装器的方法。此外，与使用完整数据集构建的模型相比，通过包装子集选择器选择度量子集可以提高缺陷预测模型的性能。,,版本内,208个度量,"基于包装的特征选择方法采用一些预定的学习算法(分类器或学习器)来评估所选特征子集的优劣。该方法的性能取决于三个因素:(1)在特征空间中搜索可能的最优特征子集的策略;(2)学习者;(3)用所选择的特征子集构建分类分类模型的评价准则。
在本研究中，我们使用了Best First (BF)和Greedy Stepwise (GS)两种搜索算法。",,"一般来说，在大多数情况下，GS的性能优于BF。就包装器度量而言，BAM是平均而言最好的包装器度量。在使用基于内部包装的特征选择算法的三个学习器中，NB是最好的内部学习器。在三种外部分类器中，无论基于包装器的特征选择器内部使用哪种学习器，SVM的性能都是最好的，而NB的性能最差。
我们的结果和统计分析表明，BAM作为评估包装器内构建的模型的性能指标是非常可靠的。我们也推荐GS作为包装器内的搜索方法。在使用基于内部包装的特征选择算法的三种学习器中，NB是最好的内部学习器。在构建分类分类模型时，我们推荐SVM分类器，它的表现明显优于LR和NB分类器。",eclipse 2.0 2.1 3.0,377-661个模块/包,公开,完成,JAVA,朴素贝叶斯(NB)，支持向量机(SVM)，逻辑回归(LR),包级,故障倾向,总体准确度(OA)， ROC曲线下面积(AUC)， Precision-Recall曲线下面积(PRC)，最佳几何平均值(BGM)和最佳算术平均值(BAM)。,实际上有两种学习器，一个是包装内用来选择特征的学习器，一个是特征选择完成后用来预测的学习器，所以又叫做包装器内学习器和外部学习器
"Gao, Kehan; Khoshgoftaar, Taghi M.; Napolitano, Amri",Investigating Two Approaches for Adding Feature Ranking to Sampled Ensemble Learning for Software Quality Estimation,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194015400069,2015,"Defect prediction is very challenging in software development practice. Classification models are useful tools that can help for such prediction. Classification models can classify program modules into quality-based classes, e.g. fault-prone (fp) or not-fault-prone (nfp). This facilitates the allocation of limited project resources. For example, more resources are assigned to program modules that are of poor quality or likely to have a high number of faults based on the classification. However, two main problems, high dimensionality and class imbalance, affect the quality of training datasets and therefore classification models. Feature selection and data sampling are often used to overcome these problems. Feature selection is a process of choosing the most important attributes from the original dataset. Data sampling alters the dataset to change its balance level. Another technique, called boosting (building multiple models, with each model tuned to work better on instances misclassified by previous models), is found to also be effective for resolving the class imbalance problem.In this study, we investigate an approach for combining feature selection with this ensemble learning (boosting) process. We focus on two different scenarios: feature selection performed prior to the boosting process and feature selection performed inside the boosting process. Ten individual base feature ranking techniques, as well as an ensemble ranker based on the ten, are examined and compared over the two scenarios. We also employ the boosting algorithm to construct classification models without performing feature selection and use the results as the baseline for further comparison. The experimental results demonstrate that feature selection is important and needed prior to the learning process. In addition, the ensemble feature ranking method generally has better or similar performance than the average of the base ranking techniques, and more importantly, the ensemble method exhibits better robustness than most base ranking techniques. As for the two scenarios, the results show that applying feature selection inside boosting performs better than using feature selection prior to boosting.",3,在本研究中，我们研究了一种将特征选择与集成学习(增强)过程相结合的方法。,然而，两个主要问题，高维和类不平衡，影响了训练数据集的质量，从而影响了分类分类模型的质量。特征选择和数据采样通常用于克服这些问题。特征选择是从原始数据集中选择最重要的属性的过程。数据采样将更改数据集以更改其平衡级别。,"在本研究中，我们感兴趣的是调查两个常见的问题，即高维数和类不平衡，存在于许多软件测量数据集
在本研究中，我们研究了一种将特征选择与集成学习(增强)过程相结合的方法。我们关注两种不同的场景:在增强过程之前执行的特征选择和在增强过程中执行的特征选择
更具体地说，我们想研究十种基本特征排序技术和基于十种基本特征的集成排序器，并比较它们的行为，包括相对于不同的学习器和数据集的预测性能和稳定性(平均值周围的变化)。",实验结果表明，特征选择在学习过程之前是非常重要的。此外，集成特征排序方法的性能一般优于或接近基排序技术的平均值，更重要的是，集成方法比大多数基排序技术具有更好的鲁棒性。对于这两种场景，结果表明，在增强中应用特征选择优于在增强之前使用特征选择。值得一提的是，集成排序技术和内部特征选择在构建模型时都会产生大量的计算成本(当两种技术结合使用时，计算成本会增加)。,,跨版本,209个属性,"实证结果表明，特征选择是学习过程之前的重要步骤，可以显著提高分类识别性能。
三种标准方法，六种基于阈值的特征选择技术，以及信噪比方法。",,"在RUSBoost (IFS)内部执行的特征选择比在RUSBoost (EFS)之前应用时产生更好的分类性能。在11种特征排序技术中，集成方法表现出竞争力，排在表现最好的S2N和ROC之后，与PRC表现相同
在SMOTEBoost (IFS)内部执行的特征选择提供了比在SMOTEBoost (EFS)之前应用时更好的性能。集成方法表现出最好的性能，与S2N和ROC具有相同的性能，略优于PRC, MI和Dev
。RF的表现仍然最差",Eclipse,661个实例,公开,完成,JAVA,朴素贝叶斯(NB)、多层感知器(MLP)、k近邻(KNN)、支持向量机(SVM)和逻辑回归(LR)。,类,故障倾向,AUC,类似14年的一篇，方法和思路都差不多
"Laradji, Issam H.; Alshayeb, Mohammad; Ghouti, Lahouari",Software defect prediction using ensemble learning on selected features,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2014.07.005,2015,"Context: Several issues hinder software defect data including redundancy, correlation, feature irrelevance and missing samples. It is also hard to ensure balanced distribution between data pertaining to defective and non-defective software. In most experimental cases, data related to the latter software class is dominantly present in the dataset.Objective: The objectives of this paper are to demonstrate the positive effects of combining feature selection and ensemble learning on the performance of defect classification. Along with efficient feature selection, a new two-variant (with and without feature selection) ensemble learning algorithm is proposed to provide robustness to both data imbalance and feature redundancy.Method: We carefully combine selected ensemble learning models with efficient feature selection to address these issues and mitigate their effects on the defect classification performance.Results: Forward selection showed that only few features contribute to high area under the receiver-operating curve (AUC). On the tested datasets, greedy forward selection (GFS) method outperformed other feature selection techniques such as Pearson's correlation. This suggests that features are highly unstable. However, ensemble learners like random forests and the proposed algorithm, average probability ensemble (APE), are not as affected by poor features as in the case of weighted support vector machines (W-SVMs). Moreover, the APE model combined with greedy forward selection (enhanced APE) achieved AUC values of approximately 1.0 for the NASA datasets: PC2, PC4, and MC1.Conclusion: This paper shows that features of a software dataset must be carefully selected for accurate classification of defective components. Furthermore, tackling the software data issues, mentioned above, with the proposed combined learning model resulted in remarkable classification performance paving the way for successful quality control. (C) 2014 Elsevier B.V. All rights reserved.",3,本文的目的是证明特征选择和集成学习相结合对缺陷分类性能的积极影响。在高效特征选择的基础上，提出了一种新的两变量(带和不带特征选择)集成学习算法，对数据不平衡和特征冗余都具有鲁棒性,软件缺陷数据存在冗余、相关性、特征不相关性和样本缺失等问题。在有缺陷的软件和无缺陷的软件之间，也很难保证数据的均衡分布。在大多数实验案例中，与后一类软件相关的数据主要存在于数据集中。,本文的目的是证明特征选择和集成学习相结合对缺陷分类性能的积极影响。在高效特征选择的基础上，提出了一种新的两变量(带和不带特征选择)集成学习算法，对数据不平衡和特征冗余都具有鲁棒性。,正向选择表明，只有少数特征对接受者工作曲线(AUC)下的高面积有贡献。在测试数据集上，贪婪前向选择(GFS)方法优于Pearson相关等其他特征选择技术。这表明功能非常不稳定。然而，像随机森林这样的集成学习器和所提出的算法，平均概率集成(APE)，不像加权支持向量机(w - svm)那样受到差特征的影响。此外，APE模型结合贪婪前向选择(enhanced APE)对NASA数据集PC2、PC4和MC1的AUC值约为1.0。结论:本文表明，必须仔细选择软件数据集的特征以准确分类缺陷组件。此外，使用所提出的组合学习模型处理上面提到的软件数据问题，产生了显著的分类性能，为成功的质量控制铺平了道路,,版本内,这些数据集由常用的软件指标组成，包括LOC、McCabe’s CC、Halstead’s length、Halstead’s volume、Halstead’s difficulty、总操作数(TNO)和分支计数(BC)。,"虽然特征选择提高了缺陷分类性能，但应该记住，它既没有解决数据不平衡的问题，也没有考虑错误分类不同类别的代价。
在缺陷分类问题中，选择不同的特征子集会产生高度不一致的性能。这种性能不一致主要是由于存在不良和冗余的特性。
Forward selection and greedy Forward selection(GFS)",Pearson’s correlation and Fisher’s criterion,GFS特征选择法比pearson和fisher方法选择的特征对模型性能有提高，作者也列出GFS选择的特征有哪些，可以作为优于其他指标的评判,Ant-1.7. Camel-1.6.  KC3 datasets.  MC1.  PC2.  PC4.,200-1988组件,公开,完成,JAVA/C/C++,平均概率集合法APE。这些分类器包括随机森林、梯度增强、随机梯度下降、w - svm、逻辑回归、多项朴素贝叶斯和伯努利朴素贝叶斯。,类级,故障倾向,AUC,实际上APE就是集百家之长，将多种算法的评判性能综合，减小误判的可能，作者先用所有数据训练以此得到APE预测成绩，然后再通过GFS选择后再训练，如果比之前的成绩高说明其性能较好具有鲁棒性
"Qu, Yu; Guan, Xiaohong; Zheng, Qinghua; Liu, Ting; Wang, Lidan; Hou, Yuqiao; Yang, Zijiang",Exploring community structure of software Call Graph and its applications in class cohesion measurement,JOURNAL OF SYSTEMS AND SOFTWARE,10.1016/j.jss.2015.06.015,2015,"Many complex networked systems exhibit natural divisions of network nodes. Each division, or community, is a densely connected subgroup. Such community structure not only helps comprehension but also finds wide applications in complex systems. Software networks, e.g., Class Dependency Networks, are such networks with community structures, but their characteristics at the function or method call granularity have not been investigated, which are useful for evaluating and improving software intra-class structure. Moreover, existing proposed applications of software community structure have not been directly compared or combined with existing software engineering practices. Comparison with baseline practices is needed to convince practitioners to adopt the proposed approaches. In this paper, we show that networks formed by software methods and their calls exhibit relatively significant community structures. Based on our findings we propose two new class cohesion metrics to measure the cohesiveness of object-oriented programs. Our experiment on 10 large open-source Java programs validate the existence of community structures and the derived metrics give additional and useful measurement of class cohesion. As an application we show that the new metrics are able to predict software faults more effectively than existing metrics. (C) 2015 Elsevier Inc. All rights reserved.",3,我们证明了由软件方法及其调用形成的网络表现出相对显著的社区结构。基于我们的发现，我们提出了两个新的类内聚度量来度量面向对象程序的内聚性。,许多复杂的网络系统表现出网络节点的自然划分。每个部门或社区都是一个紧密相连的子群体。这种社区结构不仅有助于理解复杂系统，而且在复杂系统中有广泛的应用。软件网络，如类依赖网络，是一类具有社区结构的网络，但其在函数或方法调用粒度上的特征尚未被研究，这对于评估和改进软件类内结构是有用的。此外，现有提出的软件社区结构的应用并没有直接与现有的软件工程实践进行比较或结合。需要与基线实践进行比较，以说服从业者采用建议的方法。,"在本文中，我们提出了两个新的基于社区结构的类内聚度量:smcc (Method Community cohesion)和mcec (Method Community Entropy cohesion)。MCC的基本思想是量化某个类的多少方法驻留在同一个社区中。对于MCEC，它使用信息熵的标准概念(Shannon, 2001)来量化一个类的所有方法在社区中的分布。与已有的度量方法相比，这两种度量方法为类内聚度量提供了一种新的、更系统的视角。",本文通过对10个广泛使用的开源Java软件系统的分析，采用4种社区检测算法，表明软件静态调用图通常呈现相对显著的社区结构。提出了两个类内聚度量。这两个指标基于类的方法在社区中的分布，因此可以反映类的内聚性。我们表明，建议的度量可以提供现有类内聚度量不能反映的类内聚的额外和有用的信息。在包含1500个类的4个开源程序的故障预测实验中，当单独使用所提出的指标时，它们的性能与现有指标相当。当评估度量标准的组合时，建议的度量标准通常比现有的度量标准提供更好的结果。,,版本内,"在本案例研究中，有14个独特的度量(五个先前的类内聚度量、LOC、四个版本的MCC和四个版本的MCEC)。
Method Community Cohesion (MCC):
Method Community Entropy Cohesion (MCEC)
COH
LCOM1 2 5
LSCC",,"本文实现了四种广泛使用的社区检测算法。其中，快速贪婪(fg)是基于模块化的贪婪优化(Clauset et al.， 2004);infomap (im)基于Rosvall和Bergstrom(2008)提出的infomap方法检测网络的社区结构;标签传播(label propagation, lp)是Raghavan等人(2007)提出的一种快速分区算法;multilevel (ml)是Blondel等人(2008)提出的一种分层、自下而上的社区检测算法。",基于这些实验结果，我们可以看到MCC和MCEC在单变量逻辑回归中单独使用时，通常与现有指标相比具有相同的性能;在多变量逻辑回归中，MCC和MCEC与其他指标结合使用时，通常为故障预测提供了额外的有用信息，在多变量逻辑回归中，它们通常优于现有指标。,用于故障预测的有4个数据集,3w-15wSLOC,公开,完成,JAVA,逻辑回归,类级,故障倾向,Precision、Recall和F-measure,四种联系检测方法与提出的两个度量相关，相当于每个度量拥有4中不同的定义，用到后面的故障检测中
"Chatzis, Sotirios P.; Andreou, Andreas S.",Maximum Entropy Discrimination Poisson Regression for Software Reliability Modeling,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,10.1109/TNNLS.2015.2391171,2015,"Reliably predicting software defects is one of the most significant tasks in software engineering. Two of the major components of modern software reliability modeling approaches are: 1) extraction of salient features for software system representation, based on appropriately designed software metrics and 2) development of intricate regression models for count data, to allow effective software reliability data modeling and prediction. Surprisingly, research in the latter frontier of count data regression modeling has been rather limited. More specifically, a lack of simple and efficient algorithms for posterior computation has made the Bayesian approaches appear unattractive, and thus underdeveloped in the context of software reliability modeling. In this paper, we try to address these issues by introducing a novel Bayesian regression model for count data, based on the concept of max-margin data modeling, effected in the context of a fully Bayesian model treatment with simple and efficient posterior distribution updates. Our novel approach yields a more discriminative learning technique, making more effective use of our training data during model inference. In addition, it allows of better handling uncertainty in the modeled data, which can be a significant problem when the training data are limited. We derive elegant inference algorithms for our model under the mean-field paradigm and exhibit its effectiveness using the publicly available benchmark data sets.",3,在本文中，我们试图通过引入一种新的计数数据贝叶斯回归模型来解决这些问题，该模型基于最大边际数据建模的概念，在完全贝叶斯模型处理的背景下，通过简单有效的后验分布更新来实现。我,"相当多的研究工作致力于软件度量的设计和提取
大多数研究都是基于朴素泊松广义线性模型(pGLM)。
正如在这些作品中所显示的那样，与简单的pglm类型模型相比，使用高级贝叶斯回归模型进行计数数据的基于度量的软件可靠性建模可以显著提高性能",在这项工作中，我们引入了一个用于计数回归建模的分层贝叶斯模型，该模型利用最大边际原则的优势来学习将软件度量映射到预测的错误计数的函数。 ,正如我们所展示的，我们的方法比基线替代方案和最近提出的最先进的方法产生了显著的改进。,,跨版本,"Change Metrics.
Source Code Metrics：基于CK度量套件[9]，并可选择添加一些进一步的面向对象(OO)度量
Entropy of Changes Metrics
Entropy of Source Code Metrics.",,,正如我们从上面的演示中观察到的那样，在大多数情况下，我们的方法在统计上比竞争对手有显著的改进，但CK和OO指标除外，所有方法产生的结果都令人失望。 ,"Eclipse JDT Core
Equinox framework
Mylyn","997
439
2196",公开,完成,JAVA,分层贝叶斯,类级别,故障数量,"性能评估是基于预测和实际故障数量之间的均方根误差(RMSE)。
通过Wilcoxon sign -rank检验，我们的方法与考虑的竞争对手的性能差异",
"Lee, Taek; Nam, Jaechang; Han, Donggyun; Kim, Sunghun; In, Hoh Peter",Developer Micro Interaction Metrics for Software Defect Prediction,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,10.1109/TSE.2016.2550458,2016,"To facilitate software quality assurance, defect prediction metrics, such as source code metrics, change churns, and the number of previous defects, have been actively studied. Despite the common understanding that developer behavioral interaction patterns can affect software quality, these widely used defect prediction metrics do not consider developer behavior. We therefore propose micro interaction metrics (MIMs), which are metrics that leverage developer interaction information. The developer interactions, such as file editing and browsing events in task sessions, are captured and stored as information by Mylyn, an Eclipse plug-in. Our experimental evaluation demonstrates that MIMs significantly improve overall defect prediction accuracy when combined with existing software measures, perform well in a cost-effective manner, and provide intuitive feedback that enables developers to recognize their own inefficient behaviors during software development.",3,我们提出了微交互度量(mim)，它是利用开发人员交互信息的度量,然而，尽管理解开发人员的行为交互会影响软件质量，但目前可用的CMs源代码度量和hm变更历史度量并没有处理开发人员的行为。开发人员在开发过程中可能会犯无效或低效的习惯;因此，可能会引入缺陷。因此，在构建缺陷预测模型时，利用开发人员交互信息是可取的。研究开发人员的行为是长期开发不可或缺的一部分,为此，我们提出了微交互指标来捕捉开发人员在开发过程中的行为交互。我们使用Mylyn，这是一个用于任务上下文存储和恢复的Eclipse插件[21]。因为开发人员交互模式会影响软件质量和开发人员的生产力[18]，[19]，[20]，基于开发人员交互的度量可以成为预测缺陷的重要指标。在本文中，我们比较了在2005年12月至2010年6月期间使用包含Mylyn数据的Eclipse子项目的mim、CMs和hm的缺陷预测性能。我们的评估结果表明，当与CMs和hm一起使用时，mim显著提高了整体预测精度(第5.1节)。此外，就所需的工作而言，它们以一种经济有效的方式促进了代码检查，通过相当大的缺陷检测提供了显著的好处(第5.2节)。此外，我们获取并比较了来自两个不同领域(开源与闭源项目)的MIM，以探索MIM在预测贡献方面的排名差异(第6.4节)。,在本文中，我们提出并评估了用于改进缺陷分类性能的MIMs。我们的评估结果表明，当与现有的度量标准套件(CM?HM)一起使用时，mim显著地促进了缺陷分类性能的提高;即，从F-measure (m - ? cm - ? hm vs . cm - ? hm)来看，从0.313到0.494平均改善了大约157%;表9)此外，mim被证明能够经济有效地促进代码检查;也就是说，59%的缺陷可以通过检查由基于mim的缺陷预测模型指定的有限源代码的21%来检测(图7)。,,项目内,"24个Micro Interaction Metrics
42个源代码度量
15个变更历史度量",我们使用基于关联的特征子集(CFS)[59]进行特征选择。使用CFS是为了解决相关特征之间的多重共线性问题[49]。CFS是一种算法，用于搜索分类问题中特征之间没有不相关和冗余的特征子集的更大的缩减尺寸[60]。对于我们的目的，CFS可以用来选择一个适当大小的有效指标子集，从而避免模型构建过拟合问题。CFS通过考虑每个指标的单独预测能力以及它们之间的冗余程度来评估指标子集的价值。与有bug的类高度相关而具有低相互相关性的指标子集是首选的。,,MIM类别中最好的预测指标是nummeditingdevelopers(处理单个文件的开发人员数量)。对于代码质量预测，这个指标是一个很好的指标，用于确定历史上是否有许多开发人员分配和更改了文件。此外，nummeditevent、NumRareEdit、HourPerBrowsing和HourPerEditing指标是预测代码质量的其他良好指标。根据开发人员更改代码的时间和频率，代码的质量很可能会下降。此外，在处理很少访问的文件(NumRareEdit)时，开发人员可能会犯错误(传播bug)。,"4个数据集
3个商业数据集",3077个文件,公开/商业,完成,JAVA,朴素贝叶斯、逻辑回归、决策树和随机森林等其他机器学习算法建立了预测模型,文件级,故障倾向,"precision, recall, and F-measure",
"Arar, Omer Faruk; Ayan, Kursat",Deriving thresholds of software metrics to predict faults on open source software: Replicated case studies,EXPERT SYSTEMS WITH APPLICATIONS,10.1016/j.eswa.2016.05.018,2016,"Object-oriented metrics aim to exhibit the quality of source code and give insight to it quantitatively. Each metric assesses the code from a different aspect. There is a relationship between the quality level and the risk level of source code. The objective of this paper is to empirically examine whether or not there are effective threshold values for source code metrics. It is targeted to derive generalized thresholds that can be used in different software systems. The relationship between metric thresholds and fault proneness was investigated empirically in this study by using ten open-source software systems. Three types of fault-proneness were defined for the software modules: non-fault-prone, more-than-one-fault prone, and more-than-three-fault-prone. Two independent case studies were carried out to derive two different threshold values. A single set was created by merging ten datasets and was used as training data by the model. The learner model was created using logistic regression and the Bender method. Results revealed that some metrics have threshold effects. Seven metrics gave satisfactory results in the first case study. In the second case study, eleven metrics gave satisfactory results. This study makes contributions primarily for use by software developers and testers. Software developers can see classes or modules that require revising; this, consequently, contributes to an increment in quality for these modules and a decrement in their risk level. Testers can identify modules that need more testing effort and can prioritize modules according to their risk levels. (C) 2016 Elsevier Ltd. All rights reserved.",3,本文利用10个开源软件系统，对度量阈值与故障倾向性之间的关系进行了实证研究。,获得这些指标的阈值将有助于项目开发人员、测试人员和客户。开发人员可以在发布软件版本之前专注于阈值超越模块。另一方面，客户通常没有足够的软件知识来判断源代码的质量，他们可以在这些阈值的帮助下形成对质量的意见。阈值用于将实例分为两组，以便根据其类别对每个样本采取行动。,本文的目的是实证地检查源代码度量是否存在有效的阈值。它的目标是推导出可以在不同的软件系统中使用的广义阈值。本文以10个开源软件系统为研究对象，对度量阈值与故障倾向之间的关系进行了实证研究。为软件模块定义了三种类型的故障易感性:非故障易感性、多故障易感性和多故障易感性。进行了两个独立的案例研究，以得出两个不同的阈值。通过合并10个数据集创建单个集，并将其用作模型的训练数据。采用logistic回归和Bender方法建立了学习者模型。,结果显示，一些指标具有阈值效应。在第一个案例研究中，七个指标给出了令人满意的结果。在第二个案例研究中，11个度量给出了令人满意的结果。,,跨版本,我们使用了大量的度量标准，包括不同的度量标准组，以及CK套件。,,,RFC指标给出了比其他指标更好的结果，27个测试集中有17个的g平均值高于0.6。RFC和LOC指标的阈值往往更一般化，因此可以应用于其他类似的软件系统。CBO、WMC和Ce分别排在其后。,10个来自promise的数据集,19-428KLOC,公开,完成,JAVA,逻辑回归,类级,故障倾向,g-mean,
"Chatterjee, Subhashis; Maji, Bappa",A new fuzzy rule based algorithm for estimating software faults in early phase of development,SOFT COMPUTING,10.1007/s00500-015-1738-x,2016,"Estimation of reliability and the number of faults present in software in its early development phase, i.e., requirement analysis or design phase is very beneficial for developing reliable software with optimal cost. Software reliability prediction in early phase of development is highly desirable to the stake holders, software developers, managers and end users. Since, the failure data are unavailable in early phase of software development, different reliability relevant software metrics and similar project data are used to develop models for early software fault prediction. The proposed model uses the linguistic values of software metrics in fuzzy inference system to predict the total number of faults present in software in its requirement analysis phase. Considering specific target reliability, weightage of each input software metrics and size of software, an algorithm has been proposed here for developing general fuzzy rule base. For model validation of the proposed model, 20 real software project data have been used here. The linguistic values from four software metrics related to requirement analysis phase have been considered as model inputs. The performance of the proposed model has been compared with two existing early software fault prediction models.",3,该模型利用模糊推理系统中软件度量的语言值来预测软件在需求分析阶段存在的故障总数。,根据工程原理，在软件生命周期的早期阶段检测到故障总是更好的。这里的早期阶段是指需求分析和设计阶段。在软件开发的早期阶段，估计故障和可靠性的主要限制是软件故障数据的不可用性。因此，对于软件开发早期阶段的可靠性分析，必须依赖于不同的、与可靠性相关的软件度量标准(rrsm)、类似或更早的项目数据和专家意见。由于存在模糊和不精确的数据，上述用于软件早期故障预测的模型无法提供准确的结果。软件度量的状态和专家意见也受软件工程师的成熟度、知识和学习程度的影响。因此，模糊数可以较好地表示软件指标和专家意见，而不是清晰值,本文提出了一种基于模糊if-then规则的软件故障预测新算法，用于软件生命周期早期，特别是需求阶段的故障预测。建议的SRGM是使用rrsm开发的。rrsm在需求分析阶段是可度量的。在确定了输入和输出度量之后，利用所提出的新算法，可以从任意数量的输入软件度量中推导出输出度量的语言值，同时考虑软件的目标可靠性、每个输入软件度量的相对重要性和软件规模。将输出度量的去模糊化值用于预测软件中存在的预期故障数。,现有模型相比，该模型具有更好的故障预测能力。现有模型的性能分析采用了不同的比较标准。该模型对软件工程师和研究人员在软件开发的需求阶段进行故障预测具有重要的指导意义。,,版本内,需求阶段的4种度量,,,,20个项目,0.9-154KLOC,私有,完成,C,模糊规则,项目,故障数量,"Root mean square error (RMSE)
Normalized root mean square error (NRMSE)
Mean magnitude of relative error (MMRE)
Co-efficient of determination (R2)",
"Arvanitou, Elvira-Maria; Ampatzoglou, Apostolos; Chatzigeorgiou, Alexander; Avgeriou, Paris",Software metrics fluctuation: a property for assisting the metric selection process,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2015.12.010,2016,"Context: Software quality attributes are assessed by employing appropriate metrics. However, the choice of such metrics is not always obvious and is further complicated by the multitude of available metrics. To assist metrics selection, several properties have been proposed. However, although metrics are often used to assess successive software versions, there is no property that assesses their ability to capture structural changes along evolution.Objective: We introduce a property, Software Metric Fluctuation (SMF), which quantifies the degree to which a metric score varies, due to changes occurring between successive system's versions. Regarding SMF, metrics can be characterized as sensitive (changes induce high variation on the metric score) or stable (changes induce low variation on the metric score).Method: SMF property has been evaluated by: (a) a case study on 20 OSS projects to assess the ability of SMF to differently characterize different metrics, and (b) a case study on 10 software engineers to assess SMF's usefulness in the metric selection process.Results: The results of the first case study suggest that different metrics that quantify the same quality attributes present differences in their fluctuation. We also provide evidence that an additional factor that is related to metrics' fluctuation is the function that is used for aggregating metric from the micro to the macro level. In addition, the outcome of the second case study suggested that SMF is capable of helping practitioners in metric selection, since: (a) different practitioners have different perception of metric fluctuation, and (b) this perception is less accurate than the systematic approach that SMF offers.Conclusions: SMF is a useful metric property that can improve the accuracy of metrics selection. Based on SMF, we can differentiate metrics, based on their degree of fluctuation. Such results can provide input to researchers and practitioners in their metric selection processes. (C) 2015 Elsevier B.V. All rights reserved.",3,我们引入了一个属性，软件度量波动(SMF)，它量化了由于连续系统版本之间发生的变化而导致度量分数变化的程度。关于SMF，度量可以被描述为敏感(变化导致度量分数的高变化)或稳定(变化导致度量分数的低变化),软件质量属性是通过使用适当的度量来评估的。然而，这些度量标准的选择并不总是显而易见的，并且由于大量可用的度量标准而进一步复杂化。为了帮助选择度量标准，提出了几个属性。然而，尽管度量标准经常被用来评估连续的软件版本，但是没有任何属性可以评估它们在进化过程中捕获结构变化的能力。,我们引入了一个属性，软件度量波动(SMF)，它量化了由于连续系统版本之间发生的变化而导致度量分数变化的程度。关于SMF，度量可以被描述为敏感(变化导致度量分数的高变化)或稳定(变化导致度量分数的低变化)。方法:SMF属性通过以下方式进行评估:(a)对20个OSS项目进行案例研究，以评估SMF以不同方式描述不同度量的能力，以及(b)对10个软件工程师进行案例研究，以评估SMF在度量选择过程中的有用性。,第一个案例研究的结果表明，量化相同质量属性的不同度量在其波动方面存在差异。我们还提供证据表明，与指标波动相关的另一个因素是用于从微观到宏观层面聚合指标的函数。此外，第二个案例研究的结果表明，SMF能够帮助从业者选择公制，因为:(a)不同的从业者对公制波动有不同的感知，(b)这种感知不如SMF提供的系统方法准确。结论:SMF是一个有用的度量属性，可以提高度量选择的准确性。基于SMF，我们可以根据它们的波动程度来区分度量。这样的结果可以为研究人员和从业者在他们的度量选择过程中提供输入。,,跨版本,两个度量工具箱van Koten and Gray和QMOOD,,如果某人的目标是敏感指标，最好的选择是MAX或SUM聚合(分别为50%和44%)，而AVG很少产生敏感结果。另一方面，如果有人对稳定指标感兴趣，应该选择AVG，因为它在83.3%的情况下产生稳定的结果。从这些观察我们可以得出结论，不同的聚合函数可以应用于同一度量，并改变特定度量的波动特性。特别是对于源代码度量，MAX函数似乎提供了更敏感的结果。这个结果可以被认为是直观的，因为与设计级度量相比，源代码度量更容易改变，并且从版本到版本产生更大的变化。例如，行数的变化比类或方法数量的变化更频繁，绝对值也更大。因此，度量变化最大值的可能性在源代码度量中比在设计级度量中更高。,"研究结果表明，源代码度量原则上比设计级度量更敏感，并且当与不同的聚合函数一起使用时，存在特定的度量可以为所研究的质量属性提供敏感和稳定的度量。
",20个项目,>300个类,公开,完成,JAVA,无,无,无,我们估计软件度量波动属性SMF，作为“每对连续版本之间的差比与零的平均偏差”mf,没有进行软件故障预测，而是提出一个新的度量，衡量软件度量在版本之间的波动，即其敏感度和稳定性，用mf这个值来比较，使用不同聚合方式对mf有影响
"Chen, Lin; Ma, Wanwangying; Zhou, Yuming; Xu, Lei; Wang, Ziyuan; Chen, Zhifei; Xu, Baowen",Empirical analysis of network measures for predicting high severity software faults,SCIENCE CHINA-INFORMATION SCIENCES,10.1007/s11432-015-5426-3,2016,"Network measures are useful for predicting fault-prone modules. However, existing work has not distinguished faults according to their severity. In practice, high severity faults cause serious problems and require further attention. In this study, we explored the utility of network measures in high severity fault-proneness prediction. We constructed software source code networks for four open-source projects by extracting the dependencies between modules. We then used univariate logistic regression to investigate the associations between each network measure and fault-proneness at a high severity level. We built multivariate prediction models to examine their explanatory ability for fault-proneness, as well as evaluated their predictive effectiveness compared to code metrics under forward-release and cross-project predictions. The results revealed the following: (1) most network measures are significantly related to high severity fault-proneness; (2) network measures generally have comparable explanatory abilities and predictive powers to those of code metrics; and (3) network measures are very unstable for cross-project predictions. These results indicate that network measures are of practical value in high severity fault-proneness prediction.",3,我们探讨了网络测量在高严重故障倾向预测中的效用。通过提取模块间的依赖关系，构建了四个开源项目的软件源代码网络。,基于网络的分析将模块视为节点，将模块之间的依赖关系提取为边，构建软件源代码网络。然后，利用得到的网络测度建立预测模型。通过考虑模块之间的交互，网络度量描述了软件系统的信息流和总体拓扑结构，而这些是代码度量无法捕获的。然而，现有的网络测量工作并没有检验它们的故障严重程度预测能力。,在这项研究中，我们探讨了网络测量在高严重故障倾向预测中的效用。通过提取模块间的依赖关系，构建了四个开源项目的软件源代码网络。然后，我们使用单变量逻辑回归来研究每个网络测量与高严重程度的故障倾向之间的关联。我们建立了多变量预测模型来检查它们对错误倾向的解释能力，以及与前发布和跨项目预测下的代码度量相比，评估它们的预测有效性。,"结果表明:(1)大多数网络措施与高严重故障倾向性显著相关;(2)网络度量通常具有与代码度量相当的解释能力和预测能力;(3)网络测度对于跨项目预测是非常不稳定的。这些结果表明，网络方法在高级别故障倾向预测中具有实用价值
在这项研究中，我们只调查了网络测量在将模块分类为易故障或不易故障的背景下的实际有用性。因此，需要进一步检查它们根据易出错概率对模块进行排序的能力。此外，不稳定的跨项目预测激发了进一步的研究，以调查其潜在原因，并探索如何使用网络度量来提高预测性能。",,跨版本/跨项目,"一些全局度量仅使用传入或传出边计算，分别表示为IN和OUT。总的来说，我们探索了53个网络测量(36个en和17个GNs)在高严重故障倾向预测中的有用性。
在本研究中，代码度量用于为我们的预测模型提供性能基线。我们应用了三种广泛使用的代码度量:大小度量、结构复杂性度量和Halstead度量[21]。Chidamber和Kemerer[22]给出的一组面向对象指标(CK指标)，包括CBO、RFC、LCOM、NOC、DIT和WMC，应用于Java项目。因此，分别为所有版本的C/ c++项目和Java项目计算了17和22个代码度量。",,例如，用Firefox构建的预测模型移植到Ant时表现非常差。这种糟糕的性能可能是由源代码结构、编程语言和软件大小的差异造成的。这一结果为特征选择在缺陷预测中的重要性提供了补充证据[31]，特别是跨项目预测[32]。,我们不能证明网络度量比代码度量更有效地预测高严重性故障。更具体地说，在大多数情况下，网络度量的预测能力等于代码度量的预测能力。ENs和GNs的预测能力没有实质性差异。因此，我们得出结论，在易错性预测中，直接和间接依赖关系应同等对待。另一方面，同时使用ENs和GNs并没有提高预测效果。然而，与单独使用ENs或GNs相比，ENs和GNs的结合(即NMs)可以增强解释能力。,4个数据集多个版本,41-2881kLOC,公开,完成,JAVA/C++,逻辑回归,类/文件级,故障倾向,"Sensitivity = tp/(tp + f n).
Specificity = tn/(tn+f p)
Area under the ROC curve (AUC)",
"Wang, Junjie; Wang, Qing",Analyzing and predicting software integration bugs using network analysis on requirements dependency network,REQUIREMENTS ENGINEERING,10.1007/s00766-014-0215-x,2016,"Complexity, cohesion and coupling have been recognized as prominent indicators of software quality. One characterization of software complexity is the existence of dependency relationships. Moreover, the degree of dependency reflects the cohesion and coupling between software elements. Dependencies in the design and implementation phase have been proven to be important predictors of software bugs. We empirically investigated how requirements dependencies correlate with and predict software integration bugs, which can provide early estimates regarding software quality and thus facilitate decision making early in the software lifecycle. We conducted network analysis on the requirements dependency networks of three commercial software projects. Significant correlation is observed between most of our network measures and the number of bugs. Furthermore, many network measures demonstrate significantly greater values for higher severity (or a higher fixing workload). Afterward, we built bug prediction models using these network measures and found that bugs can be predicted with high accuracy and sensitivity, even in cross-project and cross-company contexts. We further identified the dependency type that contributes most to bug correlation, as well as the network measures that contribute more to bug prediction. These observations show that the requirements dependency network can be used as an early indicator and predictor of software integration bugs.",3,我们使用这些网络度量建立了bug预测模型，并发现即使在跨项目和跨公司的环境中，也可以以很高的准确性和灵敏度预测bug。我们进一步确定了对bug相关性贡献最大的依赖类型，以及对bug预测贡献更大的网络度量。,"以往的研究利用需求内容进行bug预测[19,22]，没有考虑需求之间的依赖关系。因此，这项研究可以为需求依赖对软件质量的潜在影响提供重要的新见解。",我们用来自两家软件公司的三个商业软件项目来研究需求依赖关系是如何与软件bug相关联并预测它们的。结果表明，需求依赖关系与软件缺陷相关，可以作为缺陷预测的预测因子。预测需求的潜在缺陷在项目管理中扮演着重要的角色，或者通过强调在开发过程中增加质量监控的需要，或者通过使用模型来计划验证和确认活动。此外，我们的工作预测了在软件开发的早期阶段，甚至在编码之前出现的错误。因此，我们的方法可以作为现有的基于代码的预测模型的有用补充,"我们在需求依赖网络上的大多数网络度量都与bug的数量显著相关，并且中心和高度连接的需求更容易出现bug(第4.1节)。?许多网络测量，主要与连接和中心性有关，对于更高的严重性(或固定工作量)显示出更大的值(第4.2节，4.3节)。?网络度量的相关效应在不同类型的需求依赖之间存在差异，依赖的约束类型对bug指示的贡献更大(4.1.1节)。
我们的研究结果还表明，需求依赖网络上的网络度量可以从以下几个方面预测软件bug，具有较高的预测性能:?需求依赖网络上的网络度量可以预测bug的数量，具有较高的准确性和灵敏度(第5.2节)。?预测模型可以应用于跨项目和跨公司环境，其预测性能与项目内预测相当(第5.3、5.4节)。?WeakComp、close和betweness是bug预测的重要预测因子，这表明具有高中心性和连接性的需求更容易出现bug(第5.5节)。",,跨版本/跨项目,网络度量,,,"，WeakComp、close和betweness对于预测bug的数量非常重要。这一结果与调用和数据流依赖网络中的观察结果大致一致[38]。此外，这三种方法可以用于错误预测，具有较高的准确性和灵敏度。它们在回归模型中的正系数表明，WeakComp、close和betweness值的增加可能对应于bug数量的增加。封闭性和间接性是中心性度量，表示从不同角度的“中心位置”;
弱比较、接近度和中间度是bug预测的重要指标。这个结果表明，中心和高度连接的需求比松散连接的需求和位于网络周围区域的需求更容易出现bug",我们的研究问题是基于中国两个中型软件组织的三个项目进行调查的。他们已经建立了稳定的开发和维护过程，并且已经达到了CMMI(能力成熟度模型集成)成熟度级别3或4。在本文的其余部分，我们使用“项目A”、“项目B”和“项目C”来表示它们。,未知,私有,完成,未知,线性回归,文件级,故障数量,"我们用准确性和灵敏度来评估线性回归模型的预测能力。为了准确性，我们计算了均方误差(MSE)。它量化了预测的bug数量和实际的bug数量之间的差异。
在敏感性方面，我们计算了预测的bug数量和实际的bug数量之间的Spearman相关系数。和前面一样，值越接近-1或?1、两项指标的相关性越强。",用私有数据集无法进行复现
"Punitha, K.; Latha, B.",SAMPLING IMBALANCE DATASET FOR SOFTWARE DEFECT PREDICTION USING HYBRID NEURO-FUZZY SYSTEMS WITH NAIVE BAYES CLASSIFIER,TEHNICKI VJESNIK-TECHNICAL GAZETTE,10.17559/TV-20151219112129,2016,"Software defect prediction (SDP) is a process with difficult tasks in the case of software projects. The SDP process is useful for the identification and location of defects from the modules. This task will tend to become more costly with the addition of complex testing and evaluation mechanisms, when the software project modules size increases. Further measurement of software in a consistent and disciplined manner offers several advantages like accuracy in the estimation of project costs and schedules, and improving product and process qualities. Detailed analysis of software metric data also gives significant clues about the locations of possible defects in a programming code. The main goal of this proposed work is to introduce software defects detection and prevention methods for identifying defects from software using machine learning approaches. This proposed work used imbalanced datasets from NASA's Metrics Data Program (MDP) and software metrics of datasets are selected by using Genetic algorithm with Ant Colony Optimization (GACO) method. The sampling process with semi supervised learning Modified Co Forest method generates the balanced labelled using imbalanced datasets, which is used for efficient software defect detection process with machine learning Hybrid Neuro-Fuzzy Systems with Naive Bayes methods. The experimental results of this proposed method proves that this defect detecting machine learning method yields more efficiency and better performance in defect prediction result of software in comparison with the other available methods.",3,这项工作的主要目标是引入软件缺陷检测和预防方法，以使用机器学习方法从软件中识别缺陷。采用遗传算法和蚁群优化(GACO)方法选择数据集的软件指标,在软件项目中，软件缺陷预测(SDP)是一个任务艰巨的过程。SDP过程对于从模块中识别和定位缺陷是有用的。当软件项目模块规模增加时，随着复杂测试和评估机制的增加，这项任务的成本将趋于增加。以一致和规范的方式对软件进行进一步的度量提供了几个优点，比如项目成本和进度估计的准确性，以及改进产品和过程质量。对软件度量数据的详细分析也提供了关于编程代码中可能存在缺陷的位置的重要线索。,这项工作的主要目标是引入软件缺陷检测和预防方法，以使用机器学习方法从软件中识别缺陷。本研究采用美国国家航空航天局(NASA)计量数据计划(MDP)的不平衡数据集，采用遗传算法和蚁群优化(GACO)方法选择数据集的软件指标。采用半监督学习改进Co森林方法的采样过程利用不平衡数据集生成平衡标记，将其用于基于朴素贝叶斯方法的机器学习混合神经模糊系统的高效软件缺陷检测过程。,实验结果表明，与现有的缺陷检测机器学习方法相比，该方法在软件缺陷预测结果方面具有更高的效率和更好的性能。,,版本内,LOC、Halstead、Mccabe,基于遗传蚁群优化(GACO)和套袋的特征选择,,,NASA’s Metrics Data Program (MDP),1k-5k,公开,完成,C,朴素贝叶斯,模块级,故障倾向,"Accuracy, precision and recall,F-measure",只与一个算法进行了性能比较，且用的都是NASA小样本数据集，提出的算法优势不一定很高
"Liu, Wangshu; Liu, Shulong; Gu, Qing; Chen, Jiaqiang; Chen, Xiang; Chen, Daoxu",Empirical Studies of a Two-Stage Data Preprocessing Approach for Software Fault Prediction,IEEE TRANSACTIONS ON RELIABILITY,10.1109/TR.2015.2461676,2016,"Software fault prediction is a valuable exercise in software quality assurance to best allocate limited testing resources. Classification is one of the effective methods for software fault prediction. The classification models are trained based on the datasets obtained by mining software historical repositories. However, the performance of the models depends on the quality of datasets. In this paper, we propose a novel two-stage data preprocessing approach which incorporates both feature selection and instance reduction. Specifically, in the feature selection stage, we first perform relevance analysis, and then propose a threshold-based clustering method, called novel threshold-based clustering algorithm, to conduct redundancy control. In the instance reduction stage, we apply random under-sampling to keep the balance between the faulty and non-faulty instances. In empirical studies, we chose datasets from real-world software projects, such as Eclipse and NASA. Then we compared our approach with some classical baseline methods, and further investigated the influencing factors in our approach. The final results demonstrate the effectiveness of our approach, and provide a guideline for achieving cost-effective data preprocessing when using our two-stage approach.",3,本文提出了一种结合特征选择和实例约简的两阶段数据预处理方法。具体而言，在特征选择阶段，我们首先进行相关性分析，然后提出一种基于阈值的聚类方法，称为新阈值聚类算法，进行冗余控制。在,然而，据我们所知，在软件故障预测中，将特征选择和实例约简结合起来以提高数据质量的研究很少。在本文中，我们提供了一种新的两阶段数据预处理方法。在特征选择方面，首先进行相关性分析，剔除不相关特征，然后提出基于阈值的聚类算法进行冗余控制，剔除冗余特征。例如减少实例，我们应用随机欠采样来减少NFP实例，以保持两类之间的平衡。,本文提出了一种结合特征选择和实例约简的两阶段数据预处理方法。具体而言，在特征选择阶段，我们首先进行相关性分析，然后提出一种基于阈值的聚类方法，称为新阈值聚类算法，进行冗余控制。在实例缩减阶段，我们采用随机欠采样来保持故障和非故障实例之间的平衡。在实证研究中，我们选择了来自现实世界软件项目的数据集，比如Eclipse和NASA。并将该方法与经典基线法进行了比较，进一步探讨了该方法的影响因素。,对于特征选择，NTC可以有效地去除冗余特征，同时保留相关特征。在用于聚类特征的相似函数中，非线性的对称不确定性被证明是最好的，特别是当与IG和CS结合使用时。这一结论与Yu和Liu[48]的研究结果一致，认为软件测度之间存在非线性相关性。相似度阈值需要根据数据集设置，但是对于较大的阈值范围(例如0.4到1.0)，结果性能相当稳定。阈值越大，选择的特征越多。例如约简，随机欠采样技术被证明是有用的，并且可以应用于其他特征选择方法并获得有益的结果，而过采样技术不适合，至少对于软件数据集。随机抽样在实验中是有效的，因为我们发现数据集中实例之间的相似性通常很高(例如，SU测量的平均实例相似性在几乎所有数据集中都大于0.9)。,,版本内,"LOC, Halstead complexity metrics, and McCabe complexity metrics
每个Eclipse数据集包含155个特性，包括代码复杂性度量(如LOC、循环复杂性和类的数量)、基于语法树的度量，以及许多其他特性",为了衡量特征与类的相关性，我们应该度量它们之间的相关性。常用的度量可以分为三组:基于熵的(如信息增益、增益比和对称不确定性)、基于统计的(如卡方)和基于实例的(如Relief和ReliefF)。在我们的方法中，我们从每组中选择一个代表，每个代表在软件故障预测中都被证明是好的[42]。这些测量是信息增益(IG)、卡方(CS)和缓解(RF)。,"为了衡量任意一对特征之间的相似度，我们选择非线性相似度度量对称不确定性(Symmetric Uncertainty, SU)[45]，以及常用的线性相似度度量余弦相似度(COS)。","此外，数据预处理可以大大减少特征数量(高达89%)和原始数据集的实例数量(高达60%)，这将简化分类器的训练过程。特征选择有助于提高之后构建的分类模型的预测性能。此外，像NTC（The novel threshold-based clustering algorithm）这样的冗余控制工具(在所有方法中导致最佳性能)对于构建用于训练分类器的适当特征集是有价值的。
非线性的对称不确定性被证明是最好的，特别是当与IG和CS结合使用时。这一结论与Yu和Liu[48]的研究结果一致，认为软件测度之间存在非线性相关性information gain (IG), chi-square (CS)",eclipse，NASA,"6700-10000个类
125-10000个方法",公开,完成,"JAVA
C",模型为朴素贝叶斯(NB)、C4.5决策树(C4.5)和k近邻(，记为IB1)。,类级/方法级,故障倾向,AUC,
"Zhang, Feng; Hassan, Ahmed E.; McIntosh, Shane; Zou, Ying",The Use of Summation to Aggregate Software Metrics Hinders the Performance of Defect Prediction Models,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,10.1109/TSE.2016.2599161,2017,"Defect prediction models help software organizations to anticipate where defects will appear in the future. When training a defect prediction model, historical defect data is often mined from a Version Control System (VCS, e.g., Subversion), which records software changes at the file-level. Software metrics, on the other hand, are often calculated at the class-or method-level (e.g., McCabe's Cyclomatic Complexity). To address the disagreement in granularity, the class-and method-level software metrics are aggregated to file-level, often using summation (i.e., McCabe of a file is the sum of the McCabe of all methods within the file). A recent study shows that summation significantly inflates the correlation between lines of code (SLOC) and cyclomatic complexity (CC) in Java projects. While there are many other aggregation schemes (e.g., central tendency, dispersion), they have remained unexplored in the scope of defect prediction. In this study, we set out to investigate how different aggregation schemes impact defect prediction models. Through an analysis of 11 aggregation schemes using data collected from 255 open source projects, we find that: (1) aggregation schemes can significantly alter correlations among metrics, as well as the correlations between metrics and the defect count; (2) when constructing models to predict defect proneness, applying only the summation scheme (i.e., the most commonly used aggregation scheme in the literature) only achieves the best performance (the best among the 12 studied configurations) in 11 percent of the studied projects, while applying all of the studied aggregation schemes achieves the best performance in 40 percent of the studied projects; (3) when constructing models to predict defect rank or count, either applying only the summation or applying all of the studied aggregation schemes achieves similar performance, with both achieving the closest to the best performance more often than the other studied aggregation schemes; and (4) when constructing models for effort-aware defect prediction, the mean or median aggregation schemes yield performance values that are significantly closer to the best performance than any of the other studied aggregation schemes. Broadly speaking, the performance of defect prediction models are often underestimated due to our community's tendency to only use the summation aggregation scheme. Given the potential benefit of applying additional aggregation schemes, we advise that future defect prediction models should explore a variety of aggregation schemes.",3,在这项研究中，我们着手研究不同的聚合方案如何影响缺陷预测模型。,缺陷预测模型帮助软件组织预测将来缺陷会出现在哪里。当训练缺陷预测模型时，历史缺陷数据通常是从版本控制系统(VCS，例如Subversion)中挖掘出来的，它在文件级别记录软件更改。另一方面，软件度量通常是在类或方法级别计算的(例如，McCabe的圈复杂度)。为了解决粒度上的分歧，类级和方法级的软件度量被聚合到文件级，通常使用求和(例如，文件的McCabe是文件中所有方法的McCabe的总和)。最近的一项研究表明，在Java项目中，总和显著地夸大了代码行数(Sloc)和圈复杂度(Cc)之间的相关性。虽然存在许多其他的聚合方案(例如，集中趋势，分散)，但它们在缺陷预测的范围内仍然未被探索。,因此，我们开始研究不同的聚合方案对缺陷预测模型的影响。我们使用从255个开源项目收集的数据进行了大规模实验。首先，我们研究了不同的聚合方案对以下方面的影响:(a)软件度量之间的相关性，因为强相关的软件度量可能是冗余的，并且可能相互干扰;(b)软件度量和缺陷计数之间的关联，确定缺陷预测模型的候选预测者。其次，我们研究了不同的聚合方案对四种缺陷预测模型性能的影响,通过对来自255个开源项目数据的11个聚合方案的分析，我们发现:(1)聚合方案可以显著地改变度量之间的相关性，以及度量与缺陷数之间的相关性;(2)在构建缺陷倾向性预测模型时，仅应用求和方案(即文献中最常用的聚合方案)仅在11%的研究项目中获得最佳性能(12种研究配置中最佳)，而应用所有研究的聚合方案在40%的研究项目中获得最佳性能;(3)在构建预测缺陷等级或缺陷计数的模型时，无论是只应用总和还是全部应用所研究的聚合方案，都可以获得相似的性能，且两者都比其他所研究的聚合方案更接近最佳性能;(4)在构建努力感知缺陷预测模型时，平均或中位数聚合方案产生的性能值明显接近于任何其他所研究的聚合方案的最佳性能。一般来说，由于我们的社区倾向于只使用求和聚合方案，缺陷预测模型的性能经常被低估。,,版本内,6个方法级别的度量,spearman相关性分析,我们介绍了将方法级指标聚合到文件级的11种聚合方案,"
聚合可以显著地改变所研究的度量之间的相关性，以及所研究的度量与缺陷计数之间的相关性。
总和方案(即，文献中最常用的聚合方案)可以显著低估用所研究的度量建立的缺陷预测模型的预测能力。
在被研究的系统中，缺陷计数与求和度量有很大的相关性(表6)，可以理解的是，对于预测缺陷计数，求和将是一个很好的聚合方案。
在预测缺陷倾向或努力感知模型的模型中，单独使用求和很少会导致最佳性能，在这些模型中，分别推荐使用所有方案和使用平均值/中位数。此外，使用所有的方案仍然有利于缺陷等级模型，特别是对于用C和c++编写的项目。在预测缺陷数的模型中，仅使用求和可能就足够了。事实上，应用所有方案是一个低成本的选择，值得尝试。",在本研究中，我们用Mockus收集的数据集[47]。该数据集包含在SourceForge和GoogleCode上托管的235K开源系统。过滤一部分后得到共255个系统,2900-32000文件,公开,完成,C/C++/C#/JAVA,"随机森林/线性回归
",文件级,故障倾向/故障数量/故障严重程度,AUC、MSE,
"Kumar, Lov; Misra, Sanjay; Rath, Santanu Ku.",An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes,COMPUTER STANDARDS & INTERFACES,10.1016/j.csi.2017.02.003,2017,"Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low - 48.89%, median- 39.26%, and high - 27.86%).",3,在这项工作中，我们提出了一个框架来验证源代码度量并识别一组合适的源代码度量，目的是减少不相关的特征并提高故障预测模型的性能。,软件故障预测模型用于在软件开发生命周期的早期阶段预测故障模块。使用源代码度量预测故障倾向是一个吸引了许多研究人员注意的领域。评估故障倾向的模型的性能取决于源代码度量，这些度量被认为是模型的输入。,我们提出了一个框架来验证源代码度量并识别一组合适的源代码度量，目的是减少不相关的特征并提高故障预测模型的性能。最初，我们对每个源代码指标应用t检验分析和单变量逻辑回归分析，以评估它们预测故障倾向的潜力。接下来，我们进行了相关分析和多元线性回归逐步向前选择，以找到适合故障预测的源代码度量集。将获得的源代码度量集作为输入，利用五种不同的训练算法和三种不同的集成方法建立神经网络的故障预测模型。利用提出的成本评估框架对所建立的故障预测模型的有效性进行了评估。我们在56个开源Java项目上进行了实验。,实验结果表明，与所有其他度量相比，使用建议的源代码度量验证框架作为输入，考虑选定的源代码度量集所开发的模型获得了更好的结果。实验结果还表明，根据故障识别效率(低- 48.89%，中值- 39.26%，高- 27.86%)，该故障预测模型最适合故障类别小于阈值的工程。,,项目内,20个软件度量,"t-test 单变量逻辑回归(ULR)分析
相互关联分析，多元线性回归逐步前向选择",在所有的训练算法中，LM的训练效果较好，即神经网络与Levenberg Marquardt (LM)训练方法开发的模型效果较好。非线性集成决策树森林(NDTF)方法优于最佳训练集成(BTE)和多数投票集成(MVE)方法。,"故障预测模型的有效性和有用性取决于软件测量数据的质量[16];因此，选择一组合适的源代码度量就成为模型开发过程中不可或缺的组成部分。
在所有情况下，与使用所有指标开发的模型相比，通过考虑使用拟议的软件指标验证技术作为输入的选定指标集开发的模型产生更好的性能，即在预测可靠性方面给出较高的准确性和F-Measure值。
Ce、CAM、Avg-CC、Ca和WMC源代码度量被发现是使用我们的源代码度量验证方法进行故障预测的重要预测因子",56个项目,9-2738个类,公开,完成,面向对象语言,"使用异构集成模型，里面包括5种不同算法的神经网络
非线性集成决策树森林(NDTF)方法、最佳训练集成(BTE)和多数投票集成(MVE)，线性判别用来预测故障",类级别,故障倾向,"accuracy，F-measure评估度量选择性能
成本评估模型",?齐次集成方法:在这种方法中，所有考虑的基础学习器(即分类模型)都是相同类型的，但每个学习器都有一个随机生成的训练集。?异构集成方法:在该方法中，所有考虑的基础学习器(即分类模型)都是不同类型的。基于组合规则，集成方法可以进一步分为两类。这些类别是:?线性集成方法:在这种方法中，仲裁器以线性方式组合基本学习器的输出，即分类模型，如平均，训练中最佳，加权平均等。?非线性集成方法:在这种方法中，考虑的基本学习器的输出，即分类模型，被馈送到一个仲裁器，这是一个非线性预测模型，如神经网络，决策树森林(DTF)等。
"Yohannese, Chubato Wondaferaw; Li, Tianrui",A Combined-Learning Based Framework for Improved Software Fault Prediction,INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS,10.2991/ijcis.2017.10.1.43,2017,"Software Fault Prediction (SFP) is found to be vital to predict the fault-proneness of software modules, which allows software engineers to focus development activities on fault-prone modules, thereby prioritize and optimize tests, improve software quality and make better use of resources. In this regard, machine learning has been successfully applied to solve classification problems for SFP. Nevertheless, the presence of different software metrics, the redundant and irrelevant features and the imbalanced nature of software datasets have created more and more challenges for the classification problems. Therefore, the objective of this study is to independently examine software metrics with multiple Feature Selection (FS) combined with Data Balancing (DB) using Synthetic Minority Oversampling Techniques for improving classification performance. Accordingly, a new framework that efficiently handles those challenges in a combined form on both Object Oriented Metrics (OOM) and Static Code Metrics (SCM) datasets is proposed. The experimental results confirm that the prediction performance could be compromised without suitable Feature Selection Techniques (FST). To mitigate that, data must be balanced. Thus our combined technique assures the robust performance. Furthermore, a combination of Random Forts (RF) with Information Gain (IG) FS yields the highest Receiver Operating Characteristic (ROC) curve (0.993) value, which is found to be the best combination when SCM are used, whereas the combination of RF with Correlation-based Feature Selection (CFS) guarantees the highest ROC (0.909) value, which is found to be the best choice when OOM are used. Therefore, as shown in this study, software metrics used to predict the fault proneness of the software modules must be carefully examined and suitable FST for software metrics must be cautiously selected. Moreover, DB must be applied in order to obtain robust performance. In addition to that, dealing with the challenges mentioned above, the proposed framework ensures the remarkable classification performance and lays the pathway to quality assurance of software.",3,本研究的目的是使用合成少数派过采样技术，独立检查多特征选择(FS)结合数据平衡(DB)的软件指标，以提高分类性能。,软件故障预测(SFP)对于预测软件模块的故障倾向是至关重要的，它允许软件工程师将开发活动集中在有故障倾向的模块上，从而优先考虑和优化测试，提高软件质量，更好地利用资源。在这方面，机器学习已经成功地应用于解决SFP的分类问题。然而，不同软件度量的存在、冗余和不相关的特征以及软件数据集的不平衡性给分类问题带来了越来越多的挑战。,本研究的目的是使用合成少数派过采样技术，独立检查多特征选择(FS)结合数据平衡(DB)的软件指标，以提高分类性能。因此，本文提出了一种新的框架，可以在面向对象度量(OOM)和静态代码度量(SCM)数据集上以组合形式有效地处理这些挑战。,实验结果证实，如果没有合适的特征选择技术(FST)，预测性能可能会受到影响。为了缓解这种情况，必须平衡数据。因此，我们的组合技术保证了鲁棒性。此外，随机堡(RF)与信息增益(IG) FS的组合产生最高的接收者工作特征(ROC)曲线值(0.993)，这被发现是使用SCM时的最佳组合，而RF与基于相关性的特征选择(CFS)的组合保证了最高的ROC值(0.909)，这被发现是使用OOM时的最佳选择。因此，如本研究所示，必须仔细检查用于预测软件模块故障倾向的软件度量，并谨慎选择适合软件度量的FST。此外，为了获得健壮的性能，必须应用DB。,,版本内,Chidamber and Kemerer’s (CK) Object Oriented Metrics (OOM) and McCabe and Halstead Static Code Metrics (SCM),相关性的特征(CFS)，主成分分析(PCA)和信息增益(IG)。两种软件度量的合适FST是不同的。在我们的案例中，IG和CFS技术分别适用于SCM和OOM。,,"一般来说，使用IG选择的特征已经被证明能够提高分类器的ROC值。因此，IG成为mc1 SCM更好的FST。FST和DB的组合可以提高性能。
这里的发现证实，不仅分类器之间的性能不一致，而且在应用特征数量较少的IG FS时观察到的性能改进
在这个OOM中观察到的另一个有趣的发现是，使用CFS选择的特征已被证明能够提高分类器的ROC值。
这重申，如果FST不够合适，无论选择和/或组合的指标如何，预测性能都可能受到损害。
然而，考虑到8个分类器的平均性能，IG(0.835)优于其他FST，其次是CFS(0.824)和PCA(0.805)。因此，我们发现在LC组合指标的情况下，IG FST比CFS和PCA FST更适合。",6个数据集,119k-998kLOC,公开,完成,JAVA/C,朴素贝叶斯(NB)、神经网络(NN)、支持向量机(SVM)、随机森林(RF)、k -近邻(KNN)、决策表(DTa)、决策树(DTr)和随机树(RTr)，,类/模块,故障倾向,AUC,
"Yu, Qiao; Jiang, Shu-juan; Wang, Rong-cun; Wang, Hong-yang",A feature selection approach based on a similarity measure for software defect prediction,FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING,10.1631/FITEE.1601322,2017,"Software defect prediction is aimed to find potential defects based on historical data and software features. Software features can reflect the characteristics of software modules. However, some of these features may be more relevant to the class (defective or non-defective), but others may be redundant or irrelevant. To fully measure the correlation between different features and the class, we present a feature selection approach based on a similarity measure (SM) for software defect prediction. First, the feature weights are updated according to the similarity of samples in different classes. Second, a feature ranking list is generated by sorting the feature weights in descending order, and all feature subsets are selected from the feature ranking list in sequence. Finally, all feature subsets are evaluated on a k-nearest neighbor (KNN) model and measured by an area under curve (AUC) metric for classification performance. The experiments are conducted on 11 National Aeronautics and Space Administration (NASA) datasets, and the results show that our approach performs better than or is comparable to the compared feature selection approaches in terms of classification performance.",3,为了充分度量不同特征与类之间的相关性，提出了一种基于相似性度量(SM)的软件缺陷预测特征选择方法。,软件缺陷预测的目的是根据历史数据和软件特性发现潜在的缺陷。软件特性可以反映软件模块的特性。然而，其中一些特征可能与类更相关(有缺陷的或无缺陷的)，但其他特征可能是多余的或不相关的。,"提出了一种基于相似性度量的特征选择方法，用于软件缺陷预测。在我们的方法中，我们设计了一种特征排序算法，根据不同类别样本的相似度更新特征权重，并通过对特征权重降序排序得到特征排序列表。然后，我们按顺序从特征排序列表中选择所有特征子集，并在k最近邻(Aha et al.， 1991)模型上对它们进行评估。使用接收者工作特征曲线下面积(AUC)度量(Huang and Ling, 2005)来衡量分类性能。最后，我们在11个美国国家航空航天局(NASA)的数据集上进行了实验，并与其他特征选择方法进行了比较，以证明我们的方法的有效性。",在11个美国国家航空航天局(NASA)的数据集上进行了实验，结果表明，我们的方法在分类性能方面优于或与所比较的特征选择方法相当。,"通常，特征选择方法可分为特征排序和特征子集选择两种，输出结果不同。特征排名的目的是评估特征的价值，并生成特征排名列表
特征子集选择是结合搜索算法选择最优的特征子集。基于关联的特征选择(Hall, 1999)是最常用的特征子集选择方法之一。它用于评估每个特征的个体预测能力和不同特征之间的冗余度。利用最优优先搜索算法和粒子群优化算法(PSO)获得最优特征子集。",项目内,"McCabe metrics (McCabe, 1976) and Halstead metrics (Halstead, 1977).","所提出的SM方法也是一种基于距离度量的特征加权方法，类似于ReliefF。然而，它们的特征加权方法是不同的。SM根据每个缺陷样本与其最近的非缺陷样本的特征差异更新特征权值，ReliefF根据随机样本在同一类和相反类中的最近邻居的特征差异更新特征权值。因此，它们的功能排名列表也不同。
",,"我们设计了实验来比较四种特征选择方法，即OneR、ReliefF、Correlation和Gain Ratio。OneR被设计用来通过OneR分类器评估特征的价值。ReliefF是一种基于距离度量的特征加权方法。相关性是通过计算不同特征与类之间的皮尔逊相关系数来衡量特征的重要性，增益比是通过信息增益比来评估特征的价值。这四种方法使用不同的方法来评估特征的价值。
我们可以得出SM明显优于OR和RF, SM与CL和GR相当。",NASA 11个数据集,125-7792样本,公开,完成,C,KNN,模块级,故障倾向,AUC,只用了knn分类器，在其他分类器上性能不一定好
"Ozturk, Muhammed Maruf",Which type of metrics are useful to deal with class imbalance in software defect prediction?,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2017.07.004,2017,"Context: There are various ways to cope with class imbalance problem which is one of the main issues of software defect prediction. Sampling algorithms are implemented on both industrial and open-source software defect prediction data sets by practitioners to wipe out imbalanced data points. Sampling algorithms, up-to-date, have been employed either static or process code metrics.Objective: In this study, sampling algorithms including Virtual, SMOTE, and HSDD (hybrid sampling for defect data sets) are explored using static code and quality metrics together. Our goal is not only to lead practitioners to decide the type of the metrics in defect prediction but also provide useful information for developers to design less defective software projects.Method: We ran sampling experiments with three sampling algorithms on ten data sets (from GitHub). Feature selection is applied on large features of the data sets. Using five classifiers, the performance of the data sets after sampling is compared with initial data sets. Regression analyzes are implemented on quality metrics to find the most influential metrics for detecting defect proneness.Results: Regardless of the type of the sampling, prediction performances are similar. Quality metrics surpassed static code metrics with respect to training times and prediction accuracies.Conclusion: Using quality metrics yields better prediction results rather than static code metrics in imbalanced data sets. As the count of project cloning increases, the number of defects decreases. Thus, approaches, related to the class imbalance, should be evaluated not only in terms of static code metrics but also for quality metrics. (C) 2017 Elsevier B.V. All rights reserved.",3,在这项研究中，包括Virtual、SMOTE和HSDD(缺陷数据集的混合采样)在内的采样算法一起使用静态代码和质量度量来探索。对质量度量进行回归分析，以找到检测缺陷倾向最具影响力的度量。,类不平衡问题是软件缺陷预测的主要问题之一，解决类不平衡问题的方法多种多样。从业者在工业和开源软件缺陷预测数据集上实现了采样算法，以消除不平衡的数据点。采样算法，最新的，已经被采用静态或过程代码度量。,在这项研究中，包括Virtual、SMOTE和HSDD(缺陷数据集的混合采样)在内的采样算法一起使用静态代码和质量度量来探索。我们的目标不仅是引导从业者在缺陷预测中决定度量标准的类型，而且还为开发人员设计更少缺陷的软件项目提供有用的信息。方法:在10个数据集(来自GitHub)上使用3种采样算法进行采样实验。特征选择应用于数据集的大特征。使用五个分类器，将采样后的数据集与初始数据集的性能进行比较。对质量度量进行回归分析，以找到检测缺陷倾向最具影响力的度量。,结果:无论哪种类型的样本，预测性能都是相似的。在训练时间和预测准确性方面，质量度量超过了静态代码度量。结论:在不平衡的数据集中，使用质量度量比使用静态代码度量产生更好的预测结果。随着项目克隆数量的增加，缺陷的数量减少。因此，与类不平衡相关的方法不仅应该根据静态代码度量，而且应该根据质量度量来评估。,"影响预测模型的主要因素有四个。这些是研究小组，数据集的家族，分类器的类型。Mahmood等人[27]对这些因素进行了平衡，并进行了实验。根据他们的研究，研究小组和家庭数据集对SDP的影响相同，为31%。
Z. Mahmood, D. Bowes, P.C. Lane, T. Hall, What is the impact of imbalance on software defect prediction performance? in: Proceedings of the 11 t h International Conference on Predictive Models and Data Analytics in Software Engineering, ACM, 2015, p. 4, doi:10.1145/2810146.2810150.",项目内,静态度量和质量度量,我们使用主成分分析(PCA)[66]来减少数据集的特征数量。它采用线性映射来总结数据集的模式。PCA揭示了不相关的特征，并呈现了数据集的变化，以便我们能够从数据集中去除冗余特征。,静态代码的集群结构和进程度量是不同的。因此，聚类可以用于根据静态代码和流程度量来区分数据集。,就训练时间而言，预处理在质量度量方面比静态代码度量产生更好的结果。训练时间在其他数据集中也缩短了，但是这种减少在project_quality数据集中更为明显。另一方面，在5个分类器上的AUC和g-mean方面，质量度量比静态代码度量产生更好的结果。表9和表10详细列出了预测结果。根据这些结果，流程度量在五个预测因子中几乎产生了最好的结果。从单因素方差分析可以清楚地看出，这些分类器在统计上是不同的。,10个数据集,24k-1626kLOC,公开,完成,JAVA、Ruby、C++,我们使用LIBSVM、贝叶斯、朴素贝叶斯、随机森林和J48算法来比较质量代码和静态代码的成功,未知,故障倾向,使用AUC、g-mean和训练时间来比较预测性能。,影响类的类型确定的主要因素是度量值。例如，如果cyclomatic_complexity大于10，则表示存在缺陷。因此，具有此值的实例可以被标记为有缺陷。然而，另一个研究主题是哪个度量在标记中更有效[40-42]。
"Gupta, Dharmendra Lal; Saxena, Kavita",Software bug prediction using object-oriented metrics,SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES,10.1007/s12046-017-0629-5,2017,"Software quality is the fundamental requirement for a user, academia person, software developing organizations and researchers. In this paper a model for object-oriented Software Bug Prediction System (SBPS) has been developed. This model is capable of predicting the existence of bugs in a class if found, during software validation using metrics. The designed model forecasts the occurrences of bugs in a class when any new system is tested on it. For this experiment some open source similar types of defect datasets (projects) have been collected from Promise Software Engineering Repository. Some of these datasets have been selected for prediction of bugs, of which a few are not involved in model construction. First of all, we have formulated some hypotheses corresponding to each and every metric, and from metrics validation based on hypothesis basis finally 14 best suitable metrics have been selected for model creation. The Logistic Regression Classifier provides good accuracy among all classifiers. The proposed model is trained and tested on each of the validated dataset, including validated Combined Dataset separately too. The performance measure (accuracy) is computed in each case and finally it is found that the model provides overall averaged accuracy of 76.27%.",3,建立了面向对象的软件Bug预测系统模型。,大多数情况下，它被分为三大类:过程度量、产品度量和项目度量。过程度量用于改进软件开发和低产品可维护性，例如，开发过程中缺陷移除的有效性，修复过程的响应时间和缺陷到达的测试模式。产品度量标准处理产品的特征，如大小、复杂性、设计特征、产品中的质量水平和产品的性能，而项目度量标准涵盖了参与软件开发的员工数量、他们在整个软件生命周期中的人员配置模式、项目开发中产生的成本、管理的进度和获得的生产力[3]。,本文建立了面向对象的软件Bug预测系统模型。如果在软件验证过程中使用度量，该模型能够预测类中是否存在bug。当任何新系统在一个类上进行测试时，所设计的模型预测了类中错误的发生。对于这个实验，已经从Promise Software Engineering Repository中收集了一些开源的类似类型的缺陷数据集(项目)。其中一些数据集已被选择用于预测bug，其中一些不涉及模型构建。首先，我们为每个指标制定了相应的假设，并基于假设基础对指标进行验证，最后选择了14个最适合的指标进行模型创建。,逻辑回归分类器在所有分类器中具有较好的准确率。该模型在每个验证的数据集(包括验证的组合数据集)上分别进行了训练和测试。计算了每种情况下的性能度量(准确率)，最终发现该模型的总体平均准确率为76.27%。,,版本内,"20个面对对象的度量：WMC, DIT, NOC, CBO, RFC and LCOM [6], CA and CE [1], LOC and LCOM3 [17] and NPM, DAM, MOA, MFA, CAM, IC, CBM, AMC, MAX_CC and AVG-CC",模型中使用的度量是根据Pearson相关性进行验证和选择的。,,从假设验证中发现，该漏洞与指标WMC、CBO、RFC、LCOM、CA、CE、NPM、LCOM3、LOC、DAM、MOA、CAM、MAX_CC和AVG_CC高度相关。,本文选取了12个类似类型的开源项目(Camel1.6、Tomcat 6.0、Ant 1.7、jEdit4.3、Ivy 2.0、arc、e-learning、berek、forrest 0.8、Zuzel、Intercafe和Nieruchomosci)，这些项目都是其回顾版本的最新版本，收集自Promise软件工程存储库，,3597个实例,公开,完成,JAVA,14种不同的分类器:朴素贝叶斯、支持向量机(LivSVM)、逻辑回归、多层感知器、SGD(随机梯度下降)、SMO(顺序最小优化)、投票感知器、属性选择分类器、通过回归分类、Logit Boost、树决策印章、随机森林、随机树和REP(减少错误修剪)树,类级,故障倾向,accuracy,提出的方法比较简单，就是用不同数据集训练最后在训练集上预测，将OO度量减少了而已
"Ni, Chao; Liu, Wang-Shu; Chen, Xiang; Gu, Qing; Chen, Dao-Xu; Huang, Qi-Guo",A Cluster Based Feature Selection Method for Cross-Project Software Defect Prediction,JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY,10.1007/s11390-017-1785-0,2017,"Cross-project defect prediction (CPDP) uses the labeled data from external source software projects to compensate the shortage of useful data in the target project, in order to build a meaningful classification model. However, the distribution gap between software features extracted from the source and the target projects may be too large to make the mixed data useful for training. In this paper, we propose a cluster-based novel method FeSCH (Feature Selection Using Clusters of Hybrid-Data) to alleviate the distribution differences by feature selection. FeSCH includes two phases. The feature clustering phase clusters features using a density-based clustering method, and the feature selection phase selects features from each cluster using a ranking strategy. For CPDP, we design three different heuristic ranking strategies in the second phase. To investigate the prediction performance of FeSCH, we design experiments based on real-world software projects, and study the effects of design options in FeSCH (such as ranking strategy, feature selection ratio, and classifiers). The experimental results prove the effectiveness of FeSCH. Firstly, compared with the state-of-the-art baseline methods, FeSCH achieves better performance and its performance is less affected by the classifiers used. Secondly, FeSCH enhances the performance by effectively selecting features across feature categories, and provides guidelines for selecting useful features for defect prediction.",3,本文提出了一种基于聚类的新方法FeSCH (Feature Selection Using Clusters of Hybrid-Data)，通过特征选择来缓解分布差异。FeSCH包括两个阶段。特征聚类阶段使用基于密度的聚类方法对特征进行聚类，特征选择阶段使用排序策略从每个聚类中选择特征。,跨项目缺陷预测(CPDP)利用外部源软件项目的标记数据来弥补目标项目中有用数据的不足，从而构建有意义的分类模型。然而，从源项目和目标项目中提取的软件特征之间的分布差距可能太大，无法使混合数据对训练有用。,本文提出了一种新的CPDP特征选择方法FeSCH，该方法分为两个阶段。在特征聚类阶段，我们将冗余特征聚到多个聚类中。在特征选择阶段，我们从每个聚类中选择源项目和目标项目之间分布相似的特征来构建目标特征集。其中，FeSCH首先使用基于密度的聚类方法DPC (Density Peaks clustering)[7]将原始特征集划分为多个聚类。然后使用特定的排序策略从每个聚类中选择合适的特征。对于CPDP，我们在特征选择阶段设计了三种不同的启发式策略，分别是LDF(局部特征密度)、SFD(特征分布相似度)和FCR(特征类相关性)。,实验结果表明，FeSCH在大多数情况下优于其他基线方法，并且其性能不依赖于所训练的分类器。此外，还提供了在跨项目软件缺陷预测中选择合适特征的指导原则，包括最优排序策略、适合的特征选择比例以及有利的软件度量。,,跨项目,"ReLink有26个特性，可分为复杂度指标和计数指标。这些指标是基于代码复杂性(例如LOC、循环复杂性和类的数量)和抽象语法树(例如块的数量、语句的数量和方法引用)设计的。
AEEEM有61个度量标准，分为代码度量标准、过程度量标准和基于变化的度量标准。人工度量是使用熵等工具计算的。","我们提出了三种新的特征排序策略，即LDF(局部特征密度)、SFD(特征分布相似度)和FCR(特征类相关性)。
在LDF该策略中，使用局部密度度量来选择特征。局部密度是指一个特征周围邻居的数量，可以反映该特征的受欢迎程度或代表性。
在SFD策略中，特征是根据源和目标项目数据之间的分布相似度来选择的。我们使用MIC (maximum information coefficient，最大信息系数)[36]来度量两个分布的差异
FCR主要的假设是，与类标签密切相关的特征值得选择。在CPDP上下文中，由于目标数据没有类标签，我们使用IG(信息增益)来基于源数据度量特征到标签的相关性
LDF将源数据和目标数据作为一个整体进行组合，并选择具有代表性的特征。SFD对源数据和目标数据进行比较，选择两个数据集之间分布相似的特征。FCR只考虑源数据，并选择与类标签相关度高的特征。在实证研究中，我们将进一步比较这些排名策略。",,"SFD的平均性能最好(ReLink为0.65,AEEEM为0.51)，而LDF的平均性能最差(ReLink为0.49,AEEEM为0.46)。没有哪一种排序策略能在所有CPDP情况下都优于其他策略。这三种排名策略对FeSCH都是有效和有用的。SFD策略在我们的实验中表现更好，该策略是增加源项目和目标项目之间特征分布的相似性。LDF策略虽然表现最差，但在某些情况下仍有希望。
在ReLink中，FeSCH总是选择AvgCyclomaticModified和CountLineCodeExec。一般来说，从CountMetric (CTM)类别中选择的特征大多与CTM的良好性能相对应。在AEEEM上，在最受欢迎的特性中，基于源代码的特性(SCM、COSCM和EOSCM)大多被选中。然而，从选择比来看，基于变化的特征(EOCM)的熵占主导地位，因为5个EOCM特征中有3个出现在前表中。熵度量，挖掘连续软件版本之间的差异，是CPDP最有价值的。",ReLink and AEEEM,56-1862个实例,公开,完成,未知,考虑了三种分类器，包括基于概率的分类器朴素贝叶斯，基于决策树的分类器随机森林和基于函数的分类器逻辑回归。,类/文件级,故障倾向,precision、recall、F-measure、AUC,结果证明，特征选择对于CPDP至关重要，这与Nam等人的发现一致。[1]可能的原因是，不相关和冗余的特征会导致软件缺陷预测的严重性能下降，特别是在CPDP上下文中。分类器可能不会对CPDP上下文下的预测性能产生判别效应。研究人员应该注意为目标项目训练有用的缺陷预测者建立高质量的源数据。
"Kalsoom, Anum; Maqsood, Muazzam; Ghazanfar, Mustansar Ali; Aadil, Farhan; Rho, Seungmin",A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA),JOURNAL OF SUPERCOMPUTING,10.1007/s11227-018-2326-5,2018,"Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers-Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques-SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve.",3,我们进一步使用基于flda的特征选择方法，结合SMOTE和ressample来选择最具判别性的指标,软件质量是软件公司成功的一个重要因素。传统的软件质量保证技术面临着一些严重的限制，特别是在时间和预算方面。这导致越来越多地使用机器学习分类技术来预测软件故障。软件故障预测可以帮助开发人员在软件生命周期的早期阶段发现软件问题。这些技术在多大程度上可以推广到不同规模的软件、类不平衡问题和鉴别软件度量是最关键的挑战。,本研究论文的目标是(1)研究软件故障预测数据集大小对最广泛使用的机器学习分类器性能的影响(2)处理软件故障预测的类不平衡问题(3)使用Fisher线性判别分析(FLDA)的有效方法进行高效的特征选择和降维。在本文中，我们分析了贝叶斯网络、NB、人工神经网络、支持向量机、K近邻、AdaBoost、Bagging、Zero R和Random Forest这9种被广泛使用的机器学习分类器在软件故障预测中的性能。采用smote和带替换的Resample两种标准采样技术来处理类不平衡问题。我们进一步使用基于flda的特征选择方法，结合SMOTE和ressample来选择最具判别性的指标。然后将基于性能的前4个分类器用于软件故障预测。实验是在15个公开可用的数据集(小、中、大)上进行的，这些数据集是从PROMISE存储库收集的。,通过单独使用采样技术，机器学习分类器的性能得到了提高。重新取样替代比SMOTE表现更好。当两种采样技术分别使用FLDA时，获得了最好的结果。Resample- flda产生了最好的结果，优于所有其他方法(简单的Resample、简单的SMOTE和SMOTEFLDA)。所报道的结果优于现有的许多软件故障预测方法。,基于过滤器的方法根据特征和类标签之间的相关性选择最相关的特征。基于包装器的方法需要分类模型的反馈，并且需要迭代地选择特征向量，这可能导致较高的计算复杂度,版本内,LOC based metrics、Halsted metrics、McCabe metrics、Miscellaneous,Fisher线性判别分析(FLDA)：在本研究中，我们使用FLDA进行降维。它是一种监督降维方法，使用类标签来识别最具判别性的特征[28]。与主成分分析(PCA)等无监督降维方法不同，它只选择那些适合类标签的特征。对于软件故障预测，有两类;易故障和非易故障。因此，FLDA只选择那些有助于对上述类中的实例进行分类的特征。FLDA通过计算类标签内部和类标签之间的分散矩阵，将高维数据转换为低维数据;,SMOTE性能低下的原因是它创建和使用合成数据。因此，如果创建的数据是错误的，错误将进一步传播。,SMOTE-FLDA在所有数据集上的表现都非常好，这表明在SMOTE之后应用FLDA可以提高系统的性能。所有四个分类器表现出一致的性能。Resample-FLDA的结果甚至比SMOTE-FLDA更好,"我们使用了16个公开可用的数据集，包括Ar1, Ar3, AR4, AR5, AR6, CM1_req, jEdit-4.0_4.2, jEdit4.2_4.3, Kc1, Kc2, Kc3, Mc2, Mw1, Pc1, Pc2和Pc4 (http://promise.site.uottawa)。ca / SERepository / datasets-page.html)。",2-42kLOC,公开,完成,未知,贝叶斯、朴素贝叶斯(NB)、神经网络、支持向量机、KNN、AdaBoost、Bagging、Zero R和随机森林RF,模块级,故障倾向,"precision, recall, F1, AUC,",
"Choudhary, Garvit Rajesh; Kumar, Sandeep; Kumar, Kuldeep; Mishra, Alok; Catal, Cagatay",Empirical analysis of change metrics for software fault prediction,COMPUTERS & ELECTRICAL ENGINEERING,10.1016/j.compeleceng.2018.02.043,2018,"A quality assurance activity, known as software fault prediction, can reduce development costs arid improve software quality. The objective of this study is to investigate change metrics in conjunction with code metrics to improve the performance of fault prediction models. Experimental studies are performed on different versions of Eclipse projects and change metrics are extracted from the GIT repositories. In addition to the existing change metrics, several new change metrics are defined and collected from the Eclipse project repository. Machine learning algorithms are applied in conjunction with the change and source code metrics to build fault prediction models. The classification model with new change metrics performs better than the models using existing change metrics. In this work, the experimental results demonstrate that change metrics have a positive impact on the performance of fault prediction models, and high-performance models can be built with several change metrics. (C) 2018 Elsevier Ltd. All rights reserved.",3,本研究的目的是研究变更度量与代码度量的结合，以提高故障预测模型的性能。,研究人员还研究了软件度量阈值来建立预测模型和设计噪声检测技术[6]。这些研究表明，软件度量是构建高性能故障预测模型的重要组成部分之一。最近的一项工作[7]强调了在选择合适的软件故障预测模型时属于输入度量数据集的特征的重要性。出于这个原因，本文的作者关注于变更度量来提高模型的性能。最近的研究应用了与开发人员、组织度量[8]和网络度量相关的度量。,在本研究中，我们详细分析了变化度量对故障预测模型的影响。从软件存储库中提取几个变化指标，并使用机器学习算法(即决策树、k近邻和随机森林)构建模型。,结果表明，变更度量为故障预测器提供了额外的性能，并且它们补充了预测模型的静态代码度量。新引入的变更度量提高了模型的性能，并有助于构建高性能的故障预测器。分类结果显示，新的度量标准在召回方面提供了重要的提高，即比静态代码度量标准提高了大约10%，比现有的变更度量标准提高了大约23%。即使是很小的召回值的增加对于组织中可以节省的资源也是至关重要的。建议使用静态代码度量和更改度量的机器学习模型优于仅使用静态代码度量的模型。此外，我们观察到随机森林分类器提供了更好的精度值，但决策树(J48)和KNN分类器提供了更好的召回率和更好的总体f度量。对于跨项目预测模型，新的变更度量提供了对现有变更度量的改进，但是在大多数情况下，使用新变更度量和代码度量组合的模型执行得最好。因此，可以得出结论，在这项工作中提出的新的变化度量是有希望的，并且基于这些度量建立的模型提供了更好的预测结果。,"软件度量可以分为以下几种类型:?代码和复杂性度量[9-11]:复杂性度量表示代码块的复杂程度，众所周知，代码越复杂，该模块存在的漏洞和风险就越大。到目前为止，研究人员已经提出并应用了许多复杂性度量(例如，著名的Thomas McCabe的CC度量)，这些度量主要是基于源代码计算的。因此，我们将此类别显示为代码和复杂性度量。CC度量显示了该模块(方法/类/包)存在多少必须单独测试的独立路径。这些指标是直接来自软件的传统产品指标。代码度量的一些例子是代码行和注释行。复杂性度量的例子有系统复杂性、mccabab<e:1>圈复杂性和本质复杂性。如果在项目中使用C语言等过程性编程语言，McCabe和Halstead指标[12]是最受欢迎的。?面向对象的度量[13,14]:这些度量对于面向对象的编程范式是有效的，并且它们与特定的编程概念相关，例如继承、类、内聚和耦合。已经提出了几个面向对象的度量套件。最流行的是CK (Chidamber-Kemerer)指标套件。CK指标包括:加权方法计数(WMC)、对象类之间的耦合(CBO)、子类数量(NOC)、方法内聚不足(LCOM)、继承树深度(DIT)和类响应(RFC)。变更或过程度量标准[15-18]:这些度量标准与软件开发过程中所做的变更相关。它们在软件生命周期的多个版本中收集。一些过程度量是代码流失度量、变更爆发和代码增量。代码流失度量显示了代码发展的速度[19]。变化突发度量考虑了连续的变化序列[18]。代码增量度量根据特定度量(如代码行数)计算两个构建之间的差异。?开发人员指标[20,21]:这些指标与软件开发人员直接相关，并为为软件做出贡献的不同开发人员提取。这些指标包括修改模块的开发人员的累积数量，在所有版本中更改文件的开发人员的累积数量，以及开发人员G.R. Choudhary等人修改的代码行数。/计算机和电气工程67(2018)15-24 17?网络指标[22-24]:这些指标是用于故障预测的最新指标。网络度量是从不同实体之间的依赖关系中提取的。这些实体被视为图中的节点，并且使用这些实体之间的交互创建依赖关系图。网络分析在这个图上的应用提供了网络度量值，目的是找到依赖项和缺陷之间的关联。这些网络度量包括度中心性、接近中心性、中间中心性、特征向量中心性、大小度量、约束度量和自我网络度量。",跨版本,code and change metrics. 代码和变更度量,spearman相关性分析,,"与静态代码度量相比，新的变更度量的改进是非常显著的，例如，召回率和精确度都提高了10%。代码和变更度量的组合模型显示，J48分类器中的召回率显著提高，与v2.1中的变更度量相比，召回率提高了7%，与静态代码度量相比，召回率提高了16%。?组合模型在所有情况下都优于静态代码度量，在大多数情况下优于变更度量
就召回而言，在大多数情况下，静态代码比更改度量执行得更好。?具有新变更度量的分类模型在大多数情况下仍然比现有的变更度量表现更好，在使用v2.0训练和v2.1测试的模型中使用J48分类器，召回率提高高达7%。?在大多数情况下，与现有的变更度量和静态代码度量相比，新的变更度量在精度上也有了很好的改进。?静态代码和变更度量的组合模型比单独的模型执行得更好。","数据收集过程首先从链接https://git.eclipse.org/c/克隆Eclipse GIT存储库。Eclipse versions 2.0, 2.1, and 3.0.",,公开,完成,JAVA,决策树、k近邻和随机森林,类级maybe,故障倾向,"Precision (P), Recall (R) and F-Measure (F).",
"Huda, Shamsul; Alyahya, Sultan; Ali, Mohsin; Ahmad, Shafiq; Abawajy, Jemal; Al-Dossari, Hmood; Yearwood, John",A Framework for Software Defect Prediction and Metric Selection,IEEE ACCESS,10.1109/ACCESS.2017.2785445,2018,"Automated software defect prediction is an important and fundamental activity in the domain of software development. However, modern software systems are inherently large and complex with numerous correlated metrics that capture different aspects of the software components. This large number of correlated metrics makes building a software defect prediction model very complex. Thus, identifying and selecting a subset of metrics that enhance the software defect prediction method's performance are an important but challenging problem that has received little attention in the literature. The main objective of this paper is to identify significant software metrics, to build and evaluate an automated software defect prediction model. We propose two novel hybrid software defect prediction models to identify the significant attributes (metrics) using a combination of wrapper and filter techniques. The novelty of our approach is that it embeds the metric selection and training processes of software defect prediction as a single process while reducing the measurement overhead significantly. Different wrapper approaches were combined, including SVM and ANN, with a maximum relevance filter approach to find the significant metrics. A filter score was injected into the wrapper selection process in the proposed approaches to direct the search process efficiently to identify significant metrics. Experimental results with real defect-prone software data sets show that the proposed hybrid approaches achieve significantly compact metrics (i.e., selecting the most significant metrics) with high prediction accuracy compared with conventional wrapper or filter approaches. The performance of the proposed framework has also been verified using a statistical multivariate quality control process using multivariate exponentially weighted moving average. The proposed framework demonstrates that the hybrid heuristic can guide the metric selection process in a computationally efficient way by integrating the intrinsic characteristics from the filters into the wrapper and using the advantages of both the filter and wrapper approaches.",3,本文的主要目标是识别重要的软件度量，构建和评估一个自动化的软件缺陷预测模型。我们提出了两种新的混合软件缺陷预测模型，使用包装和过滤技术的组合来识别重要的属性(度量)。,自动化软件缺陷预测是软件开发领域中一项重要的基础性活动。然而，现代软件系统本质上是庞大而复杂的，具有许多捕获软件组件不同方面的相关度量。大量相关的度量使得构建软件缺陷预测模型变得非常复杂。因此，识别和选择度量的子集来增强软件缺陷预测方法的性能是一个重要但具有挑战性的问题，在文献中很少受到关注。,在本文中，我们提出了一种用于软件故障预测和度量选择的混合包装滤波方法。该方法的新颖之处在于我们引入了不同的包装启发式方法，并与过滤方法进行了混合。提出了基于包装启发式的支持向量机混合启发式和人工神经网络(ANN)混合启发式两种混合模型，并将其应用于软件缺陷数据的重要度量。这避免了包装器在寻找指标的最佳子集时产生的任何偏差的影响。,所提出的框架表明，混合启发式算法通过将滤波器的内在特征集成到包装器中，并利用滤波器和包装器方法的优点，可以以计算效率高的方式指导度量选择过程,过滤[15]和包装[16]方法都用于度量选择。过滤模型在数据集上使用启发式方法来减少整体搜索空间。过滤方法在其度量排序过程中不考虑性能评估，因为这通常在稍后进行。因此，所选子集在故障预测中的性能可能无法一直得到保证。此外，由于独立的特征评估而不考虑它们之间的相互作用，性能可能会受到影响。另一方面，包装器方法使用归纳算法来评估所选特征子集的性能。通常，对于m维度量数据集，包装器方法需要从2m子集空间中搜索以找到最重要的度量子集。因此，由于搜索空间呈指数增长，计算成本很高[17]。尽管包装器方法考虑了特征依赖性，但它们存在过度拟合的风险,版本内,不同的数据集具有不同的度量数最高37个静态度量,"，我们提出了一个混合模型，通过将过滤器的分数集成到包装器选择过程中，将两种方法混合在一起。因此，所提出的混合模型具有两种方法的优点。提出了两种不同的包装框架:1)基于人工神经网络的输入增益测量近似(ANNIGMA)[35] 2)基于支持向量机(SVM)的包装评分
最大相关性(MR)被认为是滤波器。",ANNIGMA、SVM分别与MR组合构成不同的混合模型进行比较,"混合技术优于包装器和过滤器方法。混合MR-SVM和MR-ANNIGMA的性能优于独立滤波和包装方法，
结果表明，混合模型MR-SVM的性能优于MR-ANNIGMA，这证明了我们提出的框架在找到最显著和最紧凑的子集的同时也能够找到合适的包装器",8个NASA数据集CM1、JM1、AR1、KC1、KC2、PC1、PC3和PC4。,,公开,完成,C,SVM和ANN,模块级,故障倾向,accuracies and AUC,
"Shao, Yuanxun; Liu, Bin; Wang, Shihai; Li, Guoqi",A novel software defect prediction based on atomic class-association rule mining,EXPERT SYSTEMS WITH APPLICATIONS,10.1016/j.eswa.2018.07.042,2018,"To ensure the rational allocation of software testing resources and reduce costs, software defect prediction has drawn notable attention to many white-box and black-box classification algorithms. Although there have been lots of studies on using software product metrics to identify defect-prone modules, defect prediction algorithms are still worth exploring. For instance, it is not easy to directly implement the Apriori algorithm to classify defect-prone modules across a skewed dataset. Therefore, we propose a novel supervised approach for software defect prediction based on atomic class-association rule mining (ACAR). It holds the characteristics of only one feature of the antecedent and a unique class label of the consequent, which is a specific kind of association rules that explores the relationship between attributes and categories. It holds the characteristics of only one feature of the antecedent and a unique class label of the consequent, which is a specific kind of association rules that explores the relationship between attributes and categories. Such association patterns can provide meaningful knowledge that can be easily understood by software engineers. A new software defect prediction model infrastructure based on association rules is employed to improve the prediction of defect-prone modules, which is divided into data preprocessing, rule model building and performance evaluation. Moreover, ACAR can achieve a satisfactory classification performance compared with other seven benchmark learners (the extension of classification based on associations (CBA2), Support Vector Machine, Naive Bayesian, Decision Tree, OneR, K-nearest Neighbors and RIPPER) on NASA MDP and PROMISE datasets. In light of software defect associative prediction, a comparative experiment between ACAR and CBA2 is discussed in details. It is demonstrated that ACAR is better than CBA2 in terms of AUC, G-mean, Balance, and understandability. In addition, the average AUC of ACAR is increased by 2.9% compared with CBA2, which can reach 81.1%. (C) 2018 Elsevier Ltd. All rights reserved.",3,我们提出了一种基于原子类关联规则挖掘(ACAR)的软件缺陷预测新方法,为了保证软件测试资源的合理分配和降低成本，软件缺陷预测引起了许多“白盒”和“黑盒”分类算法的关注。尽管已经有很多关于使用软件产品度量来识别容易出现缺陷的模块的研究，但是缺陷预测算法仍然值得探索。例如，在倾斜数据集上直接实现Apriori算法对容易出现缺陷的模块进行分类是不容易的。,在本研究中，我们提出了一种基于原子类关联规则挖掘(ACAR)的软件缺陷预测算法。ACAR是关联分类的扩展，它可以在考虑度量交互的同时消除不一致和冗余的原子规则。ACAR通过利用单个突出属性和目标类之间的关联关系来实现分类。原子规则是指前句和后句分别只包含一个属性或预定目标的规则，可以看作是一种特殊类型的关联规则。它采用IF-THEN形式的产生规则表示，如IF Cyclomatic complexity > 10 THEN defects = true。此外，ACAR在规则生成、规则修剪和分类方面不同于现有的经典关联算法。ACAR有三个特点。在规则生成阶段，采用新的缺陷预测框架，按类别生成关联规则，极大地解决了类不平衡导致的规则缺陷问题。在规则剪枝阶段，主要采用后剪枝策略去除特定规则、不一致规则和冗余规则。特别是对属性间交互产生的冗余规则进行修剪。据我们所知，该方法是第一个以正式方式提出的规则修剪方法。在规则预测阶段，它使用多个规则的支持值的总和进行预测，这有助于理解缺陷是如何与各种特征相关的。,在软件缺陷关联预测方面，详细讨论了ACAR与CBA2的对比实验。结果表明，ACAR在AUC、G-mean、Balance和可理解性方面优于CBA2。与CBA2相比，ACAR的平均AUC提高了2.9%，达到81.1%。,,版本内,未知,"the relief-based attribute evaluation filter method它根据属性和类之间的相关性为属性赋予不同的权重。如果属性的权重小于某个阈值，它将被删除。相关性是通过属性与最近实例的区分能力来计算的――Liu, W., Liu, S., Gu, Q., Chen, J., Chen, X., & Chen, D. (2016). Empirical studies of a two-stage data preprocessing approach for software fault prediction. IEEE Transactions on Reliability, 65(1), 38-53.",,,NASA MDP and PROMISE datasets.,101-10000模块,公开,完成,C/C++/JAVA/Perl,基于原子类关联规则发现的缺陷预测模型框架,模块级,故障倾向,recall，accuracy，AUC，G-mean and balance performance,
"Moustafa, Sammar; ElNainay, Mustafa Y.; El Makky, Nagwa; Abougabal, Mohamed S.",Software bug prediction using weighted majority voting techniques,ALEXANDRIA ENGINEERING JOURNAL,10.1016/j.aej.2018.01.003,2018,"Mining software repositories is a growing research field where rich data available in the different development software repositories, are analyzed and cross-linked to uncover useful information. Bug prediction is one of the potential benefits that can be gained through mining software repositories. Predicting potential defects early as they are introduced to the version control system would definitely help in saving time and effort during testing or maintenance phases. In this paper, defect prediction models that uses ensemble classification techniques have been proposed. The proposed models have been applied using different sets of software metrics as attributes of the classification techniques and tested on datasets of different sizes. The results show that change metrics outperform static code metrics and the combined model of change and static code metrics. Ensembles tend to be more accurate than their base classifiers. Defect prediction models using change metrics and ensemble classifiers have revealed the best performance, especially when the datasets used have imbalanced class distribution. (C) 2018 Faculty of Engineering, Alexandria University. Production and hosting by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",3,本文提出了一种基于集成分类技术的缺陷预测模型。所提出的模型已经使用不同的软件度量集作为分类技术的属性，并在不同规模的数据集上进行了测试。,挖掘软件存储库是一个不断发展的研究领域，通过分析和交叉链接不同开发软件存储库中可用的丰富数据来发现有用的信息。Bug预测是通过挖掘软件存储库可以获得的潜在好处之一。当潜在的缺陷被引入到版本控制系统时，尽早预测它们无疑有助于节省测试或维护阶段的时间和精力,我们使用集成分类器和不同的软件度量集构建了不同的模型，并使用不同大小的数据集对它们进行评估，以得出缺陷预测的最佳模型，特别是针对不平衡类分布的模型。所使用的集合基于加权多数投票技术。集成将一系列基本分类器组合在一起，目的是创建一个改进的复合分类模型。使用的度量是静态代码度量和变更度量。还应用了两种度量标准的组合模型。本研究的主要贡献是构建和评估基于加权多数投票技术的集成分类器与不同软件度量集的不同组合，以得出最佳的错误预测模型，用于具有不平衡类分布的现实软件开发数据集,本文给出的结果强烈支持使用变更度量和级联集成分类器构建缺陷预测器。变更度量比静态代码度量以及静态代码和变更度量的组合显示出更好的性能。结果还表明，集成分类器通过提高分类精度，解决了类不平衡数据集的问题。,,跨版本,静态代码度量标准，变更度量标准，以及它们的组合模型。,,,变更度量比静态代码度量以及静态代码和变更度量的组合显示出更好的性能。,来自Apache的四个项目,30-254kLOC,公开,完成,JAVA,朴素贝叶斯(NB)、决策树(C4.5)、逻辑回归(LR)、支持向量机(SVM)和随机森林(RF)。加权多数投票技术分别用3个分类器(NB、LR和C4.5)和5个分类器实现一次,文件级,故障倾向,F-measure，accuracy，AUC,
"Kaur, Arvinder; Chopra, Deepti",Entropy Churn Metrics for Fault Prediction in Software Systems,ENTROPY,10.3390/e20120963,2018,"Fault prediction is an important research area that aids software development and the maintenance process. It is a field that has been continuously improving its approaches in order to reduce the fault resolution time and effort. With an aim to contribute towards building new approaches for fault prediction, this paper proposes Entropy Churn Metrics (ECM) based on History Complexity Metrics (HCM) and Churn of Source Code Metrics (CHU). The study also compares performance of ECM with that of HCM. The performance of both these metrics is compared for 14 subsystems of 5different software projects: Android, Eclipse, Apache Http Server, Eclipse C/C++ Development Tooling (CDT), and Mozilla Firefox. The study also analyses the software subsystems on three parameters: (i) distribution of faults, (ii) subsystem size, and (iii) programming language, to determine which characteristics of software systems make HCM or ECM more preferred over others.",3,本文提出了基于历史复杂性度量(HCM)和源代码度量(CHU)的熵流失度量(ECM)。,故障预测是辅助软件开发和维护过程的一个重要研究领域。这是一个不断改进其方法以减少故障解决时间和工作量的领域。,为了建立故障预测的新方法，本文提出了基于历史复杂性度量(HCM)和源代码度量(CHU)的熵流失度量(ECM)。研究还比较了ECM和HCM的性能。这两个指标的性能在5个不同软件项目的14个子系统中进行了比较:Android、Eclipse、Apache Http Server、Eclipse C/ c++ Development tools (CDT)和Mozilla Firefox。该研究还分析了软件子系统的三个参数:(i)故障分布，(ii)子系统大小，(iii)编程语言，以确定软件系统的哪些特征使HCM或ECM比其他更受欢迎。,ECM对14个数据集中的4个给出了更好的结果，HCM对14个数据集中的6个给出了更好的结果，ECM和HCM对14个数据集中的4个给出了相同的结果。该研究进一步分析了软件子系统的特征，以便确定哪种度量更适合于哪种类型的软件系统。子系统分析基于三个参数，即(a)每年故障数量分布，(b)文件数量，(c)编程语言。从分析中可以推断，(a) HCM度量更适合于每年故障非正态分布的软件系统/子系统，(b) ECM度量更适合于中型和大型软件系统/子系统，(c) HCM度量更适合于使用c和c++编程的软件子系统/系统。,,跨版本,"
基于历史复杂性度量(HCM)和源代码度量(CHU)的熵流失度量(ECM)
软件系统的特征基于三个参数:(i)故障分布，(ii)系统大小，(iii)编程语言，以确定何时使用ECM优于HCM，反之亦然。",,,可以得出结论，HCM更适合于年故障非正态分布的子系统。对于中型和大型子系统，最好使用ECM，对于小型子系统，最好使用HCM。换句话说，当处理文件之间有大耦合的系统时，ECM是一个更好的预测器。可以建议HCM应该优先用于使用C和c++编程的软件子系统/系统。,"Android, Eclipse, Apache Http Server, Eclipse C/C++ Development Tooling (CDT), and Mozilla Firefox.",14-2063个文件,公开,完成,C/C++/JAVA,线性回归,文件级,故障数量,均方根误差(RMSE),
"Beranic, Tina; Podgorelec, Vili; Hericko, Marjan",Towards a Reliable Identification of Deficient Code with a Combination of Software Metrics,APPLIED SCIENCES-BASEL,10.3390/app8101902,2018,"Different challenges arise while detecting deficient software source code. Usually a large number of potentially problematic entities are identified when an individual software metric or individual quality aspect is used for the identification of deficient program entities. Additionally, a lot of these entities quite often turn out to be false positives, i.e., the metrics indicate poor quality whereas experienced developers do not consider program entities as problematic. The number of entities identified as potentially deficient does not decrease significantly when the identification of deficient entities is carried out by applying code smell detection rules. Moreover, the intersection of entities identified as allegedly deficient among different code smell detection tools is small, which suggests that the implementation of code smell detection rules are not consistent and uniform. To address these challenges, we present a novel approach for identifying deficient entities that is based on applying the majority function on the combination of software metrics. Program entities are assessed according to selected quality aspects that are evaluated with a set of software metrics and corresponding threshold values derived from benchmark data, considering the statistical distributions of software metrics values. The proposed approach was implemented and validated on projects developed in Java, C++ and C#. The validation of the proposed approach was done with expert judgment, where software developers and architects with multiple years of experiences assessed the quality of the software classes. Using a combination of software metrics as the criteria for the identification of deficient source code, the number of potentially deficient object-oriented program entities proved to be reduced. The results show the correctness of quality ratings determined by the proposed identification approach, and most importantly, confirm the absence of false positive entities.",3,我们提出了一种识别缺陷实体的新方法，该方法基于在软件度量的组合上应用多数函数。,在检测有缺陷的软件源代码时，会出现不同的挑战。通常，当单个软件度量或单个质量方面用于识别有缺陷的程序实体时，会识别出大量潜在的有问题的实体。此外，许多这些实体经常被证明是错误的，也就是说，这些指标表明质量很差，而有经验的开发人员并不认为程序实体有问题。当通过应用代码,为了解决这些挑战，我们提出了一种识别缺陷实体的新方法，该方法基于在软件度量的组合上应用多数函数。程序实体根据选择的质量方面进行评估，这些质量方面是用一组软件度量标准和从基准数据中得到的相应阈值进行评估的，考虑到软件度量标准值的统计分布。所提出的方法在Java、c++和c#开发的项目中得到了实现和验证。所建议的方法的验证是通过专家判断完成的，其中具有多年经验的软件开发人员和架构师评估了软件类的质量。使用软件度量的组合作为识别缺陷源代码的标准，潜在缺陷的面向对象程序实体的数量被证明是减少的。,结果表明，所提出的识别方法确定的质量评级是正确的，最重要的是，确认了假阳性实体的存在。,,版本内,"代码规模:SLOC、AMS、NOM
复杂性:WMC、ACC、NS
耦合性:CBO
内聚性:LCOM",,,,18个软件,76-19297类,公开,完成,JAVA/C++/C#,阈值和函数,类级,故障倾向,"accuracy, precision, recall and F-Measure",单纯使用了度量阈值，即某度量超过阈值就有理由认为该类潜在故障，同时通过多个度量组合函数确定故障倾向
"Arshad, Ali; Riaz, Saman; Jiao, Licheng; Murthy, Aparna",The Empirical Study of Semi-Supervised Deep Fuzzy C-Mean Clustering for Software Fault Prediction,IEEE ACCESS,10.1109/ACCESS.2018.2866082,2018,"Software fault prediction is a very consequent research topic for software quality assurance. The performance of fault prediction model depends on the features that are used to train it. Redundant and irrelevant features can hinder the performance of a classification model. In this paper, we propose an empirical study of two-stage data pre-processing technique on software fault prediction models. In the first stage, a novel semi-supervised deep Fuzzy C-Mean (DFCM) clustering-based feature extraction technique is proposed to create new features by utilizing deep multi-clusters of unlabeled and labeled data sets that tends to maximize intra-cluster class and intra-cluster feature by using FCM clustering. The FCM also utilizes to handle the class imbalance problem. In the second stage, we further ameliorate the prediction performance with coalescence of feature selection (using random-under sampling) to reduce the noisy data for classification. However, by the performance of the model results in the amalgamation of novel DFCM data pre-processing approach work better due to their ability to identify and amalgamation essential information in data features. An empirical study is designed on real-world software project (NASA & Eclipse) data set to evaluate the performance of DFCM by implemented different data pre-processing schemes on prediction models (C4.5, naive bayes, and 1-near neighbor (1-NN)), which are widely used in software fault prediction and further investigated the influencing factors in our approach. The result shows that the performance of the proposed DFCM feature extraction technique for data pre-processing is stable and effectiveness on all prediction models.",3,本文对软件故障预测模型的两阶段数据预处理技术进行了实证研究。在第一阶段，提出了一种基于半监督深度模糊c均值(DFCM)聚类的特征提取技术，,软件故障预测是软件质量保证领域一个非常重要的研究课题。故障预测模型的性能取决于所训练的特征。冗余和不相关的特征会阻碍分类模型的性能。,本文对软件故障预测模型的两阶段数据预处理技术进行了实证研究。在第一阶段，提出了一种基于半监督深度模糊c均值(DFCM)聚类的特征提取技术，利用未标记和标记数据集的深度多聚类来创建新的特征，该技术倾向于利用FCM聚类来最大化聚类内类和聚类内特征。FCM还用于处理类不平衡问题。在第二阶段，我们通过特征选择的合并(使用随机抽样)进一步改善预测性能，以减少噪声数据进行分类。然而，通过对模型结果进行融合的新型DFCM数据预处理方法由于能够识别和融合数据特征中的基本信息而工作得更好。以实际软件项目(NASA和Eclipse)数据集为研究对象，通过对广泛应用于软件故障预测的预测模型(C4.5、朴素贝叶斯和1-近邻(1-NN))实施不同的数据预处理方案，对DFCM的性能进行了评价，并进一步探讨了影响我们方法的因素。,该方法在所有预测模型上都具有最佳的AUC测量值。但与C4.5和1-NN相比，NB预测模型使用我们提出的基于RUS的DFCM特征提取方法获得了较好的AUC度量。秩检验采用Mann-Whitney U检验，实验结果表明DFCM+RUS方案与我们的四种方案之间的差异具有统计学意义。通过对实验结果的分析，我们的数据预处理方法提高了传统类比失衡预测模型的准确率。,,版本内,21-155个特征，并没有详细说明有哪些,"一种是我们提出的基于DFCM聚类的特征提取算法，另一种是仅使用特征排序的信息增益(Information Gain, IG)[56]。",使用随机欠采样(RUS)通过选择' s '特征来构建更平衡的特征，其中' s '是在任何聚类中提取的最小特征数，,结果表明，DFCM特征提取方法是对特征排序方法(IG)的显著改进。,"ten datasets belong to NASA (cm1, jm1, kc1, kc3, mc2, mw1, pc1, pc3, pc4, and pc5) , and three datasets belong to Eclipse (Eclipse 2.0, Eclipse 2.0 and Eclipse 3.0)",125-17000模块,公开,完成,JAVA/C,朴素贝叶斯(NB)、C4.5决策树(C4.5)和1-近邻规则(1-NN),模块级,故障倾向,"Sensitivity, Specificity, and Area-under-thecurve (AUC) ",
"Manjula, C.; Florence, Lilly",Deep neural network based hybrid approach for software defect prediction using software metrics,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,10.1007/s10586-018-1696-z,2019,"In the field of early prediction of software defects, various techniques have been developed such as data mining techniques, machine learning techniques. Still early prediction of defects is a challenging task which needs to be addressed and can be improved by getting higher classification rate of defect prediction. With the aim of addressing this issue, we introduce a hybrid approach by combining genetic algorithm (GA) for feature optimization with deep neural network (DNN) for classification. An improved version of GA is incorporated which includes a new technique for chromosome designing and fitness function computation. DNN technique is also improvised using adaptive auto-encoder which provides better representation of selected software features. The improved efficiency of the proposed hybrid approach due to deployment of optimization technique is demonstrated through case studies. An experimental study is carried out for software defect prediction by considering PROMISE dataset using MATLAB tool. In this study, we have used the proposed novel method for classification and defect prediction. Comparative study shows that the proposed approach of prediction of software defects performs better when compared with other techniques where 97.82% accuracy is obtained for KC1 dataset, 97.59% accuracy is obtained for CM1 dataset, 97.96% accuracy is obtained for PC3 dataset and 98.00% accuracy is obtained for PC4 dataset.",3,我们引入了一种混合方法，将用于特征优化的遗传算法(GA)与用于分类的深度神经网络(DNN)相结合。,在软件缺陷的早期预测领域，已经开发了各种技术，如数据挖掘技术、机器学习技术等。然而，缺陷的早期预测仍然是一个具有挑战性的任务，需要解决这个问题，并且可以通过提高缺陷预测的分类率来改进。,为了解决这一问题，我们引入了一种混合方法，将用于特征优化的遗传算法(GA)与用于分类的深度神经网络(DNN)相结合。在遗传算法中引入了新的染色体设计和适应度函数计算技术。深度神经网络技术也采用自适应自编码器，提供了更好的表示选定的软件特征。通过实例分析证明了优化技术的应用提高了混合方法的效率。利用MATLAB工具对PROMISE数据集进行了软件缺陷预测的实验研究。,在这项研究中，我们使用了提出的新方法进行分类和缺陷预测。对比研究表明，本文提出的软件缺陷预测方法在KC1、CM1、PC3和PC4上的准确率分别达到97.82%、97.59%、97.96%和98.00%，均优于其他预测方法。,,版本内,promise中一些度量,遗传算法,"自适应自编码器
自适应自编码器去噪",,"KC1, KC2, CM1, PC1, JM1",10-43kLOC,公开,完成,C/C++,DNN深度神经网络,模块级,故障倾向,"accuracy, precision, specificity, sensitivity and F-measure",准确率等非常高AUC似乎也很高，基本达到了分类上限，需要学习下
"Chen, Xiang; Zhang, Dun; Zhao, Yingquan; Cui, Zhanqi; Ni, Chao",Software defect number prediction: Unsupervised vs supervised methods,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2018.10.003,2019,"Context: Software defect number prediction (SDNP) can rank the program modules according to the prediction results and is helpful for the optimization of testing resource allocation.Objective: In previous studies, supervised methods vs unsupervised methods is an active issue for just-in-time defect prediction and file-level defect prediction based on effort-aware performance measures. However, this issue has not been investigated for SDNP. To the best of our knowledge, we are the first to make a thorough comparison for these two different types of methods.Method: In our empirical studies, we consider 7 real open-source projects with 24 versions in total, use FPA and Kendall as our effort-aware performance measures, and consider three different performance evaluation scenarios (i.e., within-version scenario, cross-version scenario, and cross-project scenario).Result: We first identify two unsupervised methods with best performance. These two methods simply rank modules according to the value of metric LOC and metric RFC from large to small respectively. Then we compare 9 state-of-the-art supervised methods incorporating SMOTEND, which is used for handling class imbalance problem, with the unsupervised method based on LOC metric (i.e., LOC_D method). Final results show that LOC_D method can perform significantly better than or the same as these supervised methods. Later motivated by a recent study conducted by Agrawla and Menzies, we apply differential evolutionary (DE) to optimize parameter value of SMOTEND used by these supervised methods and find that using DE can effectively improve the performance of these supervised methods for SDNP too. Finally, we continue to compare LOC_D with these optimized supervised methods using DE, and LOC_D method still has advantages in the performance, especially in the cross-version and cross-project scenarios.Conclusion: Based on these results, we suggest that researchers need to use the unsupervised method LOC_D as the baseline method, which is used for comparing their proposed novel methods for SDNP problem in the future.",3,比较监督方法和非监督方法 首先确定了两种性能最佳的无监督方法。这两种方法简单地根据度量LOC和度量RFC的值分别从大到小对模块进行排序。然后，我们比较了包含SMOTEND的9种最先进的监督方法(用于处理类不平衡问题)与基于LOC度量的无监督方法(即LOC_D方法)。,"软件缺陷数预测(Software defect number prediction, SDNP)可以根据预测结果对程序模块进行排序，有助于优化测试资源的分配。",在以往的研究中，监督方法与非监督方法是实时缺陷预测和基于工作感知性能度量的文件级缺陷预测的一个活跃问题。然而，这个问题并没有针对SDNP进行调查。据我们所知，我们是第一个对这两种不同类型的方法进行彻底比较的人。方法:在实证研究中，我们选取了7个真实的开源项目，共24个版本，使用FPA和Kendall作为我们的努力感知性能指标，并考虑了3种不同的性能评估场景(即版本内场景、跨版本场景和跨项目场景)。,"结果:首先确定了两种性能最佳的无监督方法。这两种方法简单地根据度量LOC和度量RFC的值分别从大到小对模块进行排序。然后，我们比较了包含SMOTEND的9种最先进的监督方法(用于处理类不平衡问题)与基于LOC度量的无监督方法(即LOC_D方法)。最终结果表明，LOC_D方法的性能明显优于或等同于这些有监督的方法。后来，受Agrawla和Menzies最近研究的启发，我们应用微分进化(differential evolutionary, DE)对这些监督方法所使用的SMOTEND参数值进行优化，发现使用微分进化(differential evolutionary, DE)也可以有效地提高这些监督方法对SDNP的性能。最后，我们继续使用DE将LOC_D方法与这些优化后的监督方法进行比较，发现LOC_D方法在性能上仍然具有优势，特别是在跨版本和跨项目的场景下。结论:基于这些结果，我们建议研究人员需要使用无监督方法LOC_D作为基线方法，用于将来比较他们提出的sdn问题的新方法","M. Yan, Y. Fang, D. Lo, X. Xia, X. Zhang, File-level defect prediction: Unsupervised vs. supervised models, in: Proceedings of the International Symposium on Empirical Software Engineering and Measurement, 2017, pp. 344C353.",版本内、跨版本、跨项目,内聚、耦合、复杂度、抽象等,,缓解类不平衡：SMOTEND Method,在版本内场景下，LOC_D的性能明显优于CBS_A和OneWay_A。而LOC_D与CBS_D和OneWay_D具有相似的性能。在跨版本场景中，LOC_D的性能明显优于CBS_A、CBS_D、OneWay_A。而LOC_D与OneWay_D具有相似的性能。在跨项目场景中，LOC_D的性能明显优于所有方法(在考虑FPA度量时，OneWay_D除外)。这里以A (Ascending)作为后缀的方法名表示模块按照相应的度量值从小到大进行排序。这样，度量值越小的模块排名越靠前。而以D(降序)为后缀的方法名则表示模块按照对应的度量值从大到小进行排序。,7个项目：ant，camel等,111-900个模块,公开,完成,JAVA,"Linear regression (LR)Bayesian ridge regression (BRR)Decision tree regression (DTR)Nearest Neighbors Regression (NNR)Gradient Boosting Regression (GBR)Random forest regressor (RF)我们考虑一种集成学习方法AdaBoost
",模块级,故障数量,"FPA (Fault-Percentile-Average)
Kendall rank correlation coefficient肯德尔等级相关系数",
"Shippey, Thomas; Bowes, David; Hall, Tracy",Automatically identifying code features for software defect prediction: Using AST N-grams,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2018.10.001,2019,"Context Identifying defects in code early is important. A wide range of static code metrics have been evaluated as potential defect indicators. Most of these metrics offer only high level insights and focus on particular pre-selected features of the code. None of the currently used metrics clearly performs best in defect prediction.Objective: We use Abstract Syntax Tree (AST) n-grams to identify features of defective Java code that improve defect prediction performance.Method: Our approach is bottom-up and does not rely on pre-selecting any specific features of code. We use non-parametric testing to determine relationships between AST n-grams and faults in both open source and commercial systems. We build defect prediction models using three machine learning techniques.Results: We show that AST n-grams are very significantly related to faults in some systems, with very large effect sizes. The occurrence of some frequently occurring AST n-grams in a method can mean that the method is up to three times more likely to contain a fault. AST n-grams can have a large effect on the performance of defect prediction models.Conclusions: We suggest that AST n-grams offer developers a promising approach to identifying potentially defective code.",3,我们使用抽象语法树(AST) n-grams来识别缺陷Java代码的特征，从而提高缺陷预测的性能。,尽早识别代码中的缺陷是很重要的。广泛的静态代码度量已经被评估为潜在的缺陷指示器。这些指标中的大多数只提供高层次的见解，并专注于特定的预先选择的代码特性。目前使用的度量在缺陷预测中没有一个表现得最好。,我们使用抽象语法树(AST) n-grams来识别有缺陷的Java代码的特征，从而提高缺陷预测的性能。方法:我们的方法是自底向上的，不依赖于预先选择代码的任何特定特性。我们使用非参数测试来确定开源和商业系统中AST n-gram和故障之间的关系。我们使用三种机器学习技术建立缺陷预测模型。,在某些系统中，AST n-图与故障有非常显著的关系，具有非常大的效应大小。在一个方法中出现一些频繁出现的AST n-图可能意味着该方法包含错误的可能性高达三倍。AST n-图对缺陷预测模型的性能有很大的影响。结论:我们建议AST n-gram为开发人员提供了一种有希望的方法来识别潜在的缺陷代码。,,版本内,AST n-gram AST的序列形式,,,,9个公开系统，两个私有系统,36-353kLOC,公开/私有,完成,JAVA,朴素贝叶斯、J489和随机森林。,方法级,故障倾向,"precision, recall, f-measure and Matthew’s correlation coefficient (MCC).",
"Fan, Guisheng; Diao, Xuyang; Yu, Huiqun; Yang, Kang; Chen, Liqiong",Software Defect Prediction via Attention-Based Recurrent Neural Network,SCIENTIFIC PROGRAMMING,10.1155/2019/6230953,2019,"In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network (DP-ARNN). More specifically, DP-ARNN first parses abstract syntax trees (ASTs) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of DP-ARNN by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it employs the attention mechanism to further generate significant features for accurate defect prediction. To validate our method, we choose seven open-source Java projects in Apache, using F1-measure and area under the curve (AUC) as evaluation criteria. The experimental results show that, in average, DP-ARNN improves the F1-measure by 14% and AUC by 7% compared with the state-of-the-art methods, respectively.",3,本文提出了一种基于注意力的递归神经网络(DP-ARNN)的缺陷预测框架。更具体地说，DP-ARNN首先解析程序的抽象语法树(ast)，并将它们提取为向量,为了提高软件的可靠性，将软件缺陷预测应用到软件维护过程中，以识别潜在的缺陷。传统的软件缺陷预测方法主要集中在设计静态代码度量，将静态代码度量输入到机器学习分类器中，以预测代码的缺陷概率。然而，这些人工度量的特征并不包含程序的句法结构和语义信息。这些信息比手动度量更重要，并且可以提供更准确的预测模型。,本文提出了一种基于注意力的递归神经网络(DP-ARNN)的缺陷预测框架。更具体地说，DP-ARNN首先解析程序的抽象语法树(ast)，并将它们提取为向量。然后通过字典映射和词嵌入对作为DP-ARNN输入的向量进行编码。之后，它可以自动学习语法和语义特征。此外，它还利用注意机制进一步生成重要的特征，以实现对缺陷的准确预测。为了验证我们的方法，我们选择了Apache中的七个开源Java项目，使用f1度量和曲线下面积(AUC)作为评估标准。,实验结果表明，与现有方法相比，DP-ARNN平均将f1测度提高14%，AUC提高7%。,,项目内/跨版本,AST抽象语法树,根据相关方法[36]，我们只选择三种类型的ast节点作为标记:(1)方法调用节点，(2)声明节点，包括方法声明、构造函数声明和类声明，以及(3)控制流节点(即分支、循环、异常抛出和捕获)。,,从程序的ast中提取特征，并将其输入RF进行分类。RBM与DBN的区别在于前者是一个两层的浅神经网络，后者是一个由多个RBM组成的网络。综合比较7个项目的RBM + RF和DBN + RF的平均f1测度，可以看出DBN + RF的平均f1测度高于RBM + RF的值，说明项目的ast信息可以得到更深入的挖掘。从W/T/L的角度来看，与DBN + RF相比，DP-ARNN和CNN在f1测度上胜7次，RNN也胜6次，验证了基于深度学习方法的模型的稳定性。在AUC方面，DPARNN、CNN和RNN的平均值均高于DBN + RF的平均值，说明基于深度学习方法的综合判别能力优于无监督学习方法。这些结果验证了从深度学习方法中提取特征的优越性，特别是我们提出的DP-ARNN方法。,我们收集了Apache中的七个开源Java项目，每个项目都包含两个版本(即preversion和postversion)。,221-918个文件,公开,完成,JAVA,"作者提出的attention-based recurrent neural network (DP-ARNN).
RF: random forest (RF) [45] method based on 20 static code metrics
(ii) RBM + RF: random forest method with hidden features learned by restricted Boltzmann machine (RBM) [46] (iii) DBN + RF: random forest method with hidden features generated by deep belief network (DBN) [47] (iv) CNN: a deep learning method based on text sequence convolution, which feeds hidden features learned by CNN to the final classifier. (v) RNN: a bidirectional recurrent neural network based on LSTM units to generate syn",文件级,故障倾向,F-measure，AUC,
"Jayanthi, R.; Florence, Lilly",Software defect prediction techniques using metrics based on neural network classifier,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,10.1007/s10586-018-1730-1,2019,"Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction.",3,这里我们提出了一种软件缺陷预测和软件缺陷预测的组合方法。该方法提供了特征约简和人工智能的概念，其中特征约简由著名的主成分分析(PCA)方案进行，该方案通过结合最大似然估计在PCA数据重构中减少误差进一步改进。最后，应用基于神经网络的分类技术进行预测。,软件行业通过一致的bug预测、bug移除和对易出错模块的预测来努力提高软件质量。该领域因其与软件行业的重大关联而吸引了研究人员。各种软件缺陷预测技术已经被提出。最近的研究推荐使用机器学习的数据挖掘作为软件错误预测的重要范例。目前的软件缺陷预测任务存在分类精度等问题。然而，软件缺陷数据集由于其庞大的维度，本质上是不平衡的，容易出现已知故障。,为了解决这个问题，这里我们提出了一种软件缺陷预测和软件缺陷预测的组合方法。该方法提供了特征约简和人工智能的概念，其中特征约简由著名的主成分分析(PCA)方案进行，该方案通过结合最大似然估计在PCA数据重构中减少误差进一步改进。最后，应用基于神经网络的分类技术进行预测。在NASA软件数据集上制定并实现了一个框架，其中考虑了KC1、PC3、PC4和JM1四个数据集，使用MATLAB仿真工具进行性能分析。本文进行了广泛的实验研究，计算了混淆度、精度、召回率、分类精度等参数，并与现有的软件缺陷预测技术进行了比较。,实验研究表明，该方法具有较好的性能，AUC达到97.20%，与现有模型相比有显著提高。同样，它在分类精度方面表现出更好的性能。,,版本内,不同数据集有不同的度量,改进的PCA方法，最重要的是PCA是一种特征提取技术而不是特征选择方法。,,,"KC1, PC3, PC4 and JM1from promise",1125-9000个模块,公开,完成,C++/C,ANN,模块级,故障倾向,Accuracy，Sensitivity，Specif icity，precision，F-measure，AUC,本篇论文结果没有多次验证，可能不可靠
"Balogun, Abdullateef Oluwagbemiga; Basri, Shuib; Abdulkadir, Said Jadid; Hashim, Ahmad Sobri",Performance Analysis of Feature Selection Methods in Software Defect Prediction: A Search Method Approach,APPLIED SCIENCES-BASEL,10.3390/app9132764,2019,"Software Defect Prediction (SDP) models are built using software metrics derived from software systems. The quality of SDP models depends largely on the quality of software metrics (dataset) used to build the SDP models. High dimensionality is one of the data quality problems that affect the performance of SDP models. Feature selection (FS) is a proven method for addressing the dimensionality problem. However, the choice of FS method for SDP is still a problem, as most of the empirical studies on FS methods for SDP produce contradictory and inconsistent quality outcomes. Those FS methods behave differently due to different underlining computational characteristics. This could be due to the choices of search methods used in FS because the impact of FS depends on the choice of search method. It is hence imperative to comparatively analyze the FS methods performance based on different search methods in SDP. In this paper, four filter feature ranking (FFR) and fourteen filter feature subset selection (FSS) methods were evaluated using four different classifiers over five software defect datasets obtained from the National Aeronautics and Space Administration (NASA) repository. The experimental analysis showed that the application of FS improves the predictive performance of classifiers and the performance of FS methods can vary across datasets and classifiers. In the FFR methods, Information Gain demonstrated the greatest improvements in the performance of the prediction models. In FSS methods, Consistency Feature Subset Selection based on Best First Search had the best influence on the prediction models. However, prediction models based on FFR proved to be more stable than those based on FSS methods. Hence, we conclude that FS methods improve the performance of SDP models, and that there is no single best FS method, as their performance varied according to datasets and the choice of the prediction model. However, we recommend the use of FFR methods as the prediction models based on FFR are more stable in terms of predictive performance.",3,比较分析SDP中基于不同搜索方法的FS(特征选择)方法的性能是十分必要的。在本文中，使用四种不同的分类器对来自美国国家航空航天局(NASA)存储库的五个软件缺陷数据集进行了四种滤波器特征排序(FFR)和十四种滤波器特征子集选择(FSS)方法的评估。,软件缺陷预测(SDP)模型是使用源自软件系统的软件度量来构建的。SDP模型的质量很大程度上取决于用于构建SDP模型的软件度量(数据集)的质量。高维是影响SDP模型性能的数据质量问题之一。特征选择(FS)是解决维度问题的一种行之有效的方法。然而，SDP的FS方法的选择仍然是一个问题，因为大多数关于SDP的FS方法的实证研究产生了矛盾和不一致的质量结果。由于不同的底层计算特征，这些FS方法表现不同。这可能是由于FS中使用的搜索方法的选择，因为FS的影响取决于搜索方法的选择。因此，比较分析SDP中基于不同搜索方法的FS方法的性能是十分必要的。,在本文中，使用四种不同的分类器对来自美国国家航空航天局(NASA)存储库的五个软件缺陷数据集进行了四种滤波器特征排序(FFR)和十四种滤波器特征子集选择(FSS)方法的评估。实验分析表明，FS的应用提高了分类器的预测性能，并且FS方法的性能在不同的数据集和分类器上存在差异。在FFR方法中，信息增益在预测模型的性能方面表现出最大的改进。在FSS方法中，基于最佳优先搜索的一致性特征子集选择对预测模型的影响最大。然而，基于FFR的预测模型比基于FSS方法的预测模型更稳定。,从实验结果来看，IG比其他FFR方法对预测模型的改善效果最好，而基于BFS的CNS对基于FSS方法的预测模型的影响效果最好。此外，进一步分析表明，基于FFR的预测模型比其他FS方法更稳定。最后发现，FS方法的性能在不同的数据集上有所不同，并且一些分类器的行为不同。这可能是由于类不平衡，这是数据科学中主要的数据质量问题。,,版本内,每个数据集具有不同度量,"在本研究中，基于rank搜索方法的4种不同FFR方法(信息增益(IG)、ReliefF (RFA)、增益比(GR)和聚类变异(CV))和
基于两种不同搜索方法的2种FFR方法:基于相关性的特征子集选择(CFS)和基于一致性特征子集选择(CNS)。穷举搜索(最佳优先搜索(BFS)和贪婪逐步搜索(GSS)方法)和启发式搜索(遗传搜索(GS)，蝙蝠搜索(Bat)，蚂蚁搜索(AS)，萤火虫搜索(FS)和粒子群优化(PSO)方法)。",,"在本研究中，我们观察到所选择的特征数量在很大程度上取决于所使用的FS方法。CNS通常会选择更多的特征，并且基于CNS的预测模型优于其他FS方法。与FSS方法相比，FFR方法在预测模型的准确性方面产生了更稳定的结果。从单个性能精度值来看，FS方法对NB分类器的预测性能改善最大。?基于(AS, BAT, GS, FS, PSO, BFS和GSS)的CFS选择(自动)最小数量的特征。?如表15所示，平均而言，基于BAT的CFS在NB和DT上的阳性变异值最高，而基于GS和BFS的CNS在LR和KNN上的阳性变异值最高。?FFR具有最低的cv值，使其比其他FSS方法更稳定",美国国家航空航天局(NASA)设施度量数据计划(MDP)存储库,194-1162模块,公开,完成,JAVA/C/C++,Na?ve贝叶斯(NB)，决策树(DT)，核逻辑回归(LR)和K最近邻(KNN),模块级,故障倾向,accuracy，Co-efficient of Variation (C.V),分类器与特征选择独立，有些把分类器放到特征选择里所谓的包装器，但这篇中特征选择用的搜索方法与外部的分类方法独立
"Ni, Chao; Chen, Xiang; Wu, Fangfang; Shen, Yuxiang; Gu, Qing",An empirical study on pareto based multi-objective feature selection for software defect prediction,JOURNAL OF SYSTEMS AND SOFTWARE,10.1016/j.jss.2019.03.012,2019,"The performance of software defect prediction (SDP) models depend on the quality of considered software features. Redundant features and irrelevant features may reduce the performance of the constructed models, which require feature selection methods to identify and remove them. Previous studies mostly treat feature selection as a single objective optimization problem, and multi-objective feature selection for SDP has not been thoroughly investigated. In this paper, we propose a novel method MOFES (Multi-Objective FEature Selection), which takes two optimization objectives into account. One optimization objective is to minimize the number of selected features, this objective is related to the cost analysis of this problem. Another objective is to maximize the performance of the constructed SDP models, this objective is related to the benefit analysis of this problem. MOFES utilizes Pareto based multi-objective optimization algorithms (PMAs) to solve this problem. In our empirical study, we design and conduct experiments on RELINK and PROMISE datasets, which are gathered from real open source projects. Firstly, we analyze the influence of different PMAs on MOFES and find that NSGA-II can achieve the best performance on both datasets. Then, we compare MOFES method with 22 state-of-the-art filter based and wrapper based feature selection methods, and find that MOFES can effectively select fewer but closely related features to construct high-quality models. Moreover, we also analyze the frequently selected features by MOFES, and these findings can be used to provide guidelines on gathering high-quality SDP datasets. Finally, we analyze the computational cost of MOFES and find that MOFES only needs 107 seconds on average. (C) 2019 Elsevier Inc. All rights reserved.",3,本文提出了一种多目标特征选择方法(MOFES)，该方法同时考虑了两个优化目标。其中一个优化目标是最小化所选特征的数量，这个目标与这个问题的成本分析有关。另一个目标是最大化构建的SDP模型的性能，这个目标与这个问题的效益分析有关,软件缺陷预测(SDP)模型的性能取决于所考虑的软件特性的质量。冗余特征和不相关特征可能会降低所构建模型的性能，这需要特征选择方法来识别和去除它们。以往的研究多将特征选择视为单目标优化问题，对SDP的多目标特征选择研究不够深入。,本文提出了一种多目标特征选择方法(MOFES)，该方法同时考虑了两个优化目标。其中一个优化目标是最小化所选特征的数量，这个目标与这个问题的成本分析有关。另一个目标是最大化构建的SDP模型的性能，这个目标与这个问题的效益分析有关。MOFES利用基于Pareto的多目标优化算法(PMAs)来解决这一问题。在我们的实证研究中，我们设计并进行了RELINK和PROMISE数据集的实验，这些数据集是从真实的开源项目中收集的。首先，我们分析了不同pma对MOFES的影响，发现NSGA-II在两个数据集上都能达到最佳性能。然后，我们将MOFES方法与22种最先进的基于过滤器和基于包装器的特征选择方法进行了比较，发现MOFES方法可以有效地选择较少但密切相关的特征来构建高质量的模型。此外，我们还分析了MOFES频繁选择的特征，这些发现可用于为收集高质量的SDP数据集提供指导。最后，我们分析了MOFES的计算成本，发现MOFES平均只需要107秒。,本文将软件缺陷预测的特征选择形式化为一个多目标优化问题，提出了MOFES方法。基于我们的实证研究，我们发现多目标特征选择对SDP非常有用，MOFES可以有效地选择较少但有用的特征来构建高质量的SDP模型。,,版本内,"在RELINK (Wu et al.， 2011)中，根据understanding的定义，将考虑的特征分为两类。有12个复杂性度量(CPM)和15个计数度量(CTM)。
在PROMISE (Jureczko和Madeyski, 2010)中，考虑的20个特性也分为两类:面向对象度量(OOM)和复杂性度量(CPM)。",多目标特征选择方法(MOFES)。使用该方法，我们可以获得一系列非支配特征子集，并根据实际需求选择合适的特征子集(即倾向于选择更少的特征或倾向于构建性能更高的模型)。MOFES by Utilizing NSGA-II.,,与22种最先进的基线特征选择方法相比，在大多数情况下，MOFES可以在选择更少特征的情况下获得更好的性能。,RELINK and PROMISE,"229-965个类
56-399个模块",公开,完成,JAVA等,"J48, KNN, LR and NB",模块/类,故障倾向,hypervolume (HV)，AUC,
"Liang, Hongliang; Yu, Yue; Jiang, Lin; Xie, Zhuosi",Seml: A Semantic LSTM Model for Software Defect Prediction,IEEE ACCESS,10.1109/ACCESS.2019.2925313,2019,"Software defect prediction can assist developers in finding potential bugs and reducing maintenance cost. Traditional approaches usually utilize software metrics (Lines of Code, Cyclomatic Complexity, etc.) as features to build classifiers and identify defective software modules. However, software metrics often fail to capture programs' syntax and semantic information. In this paper, we propose Seml, a novel framework that combines word embedding and deep learning methods for defect prediction. Specifically, for each program source file, we first extract a token sequence from its abstract syntax tree. Then, we map each token in the sequence to a real-valued vector using a mapping table, which is trained with an unsupervised word embedding model. Finally, we use the vector sequences and their labels (defective or non-defective) to build a Long Short Term Memory (LSTM) network. The LSTM model can automatically learn the semantic information of programs and perform defect prediction. The evaluation results on eight open source projects show that Seml outperforms three state-of-the-art defect prediction approaches on most of the datasets for both within-project defect prediction and cross-project defect prediction.",3,在本文中，我们提出了一个新的框架Seml，它结合了词嵌入和深度学习方法来进行缺陷预测。,软件缺陷预测可以帮助开发人员发现潜在的错误并减少维护成本。传统方法通常利用软件度量(代码行数、圈复杂度等)作为构建分类器和识别有缺陷的软件模块的特征。然而，软件度量常常不能捕获程序的语法和语义信息。,在本文中，我们提出了一个新的框架Seml，它结合了词嵌入和深度学习方法来进行缺陷预测。具体来说，对于每个程序源文件，我们首先从其抽象语法树中提取一个标记序列。然后，我们使用映射表将序列中的每个标记映射到一个实值向量，该映射表使用无监督词嵌入模型进行训练。最后，我们使用向量序列及其标签(缺陷或非缺陷)来构建长短期记忆(LSTM)网络。LSTM模型可以自动学习程序的语义信息并进行缺陷预测。,对八个开源项目的评估结果表明，Seml在大多数数据集上都优于三种最先进的缺陷预测方法，无论是项目内缺陷预测还是跨项目缺陷预测。,,跨版本/跨项目,AST抽象语法树,"1)方法调用和类实例创建节点:我们使用这些节点的方法或类名提取并记录这些节点。例如，我们在图1中的File2.java中提取方法pop()和push()，并将它们记录为pop和push。2)声明节点:提取方法声明、类型声明和枚举声明节点，并使用其名称进行记录。3)控制流节点:提取与程序控制流有关的语句或子句，如if语句、for语句、while语句、catch子句等。控制流节点使用它们的语句类型进行记录，例如，if语句被记录为if, catch子句被记录为catch。",从AST节点提取令牌以生成令牌序列。序列中的下一个标记被映射到固定长度的实值向量，这些实值向量由具有大数据集的连续词袋(CBOW)模型预先训练。,f1得分最高。Seml在10组实验中有9组优于indexLSTM，其平均f1分数比indexLSTM高9.2%，这意味着我们的令牌嵌入方法比令牌索引表示性能更好，从而帮助LSTM模型更好地进行缺陷预测。,来自Apache的8个项目和github的5个项目,20-313kLOC,公开,完成,JAVA,LSTM,文件级,故障倾向,Precision (P)、Recall (R)和F1 score (F1),
"Anbu, M.; Mala, G. S. Anandha",Feature selection using firefly algorithm in software defect prediction,CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS,10.1007/s10586-017-1235-3,2019,"Defects occurring in software product are a universal event. Prevention of these defects in the early stage needs more attention because early stage prevention and fixing requires less effort and lower cost. Software defect prediction (SDP) is necessary in the determination of software quality as well as reliability. Prediction of defects is relatively an original research area in software quality engineering. Coverage of key predictors and the kind of data to be collected along with defect prediction model role, the interdependence of defects and predictors can be recognized in software quality. Feature selection (FS) is one of the worthy preprocessing techniques for application that uses huge volumes of data. It is the process of selecting the probable minimal attribute which is expected to be represented in the set of actual attributes. This paper proposes, FS using firefly algorithm (FA) and classifiers like support vector machine (SVM), Naive Bayes (NB) as well as K-nearest neighbor (KNN) are used for classifying the features selected. The FS that make use of the FA is that new technique of evolutionary computation that has been inspired by the process of flash lighting of the fireflies. This can search quickly the feature space for an optimal or a near optimal feature subset for minimizing a certain function of fitness. This proposed fitness function has made use of the incorporation of both the accuracy of classification and the reduction of the size. The results of the experiment have shown that the FS using the FA can achieve a better accuracy of classification than that of the other methods.",3,本文提出利用萤火虫算法(FA)和支持向量机(SVM)、朴素贝叶斯(NB)、k近邻(KNN)等分类器对所选特征进行分类。,软件产品中出现的缺陷是一个普遍的事件。早期预防这些缺陷需要更多的关注，因为早期预防和修复需要更少的精力和更低的成本。软件缺陷预测（SDP）在确定软件质量和可靠性方面是必要的。缺陷预测是软件质量工程中一个比较原始的研究领域。关键预测因子的覆盖范围和要收集的数据类型以及缺陷预测模型的作用，缺陷和预测因子的相互依赖性可以在软件质量中得到识别。对于使用大量数据的应用程序，特征选择（FS）是一种有价值的预处理技术。它是选择期望在实际属性集中表示的可能最小属性的过程。,本文提出了使用萤火虫算法（FA）和支持向量机（SVM）、朴素贝叶斯（NB）以及K近邻（KNN）等分类器的FS对所选特征进行分类。利用FA的FS是一种新的进化计算技术，其灵感来自萤火虫的闪光过程。这可以在特征空间中快速搜索最优或接近最优的特征子集，以最小化某个适应度函数。这个提出的适应度函数利用了分类的准确性和大小的减小。,研究表明，基于遗传算法的遗传算法是求解遗传算法问题的有效算法。适应度函数目标主要用于分类精度的目的，同时也会考虑尺寸缩减作为次要目标，可以进一步以最大精度获得最小尺寸范围内已选择的特征。使用SVM、NB和KNN等分类器进行实验，并使用KC1数据集对所提出的方法进行评估。结果表明，SVM-with FS的分类准确率比SVM-without FS高4.53%，比KNN- without FS高5.4%，比NB- without FS高11%，比KNN- with FS高2.8%，比FS高4.4%。同样，精度、召回率和F度量也以更好的方式得到。该研究可以扩展到改进分类器。,评估子集的一些机制有：无监督方法和有监督方法。在前者中，子集不会对训练示例进行评估。这以一种无监督的方式评估信息内容，这些方法被称为过滤方法。在监督算法的情况下，子集学习算法被称为包装方法。,版本内,KC122个度量包括五行不同的代码、三个McCabe测度、十二个Halstead测度、一个分支计数和一个目标场,增强的萤火虫算法，FA有两个重要方面的基础。第一，是光照强度的变化，而第二是吸引力的公式。简单地说，人们认为萤火虫的吸引力是通过亮度来表达的，亮度与目标函数有关[24],,可以有力地得出结论，特征选择不仅在降低计算复杂度方面起着至关重要的作用，而且在改进预测机制方面也起着至关重要作用。,来自NASA的4个数据集,496-2109个模块,公开,完成,C/C++,Na?ve Bayes KNN SVM,模块级,故障倾向,"Accuracy, probability detection (pd) or recall, precision (prec), probability of false alarm (pf), effort",
"Rathore, Santosh Singh; Kumar, Sandeep",An Approach for the Prediction of Number of Software Faults Based on the Dynamic Selection of Learning Techniques,IEEE TRANSACTIONS ON RELIABILITY,10.1109/TR.2018.2864206,2019,"D etermining the most appropriate learning technique(s) is vital for the accurate and effective software fault prediction (SFP). Earlier techniques used for SFP have reported varying performance for different software projects and none of them has always reported the best performance across different projects. The problem of varying performance can be solved by using an approach, which partitions the fault dataset into different module subsets, trains learning techniques for each subset, and integrates the outcomes of all the learning techniques. This paper presents an approach that dynamically selects learning techniques to predict the number of software faults. For a given testing module, the presented approach first locates its neighbor module subset that contained modules similar to testing module using a distance function and then chooses the best learning technique in the region of that module subset to make the prediction for testing module. The learning technique is selected based on its past performance in the region of module subset. We have performed an evaluation of the proposed approach using fault datasets garnered from the PROMISE data repository and Eclipse bug data repository. Experimental results showed that the proposed approach led to an improved performance when predicting the number of faults in software systems.",3,提出了一种动态选择学习技术来预测软件故障数量的方法。对于给定的测试模块，该方法首先利用距离函数找到包含与测试模块相似模块的相邻模块子集，然后在该模块子集区域选择最佳学习技术对测试模块进行预测。,确定最合适的学习技术对于准确有效的软件故障预测至关重要。早期用于SFP的技术报告了不同软件项目的不同性能，并且没有一种技术总是报告了不同项目的最佳性能。该方法将故障数据集划分为不同的模块子集，为每个子集训练学习技术，并将所有学习技术的结果集成在一起，从而解决故障数据集性能变化的问题。,这篇文章提出了一种动态选择学习技术来预测软件故障数量的方法。对于给定的测试模块，该方法首先利用距离函数找到包含与测试模块相似模块的相邻模块子集，然后在该模块子集区域选择最佳学习技术对测试模块进行预测。学习技术是根据其过去在模块子集区域的表现来选择的。我们已经使用从PROMISE数据存储库和Eclipse错误数据存储库中获得的故障数据集对所建议的方法进行了评估。,实验结果表明，该方法具有较好的故障数预测效果。对于大多数数据集，本文方法的误差值较低。对比分析的结果也表明，所提出的方法比个人学习技术和套袋和提升效果更好。,,版本内/跨版本,各数据集拥有自己的度量,,SMOTER,,"18个数据集，15个来自PROMISE,3个来自eclipse",352-10000个模块,公开,完成,JAVA等,多层感知机，决策树，逻辑回归,模块级,故障数量,"average absolute error (AAE), average relative error (ARE), and prediction at level l.",
"Bigonha, Mariza A. S.; Ferreira, Kecia; Souza, Priscila; Sousa, Bruno; Januario, Marcela; Lima, Daniele",The usefulness of software metric thresholds for detection of bad smells and fault prediction,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2019.08.005,2019,"Context Software metrics may be an effective tool to assess the quality of software, but to guide their use it is important to define their thresholds. Bad smells and fault also impact the quality of software. Extracting metrics from software systems is relatively low cost since there are tools widely used for this purpose, which makes feasible applying software metrics to identify bad smells and to predict faults.Objective: To inspect whether thresholds of object-oriented metrics may be used to aid bad smells detection and fault predictions.Method: To direct this research, we have defined three research questions (RQ), two related to identification of bad smells, and one for identifying fault in software systems. To answer these RQs, we have proposed detection strategies for the bad smells: Large Class, Long Method, Data Class, Feature Envy, and Refused Bequest, based on metrics and their thresholds. To assess the quality of the derived thresholds, we have made two studies. The first one was conducted to evaluate their efficacy on detecting these bad smells on 12 systems. A second study was conducted to investigate for each of the class level software metrics: DIT, LCOM, NOF, NOM, NORM, NSC, NSF, NSM, SIX, and WMC, if the ranges of values determined by thresholds are useful to identify fault in software systems.Results: Both studies confirm that metric thresholds may support the prediction of faults in software and are significantly and effective in the detection of bad smells.Conclusion: The results of this work suggest practical applications of metric thresholds to identify bad smells and predict faults and hence, support software quality assurance activities.Their use may help developers to focus their efforts on classes that tend to fail, thereby minimizing the occurrence of future problems.",3,考察面向对象度量的阈值是否可以用于帮助不良气味检测和故障预测,软件度量可能是评估软件质量的有效工具，但是为了指导它们的使用，定义它们的阈值是很重要的。难闻的气味和故障也会影响软件的质量。从软件系统中提取度量的成本相对较低，因为有广泛用于此目的的工具，这使得应用软件度量来识别不良气味和预测故障变得可行。,考察面向对象度量的阈值是否可以用于帮助不良气味检测和故障预测。方法:为了指导这项研究，我们定义了三个研究问题(RQ)，两个与识别坏气味有关，一个用于识别软件系统中的故障。为了回答这些rq，我们提出了基于度量及其阈值的坏气味检测策略:大类、长方法、数据类、特征嫉妒和拒绝遗产税。为了评估所得阈值的质量，我们进行了两项研究。第一项研究是在12个系统上评估它们检测这些难闻气味的功效。第二项研究是对每一个类级软件度量进行调查:DIT、LCOM、NOF、NOM、NORM、NSC、NSF、NSM、SIX和WMC，如果由阈值确定的值范围对识别软件系统中的故障有用。,两项研究都证实了度量阈值可以支持软件故障的预测，并且在检测不良气味方面显着有效。结论:这项工作的结果建议度量阈值的实际应用，以识别不良气味和预测故障，从而支持软件质量保证活动。使用它们可以帮助开发人员将精力集中在容易失败的类上，从而最大限度地减少未来问题的发生。,"T.G.S. Filó, M.S. Bigonha, K.M. Ferreira, A catalogue of thresholds for object-oriented software metrics, in: Proc. of International Conference on Advances and Trends in Software Engineering, 2015, pp. 48C55.",版本内,DIT(继承树深度):在继承层次结构中高于某个类的类的数量LCOM(方法间缺乏内聚):类内部内聚的度量。?MLOC(方法代码行数):方法中的代码行数。?NBD(嵌套块深度):一个方法的最大嵌套块数量。?NSC (Number of Children):给定班级的子班数。?NOF (Number of Fields):一个类的属性数量。?NOM (Number of Methods):类中方法的数量。?VG (McCabe 's Complexity):方法的圈复杂度。?WMC(加权方法每类):一个类的总权重相对于每个类方法的权重。?SIX(专门化索引):评估子类覆盖父类的程度。,,,"LCOM、NOF、NOM、NORM、NSF、NSM和WMC中有7个指标的Bad范围可以有效地指示故障。在NSM、NSF、NORM、NOM和NOF指标的良好范围内，10个系统中没有一个获得最高百分比的故障类。对于NOF, NOM和NSF，每个范围的类别百分比随着范围的临界程度从好到坏的增加而增加，即范围越临界，故障类别的百分比越大。对于SIX，常规范围在故障指示方面是最有效的。对于DIT和NSC指标，不可能说它们的阈值是系统故障的指示器，它们都是与继承应用相关的指标。结果表明，继承等级不能很好地预测软件故障的发生。因此，该研究证实，通常使用的阈值[15]可以支持对软件系统故障的预测。",10个小型系统selected from Qualitas.class Corpus 2013,129-1100个类,公开,完成,JAVA,阈值,类级,故障倾向,"Recall, Precision and F-measure",
"Borandag, Emin; Ozcift, Akin; Kilinc, Deniz; Yucalar, Fatih",Majority Vote Feature Selection Algorithm in Software Fault Prediction,COMPUTER SCIENCE AND INFORMATION SYSTEMS,10.2298/CSIS180312039B,2019,"Identification and location of defects in software projects is an important task to improve software quality and to reduce software test effort estimation cost. In software fault prediction domain, it is known that 20% of the modules will in general contain about 80% of the faults. In order to minimize cost and effort, it is considerably important to identify those most error prone modules precisely and correct them in time. Machine Learning (ML) algorithms are frequently used to locate error prone modules automatically. Furthermore, the performance of the algorithms is closely related to determine the most valuable software metrics. The aim of this research is to develop a Majority Vote based Feature Selection algorithm (MVFS) to identify the most valuable software metrics. The core idea of the method is to identify the most influential software metrics with the collaboration of various feature rankers. To test the efficiency of the proposed method, we used CM1, JM1, KC1, PC1, Eclipse Equinox, Eclipse JDT datasets and J48, NB, K-NN (IBk) ML algorithms. The experiments show that the proposed method is able to find out the most significant software metrics that enhances defect prediction performance.",3,本研究的目的是开发一种基于多数投票的特征选择算法(MVFS)来识别最有价值的软件度量。,软件项目中缺陷的识别和定位是提高软件质量和降低软件测试工作估算成本的重要任务。在软件故障预测领域，已知20%的模块通常包含80%左右的故障。为了最大限度地减少成本和工作量，精确地识别那些最容易出错的模块并及时纠正它们是非常重要的。机器学习(ML)算法经常用于自动定位容易出错的模块。此外，算法的性能与确定最有价值的软件度量密切相关。,本研究的目的是开发一种基于多数投票的特征选择算法(MVFS)来识别最有价值的软件度量。该方法的核心思想是通过各种特征排序器的协作来识别最具影响力的软件度量。为了验证该方法的有效性，我们使用了CM1、JM1、KC1、PC1、Eclipse Equinox、Eclipse JDT数据集和J48、NB、K-NN (IBk) ML算法。,与标准特征选择方法的性能相比，所提出的方法要么提高了故障检测性能，要么保持了故障检测性能不变。通过对GM值进行双向方差分析，得到的实验结果具有统计学上的支持,,版本内,"NASA数据集包含22个属性，包括4个McCabe度量[30]，9个基本Halstead度量[31]，8个派生Halstead度量[32]，最后一个属性是“缺陷”，分为2类(假或真，即软件模块是否存在缺陷)
Eclipse Equinox由38个度量组成:6个Chidamber & Kemer (CK)度量[34]，11个面向对象(OO)度量[35]，5个熵度量[35]，15个更改度量[36,37]，最后一个度量是描述文件是否有缺陷的“bug”。","Information Gain (IG), Symmetrical Uncertainty (SU), ReliefF (RLF) and Correlation-based (CO) [6],",,,来自PROMISE存储库[27]、Eclipse Equinox[28]和Eclipse JDT R3.1 [29] bug预测数据集,498-10000个模块,公开,完成,C/C++/JAVA,"Na?ve Bayes (NB), Decision Tree (J48), and K Nearest Neighbor (K-NN/IBk)",模块级,故障倾向,Geometric Mean - 1 (GM)，Precision and Recall,
"Juneja, Kapil",A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation,APPLIED SOFT COMPUTING,10.1016/j.asoc.2019.02.008,2019,"Fault Prediction is the most required measure to estimate the software quality and reliability. Several methods, measures, aspects and testing methodologies are available to evaluate the software fault. In this paper, a fuzzy-filtered neuro-fuzzy framework is introduced to predict the software faults for internal and external software projects. The suggested framework is split into three primary phases. At the earlier phase, the effective metrics or measures are identified, which can derive the accurate decision on prediction of software fault. In this phase, the composite analytical observation of each software attribute is calculated using Information Gain and Gain Ratio measures. In the second phase, these fuzzy rules are applied on these measures for selection of effective and high-impact features. In the last phase, the Neuro-fuzzy classifier is applied on fuzzy-filtered training and testing sets. The proposed framework is applied to identify the software faults based on inter-version and inter-project evaluation. In this framework, the earlier projects or project-versions are considered as training sets and the new projects or versions are taken as testing sets. The experimentation is conducted on nine open source projects taken from PROMISE repository as well as on PDE and JDT projects. The approximation is applied on internal version-specific fault prediction and external software projects evaluation. The comparative analysis is performed against Decision Tree, Random Tree, Random Forest, Naive Bayes and Multilevel Perceptron classifiers. This prediction result signifies that the proposed framework has gained the higher accuracy, lesser error rate and significant AUC and GM for inter-project and inter-version evaluations. (C) 2019 Elsevier B.V. All rights reserved.",3,本文将模糊过滤神经模糊框架引入到内部和外部软件项目的软件故障预测中。,故障预测是评估软件质量和可靠性的重要手段。有几种方法、度量、方面和测试方法可用于评估软件故障。,本文将模糊过滤神经模糊框架引入到内部和外部软件项目的软件故障预测中。建议的框架分为三个主要阶段。在早期阶段，识别出有效的度量或度量，从而对软件故障的预测做出准确的决策。在这一阶段，利用信息增益和增益比度量方法计算每个软件属性的综合分析观测值。在第二阶段，将这些模糊规则应用于这些度量，以选择有效和高影响的特征。最后，将神经模糊分类器应用于模糊过滤的训练集和测试集。将该框架应用于基于版本间和项目间评估的软件故障识别。在这个框架中，早期的项目或项目版本被视为训练集，而新的项目或版本被视为测试集。实验是在来自PROMISE存储库的9个开源项目以及PDE和JDT项目上进行的。将该近似方法应用于内部特定版本的故障预测和外部软件项目评估。对决策树、随机树、随机森林、朴素贝叶斯和多层感知器分类器进行了比较分析。,应用于PROMISE库项目的版本间评价，所有项目的平均准确率为65.38，显著高于其他基准算法。对于提议的方法，所有项目的平均MAE为0.0241，明显低于现有的分类器。对于所提出的方法，所有项目获得的平均AUC和GM分别为0.6726和0.6429，这是非常显著的，可接受的，并且高于其他分类器获得的值。结果表明，与现有的基准算法相比，该框架取得了显著的性能提升。同样，在项目间评估的情况下，所提出的框架的平均MAE和RMSE值显著降低。在精度、GM和AUC参数方面实现了显著的性能增益。评估结果表明，建议的框架在Eclipse-JDT和Eclipse-PDE项目中表现得非常好。实验结果表明，该框架在版本间和项目间的故障预测中提供了平均精度，AUC和GM均有显著提高。并与决策树回归(DTR)方法进行了对比观察。结果表明，该框架在版本间和项目间故障预测中具有较高的识别精度和较低的错误率。,,跨版本/跨项目,22个特征进行选择,Information Gain（IG）Gain ratio Chi-square feature selection OneR feature evaluation Fuzzy based feature selection,,,9个多版本的项目,125-23000个模块,公开,完成,JAVA,Neuro-Fuzzy classifier神经模糊分类器，决策树，随机森林，随机数，朴素贝叶斯和多层感知器。,模块级,故障倾向,"Accuracy, MAE (Mean Absolute Error), RMSE (Root Mean Square Error), AUC (Area under ROC Curve Value) and GM (Geometric Mean).精度，MAE(平均绝对误差)，RMSE(均方根误差)，AUC (ROC曲线下面积)和GM(几何平均)。",
"Aziz, Syed Rashid; Khan, Tamim Ahmed; Nadeem, Aamer",Experimental Validation of Inheritance Metrics' Impact on Software Fault Prediction,IEEE ACCESS,10.1109/ACCESS.2019.2924040,2019,"Software faults can cause trivial annoyance to catastrophic failures. Recent work in software fault prediction (SFP) advocates the need for predicting faults before deployment to aid testing process. Object-oriented programming is complex while comparing it with procedural languages having multiple dimensions wherein inheritance is an important aspect. In this paper, we aim to investigate how much inheritance metrics assist in predicting software fault proneness. We first select the Chidamber and Kemerer (CK) metrics, most accepted metric suite for predicting software faults and inheritance metrics. We use 65 publicly available base datasets having CK metrics and some other inheritance metrics to evaluate the impact of inheritance on SFP. We split each dataset into further two datasets: inheritance with CK and CK without inheritance for comparison of results. An artificial neural network (ANN) is used for model building, and accuracy, recall, precision, F1 measures, and true negative rate (TNR) are used for measuring performance. Comparison is made and the results show an acceptable contribution of inheritance metrics in SFP. The testing community can safely use inheritance metrics in predicting software faults. Moreover, high inheritance is not desirable, as this can potentially lead to software faults.",3,我们的目标是研究继承度量在多大程度上有助于预测软件的故障倾向。,软件故障可以从微不足道的烦恼到灾难性的失败。最近在软件故障预测(SFP)方面的工作提倡在部署前预测故障以辅助测试过程。与具有多个维度的过程性语言相比，面向对象编程是复杂的，其中继承是一个重要方面。,在本文中，我们的目标是研究继承度量在多大程度上有助于预测软件的故障倾向。我们首先选择Chidamber和Kemerer (CK)度量，这是预测软件故障和继承度量的最被接受的度量套件。我们使用65个具有CK指标和其他一些继承指标的公开可用基础数据集来评估继承对SFP的影响。我们将每个数据集进一步分为两个数据集:具有CK的继承和不具有继承的CK，以比较结果。使用人工神经网络(ANN)构建模型，并使用准确率、召回率、精度、F1度量和真负率(TNR)来衡量性能。,然而，从CK套件中排除继承度量会显著降低套件的预测能力。此外，向CK套件中添加更多的继承度量显著地提升了预测能力。这提倡了继承度量与CK度量相结合在软件故障预测中的可行性。这项工作意味着测试团体可以安全地使用继承度量来预测软件故障。此外，继承指标的数值越高，表示错误的产生。这指导软件开发人员/设计人员保持最小的继承度量。,,版本内,"继承指标{ic, mfa, noai, nomi, doc, fanin, fanout, ifanin}
CK -继承由4个指标{wmc, cbo, rfc, lcom}组成",去除不是继承的度量,,验证了Inheritance+CK在所有评估指标的总和、中位数和平均值方面具有更好的结果，而CK-Inheritance的标准差更好。在总共30个数据集中，继承+CK数据集在所有评估指标上与CK -继承进行一对一比较时具有优越的结果。从CK套件中排除继承度量会显著降低套件的预测能力。此外，向CK套件中添加更多的继承度量显著地提升了预测能力。这提倡了继承度量与CK度量相结合在软件故障预测中的可行性,CK?inheritance和inheritance +CK各筛选30个数据集,130-8000个实例,公开,完成,JAVA等,ANN,实例,故障倾向,"Accuracy, Precision, Recall, F1-score and TNR",
"Bashir, Kamal; Li, Tianrui; Yohannese, Chubato Wondaferaw",An Empirical Study for Enhanced Software Defect Prediction Using a Learning-Based Framework,INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS,10.2991/ijcis.2018.125905638,2019,"The object of software defect prediction (SDP) is to identify defect-prone modules. This is achieved through constructing prediction models using datasets obtained by mining software historical depositories. However, data mined from these depositories are often associated with high dimensionality, class imbalance, and mislabels which deteriorate classification performance and increase model complexity. In order to mitigate the consequences, this paper proposes an integrated preprocessing framework in which feature selection (FS), data balance (DB), and noise filtering (NF) techniques are fused to deal with the factors that deteriorate learning performance. We apply the proposed framework on three software metrics, namely static code metric (SCM), object oriented metric (OOM), and combined metric (CombM) and build models based on four scenarios (S): (S1) original data; (S2) FS subsets; (S3) FS subsets after DB using random under sampling (RUS) and synthetic minority oversampling technique (SMOTE); (S4) FS subsets after DB (RUS and SMOTE); and NF using iterative partitioning filter (IPF) and iterative noise filtering based on the fusing of classifiers (INFFC). Empirical results show that 1. the integrated preprocessing of FS, DB, and NF improves the performance of all the models built for SDP, 2. for all FS methods, all the models improve performance progressively from S2 through to S4 in all the software metrics, 3. model performance based on S4 is statistically significantly better than the performance based on S3 for all the software metrics, and 4. in order to achieve optimal model performance for SDP, appropriate implementation of the proposed framework is required. The results also validate the effectiveness of our proposal and provide guidelines for achieving quality training data that enhances model performance for SDP. (c) 2019 The Authors. Published by Atlantis Press SARL.",3,本文提出了一个集成的预处理框架，其中融合了特征选择(FS)、数据平衡(DB)和噪声滤波(NF)技术来处理影响学习性能的因素,软件缺陷预测(SDP)的目标是识别易出现缺陷的模块。这是通过使用挖掘软件历史存储库获得的数据集构建预测模型来实现的。然而，从这些存储库中挖掘的数据通常与高维、类不平衡和错误标记相关，这会降低分类性能并增加模型复杂性。,为了减轻这种后果，本文提出了一个集成的预处理框架，其中融合了特征选择(FS)、数据平衡(DB)和噪声滤波(NF)技术来处理影响学习性能的因素。我们将提出的框架应用于三种软件度量，即静态代码度量(SCM)、面向对象度量(OOM)和组合度量(CombM)，并基于四种场景(S)构建模型:(S1)原始数据;(S2) FS子集;(S3)采用随机欠采样(RUS)和合成少数过采样技术(SMOTE)的DB后FS子集;(S4) DB后FS子集(RUS和SMOTE);采用迭代分割滤波(IPF)和基于分类器融合的迭代噪声滤波(INFFC)的NF。,实证结果表明:1。FS、DB和NF的综合预处理提高了为SDP建立的所有模型的性能。对于所有FS方法，所有模型在所有软件度量中从S2到S4逐步提高性能，3。基于S4的模型性能在统计上明显优于基于S3的所有软件指标的性能;为了实现SDP的最佳模型性能，需要适当地实现所提出的框架。结果还验证了我们的建议的有效性，并为获得提高SDP模型性能的高质量训练数据提供了指导方针。,,版本内,SCM静态度量OOM面向对象的度量CombM组合度量,相关特征选择(CFS)卡方检验(CS)信息增益排序技术IG增益比(GR)主成分分析(PCA)ReRFliefF排名RFandRFW对称不确定性(SU),"考虑到IPF和INFFC方法在文献中的广泛应用以及在噪声消除中采用的技术，本研究选择使用IPF和INFFC方法。Iterative-partitioning Filter Iterative noise filter based on the fusion of classifiersINFFC考虑了基于使用多个分类器的过滤技术。在每次迭代中执行三个步骤。首先，使用基于fc的过滤器执行初步过滤，该过滤器考虑三个分类器(C4.5, 3-NN和LR))。第一步去除当前迭代中存在的一部分噪声，以减少其对后步的影响。更具体地说，期望在这一步中去除高置信度识别的噪声样本。","我们在以下四种情况下构建和评估模型性能:使用正常数据集进行训练;2从FS子集学习;3 .从平衡的FS数据子集中学习;4从噪声过滤、平衡的FS子集中学习。
对于没有噪声实例的改进数据集，RUS优于SMOTE。同样，在改进分类性能方面，INFFC也比IPF更有效。在本研究中提出的应用FS、DB和NF的预处理方法的学习影响，在所有软件指标上的模型性能在统计上显著优于其他方法。(2)当训练数据基于面向对象时，S3和S4中构建的大多数分类器的性能优于SCM和CombM。因此，寻找适合预处理方法的软件度量对于提高为SDP开发的模型的分类性能至关重要。(3)对于大多数分类器来说，使用整个特征集学习的性能略优于使用FS子集。然而，考虑到FS子集在应用时节省空间和时间的优势，本研究建议使用FS子集。特别是当两种情况下模型性能的差异在统计上不显著时。因此，对于SDP，本研究建议在S4中学习，特别是在INFFC中学习，以获得有效的NF。值得注意的是，本研究中提出的S4学习比其他几项研究[9,42,43]提出的数据预处理技术分别提高了46%，4.75%和39.2%。","12个数据集，其中CM1、JM1、KC2、MC1、PC1和PC5属于SCM, Prop-5、Tomcat和ant-1.7属于OOM, ML、PDE和LC属于CombM",327-17186模块,公开,完成,C/JAVA,"NB, RaF, KNN, MLP, SVM, J48, DSt, and LR.",模块级,故障倾向,AUC,不同数据集有不同的度量，没办法统一起来，因此结果无法排除数据集本身影响
"Jian, Yiheng; Yu, Xiao; Xu, Zhou; Ma, Ziyi",A Hybrid Feature Selection Method for Software Fault Prediction,IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS,10.1587/transinf.2019EDP7033,2019,"Fault prediction aims to identify whether a software module is defect-prone or not according to metrics that are mined from software projects. These metric values, also known as features, may involve irrelevance and redundancy, which hurt the performance of fault prediction models. In order to filter out irrelevant and redundant features, a Hybrid Feature Selection (abbreviated as HFS) method for software fault prediction is proposed. The proposed HFS method consists of two major stages. First, HFS groups features with hierarchical agglomerative clustering; second, HFS selects the most valuable features from each cluster to remove irrelevant and redundant ones based on two wrapper based strategies. The empirical evaluation was conducted on 11 widely-studied NASA projects, using three different classifiers with four performance metrics (precision, recall, F-measure, and AUC). Comparison with six filter-based feature selection methods demonstrates that HFS achieves higher average F-measure and AUC values. Compared with two classic wrapper feature selection methods, HFS can obtain a competitive prediction performance in terms of average AUC while significantly reducing the computation cost of the wrapper process.",3,为了过滤掉不相关和冗余的特征，提出了一种用于软件故障预测的混合特征选择(HFS)方法。,故障预测的目的是根据从软件项目中挖掘出来的度量来确定软件模块是否容易出现缺陷。这些度量值也被称为特征，可能涉及到不相关和冗余，从而影响故障预测模型的性能。,为了过滤掉不相关和冗余的特征，提出了一种用于软件故障预测的混合特征选择(HFS)方法。提出的HFS方法包括两个主要阶段。首先，HFS组具有层次聚集聚类特征;其次，HFS基于两种基于包装器的策略，从每个集群中选择最有价值的特征，去除不相关和冗余的特征。对11个被广泛研究的NASA项目进行了实证评估，使用三种不同的分类器和四种性能指标(精度、召回率、F-measure和AUC)。,与六种基于滤波器的特征选择方法的比较表明，HFS获得了更高的平均F-measure值和AUC值。与两种经典的包装器特征选择方法相比，HFS可以在平均AUC方面获得具有竞争力的预测性能，同时显著降低包装器过程的计算成本。,"在[10]Z. Xu, J. Xuan, J. Liu, and X. Cui, “Michac: Defect prediction via feature selection based on maximal information coefficient with hierarchical agglomerative clustering,” 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp.370C381, IEEE, 2016.中，我们提出了一种基于过滤器的特征选择方法，即MICHAC，该方法使用最大信息系数(MIC)[17]对候选特征进行排序以去除不相关的特征，并使用分层聚类(HAC)对特征进行分组，并从每个结果组中选择一个特征。由于MICHAC是一种基于滤波器的特征选择方法，并且训练过程不涉及任何分类算法，因此预测误差高于包装器方法。因此，我们希望采用基于包装器的特征选择策略来进一步提高MICHAC的性能。",版本内,每个项目有不同的度量,1. 前向选择(FS):我们从故障预测模型中没有特征开始。在每次迭代中，我们不断地从每个集群中添加最相关的特征，直到添加新特征不能提高模型的性能。2. 向后消除(BE):我们从所有特征开始，在每次迭代中从每个聚类中去除最不相关的特征，直到去除特征没有观察到故障预测模型的改进。使用Maximal Information Coefficient (MIC)最大信息相关系数计算与标签的关联，进行选择,,"发现HFS选择的圈密度、归一化圈复杂度和halstead effort的次数最多，MICHAC选择的次数较少。这三个特性都与代码有关
在故障预测中，我们的方法比基于滤波器的特征选择方法具有更好的预测效果
。对于NB分类器，HFS FS达到了最好的平均AUC值。然而，HFS BE的平均AUC值低于SFS，而SBE的平均AUC值与HFS相同。对于rf分类器，HFS FS和HFS BE比SFS和SBE获得更好的平均AUC值。对于RIPPER分类器，HFS FS和SFS达到了最好的AUC值。此外，我们对HFS、SFS和SBE所选择的特征进行了统计，发现这三种方法所选择的特征没有显著差异",11个来自NASA的项目,127-9500个模块,公开,完成,C/C++等,朴素贝叶斯(NB)，随机森林(RF)和重复增量修剪产生误差减少(RIPPER)。,模块级,故障倾向,"precision, recall, F-measure, and AUC).",不同包装器的方法，它的特征选择是直接靠MIC的大小排名选择特征的
"Ndenga, Malanga Kennedy; Ganchev, Ivaylo; Mehat, Jean; Wabwoba, Franklin; Akdag, Herman",Performance and cost-effectiveness of change burst metrics in predicting software faults,KNOWLEDGE AND INFORMATION SYSTEMS,10.1007/s10115-018-1241-7,2019,"The purpose of this study is to determine a type of software metric at file level exhibiting the best prediction performance. Studies have shown that software process metrics are better predictors of software faults than software product metrics. However, there is need for a specific software process metric which can guarantee the best fault prediction performances consistently across different experimental contexts. We collected software metrics data from Open Source Software projects. We used logistic regression and linear regression algorithms to predict bug status and number of bugs corresponding to a file, respectively. The prediction performance of these models was evaluated against numerical and graphical prediction model performance measures. We found that change burst metrics exhibit the best numerical performance measures and have the highest fault detection probability and least cost of misclassification of software components.",3,本研究的目的是确定在文件级别显示最佳预测性能的一种软件度量。,在这项研究中，我们调查了变更突发、变更、代码混乱、组织和源代码度量的能力，以在源代码文件的粒度上预测OSS项目中的错误组件。据我们所知，Nagappan等人[5]是研究变更突发度量预测软件缺陷能力的第一批研究者。然而，他们的调查是在Windows Vista的二进制文件级别进行的。由于二进制文件是由多个源代码文件生成的，因此它的粒度不如文件那么细。,本研究力求实现三个主要目标。它试图在变更突发度量、变更度量、代码流失度量、组织度量和源代码度量中确定一组软件度量，这些度量在软件项目的文件级粒度上表现出最佳的软件故障预测性能。第二个目标是建立与在预测软件故障时使用上述软件度量集构建的预测模型的实现相关的成本。最后，本研究试图建立结合所调查的指标对预测模型性能的影响。,根据数值和图形预测模型的性能指标对这些模型的预测性能进行了评估。结果表明，变化突发度量具有最佳的数值性能度量，并且具有最高的故障检测概率和最小的软件组件误分类成本。,软件产品度量是内在的代码度量，可以分为静态度量或动态度量。静态代码度量包括产品属性，如大小和复杂性，而动态度量包括软件属性，如耦合、内聚和继承。软件过程度量是对软件开发过程的度量。变更度量和开发人员度量是软件过程度量的例子。,跨版本,变更、代码流失、组织和变更突发指标,,,"现在我们可以回答第一个研究问题了:当用于预测文件级别的软件故障时，更改突发度量在数值模型性能度量中表现出最佳性能。与变更、代码混乱、组织和源代码度量相比，变更突发度量具有最小的组件错误分类成本。
使用组合软件度量作为预测器并不能显著提高预测模型的性能。",4个项目,242-3290个文件,公开,完成,C/JAVA,逻辑回归,文件级,故障倾向,AUC、precision、recall、G-mean1、G-mean2、F-measure和J_Coefficient。,
"Wang, Song; Liu, Taiyue; Nam, Jaechang; Tan, Lin",Deep Semantic Feature Learning for Software Defect Prediction,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,10.1109/TSE.2018.2877612,2020,"Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.",3,利用深度信念网络(DBN)来自动学习语义特征，使用从程序的抽象语法树(AST)(用于文件级缺陷预测模型)和源代码更改(用于更改级缺陷预测模型)中提取的令牌向量。我们检查了我们的方法在两个文件级缺陷预测,软件缺陷预测，它预测有缺陷的代码区域，可以帮助开发人员发现错误并确定测试工作的优先级。传统的缺陷预测特征常常不能捕捉到不同程序之间的语义差异。这降低了建立在这些传统特征上的预测模型的性能。因此，需要在程序中捕获语义的能力来构建准确的预测模型。为了弥合语义和缺陷预测特征之间的差距，我们建议利用强大的表示学习算法，深度学习，从源代码文件和代码更改中自动学习程序的语义表示。,具体来说，我们利用深度信念网络(DBN)来自动学习语义特征，使用从程序的抽象语法树(AST)(用于文件级缺陷预测模型)和源代码更改(用于更改级缺陷预测模型)中提取的令牌向量。我们检查了我们的方法在两个文件级缺陷预测任务(即，项目内文件级缺陷预测和文件级跨项目缺陷预测)和两个变更级缺陷预测任务(即，项目内变更级缺陷预测和变更级跨项目缺陷预测)上的有效性。,对于文件级缺陷预测任务，我们的评估是在来自10个开源项目的26个版本的数据上进行的。我们的研究结果表明，基于dbn的语义特征平均提高了13.3个百分点(F1)，并且平均比具有传统特征的最先进的CPDP高出6.0个百分点。对于变更级别的缺陷预测，我们对来自6个开源项目和4个开源商业项目的超过1M的变更进行了评估。实验结果表明，基于dbn的语义特征可将WCDP平均提高5.1个百分点，将基于传统变化级特征的CCDP技术平均提高2.9个百分点。此外，在工作感知的评估场景下，我们基于dbn的语义特征在文件级和变更级缺陷预测方面都优于传统特征。,,跨版本/跨项目,AST 1)方法调用和类实例创建的节点，例如，在图3中，方法createOutput()和openInput()被记录为它们的方法名;2)声明节点，即方法声明、类型声明和枚举声明;以及3)控制流节点，如while语句、catch子句、if语句、throw语句等,,"通过这个编码过程，方法调用信息和类间信息被表示为整数向量。此外，由于令牌的顺序保持不变，因此保留了一些程序结构信息。注意，在这项工作中，我们对文件级和变更级缺陷预测任务使用了相同的令牌映射机制。
在我们训练一个DBN之后，权重w和偏置b(细节见第2节)都是固定的。我们将训练数据和测试数据的归一化整数向量输入到DBN中，然后从DBN的输出层获得训练数据和测试数据的语义特征。",,10个文件级，6个变更级项目 还有4个商业项目,122-463个文件,公开,完成,C/JAVA,DBN深度信念网络生成语义特征，然后交给分类器分类ADTree，朴素贝叶斯和逻辑回归，,文件级/变更级,故障倾向,"Precision, Recall, and F1",这篇文章写的很全面，证据很充分
"Majd, Amirabbas; Vahidi-Asl, Mojtaba; Khalilian, Alireza; Poorsarvi-Tehrani, Pooria; Haghighi, Hassan",SLDeep: Statement-level software defect prediction using deep-learning model on static code features,EXPERT SYSTEMS WITH APPLICATIONS,10.1016/j.eswa.2019.113156,2020,"Software defect prediction (SDP) seeks to estimate fault-prone areas of the code to focus testing activities on more suspicious portions. Consequently, high-quality software is released with less time and effort. The current SDP techniques however work at coarse-grained units, such as a module or a class, putting some burden on the developers to locate the fault. To address this issue, we propose a new technique called as Statement-Level software defect prediction using Deep-learning model (SLDeep). The significance of SLDeep for intelligent and expert systems is that it demonstrates a novel use of deep-learning models to the solution of a practical problem faced by software developers. To reify our proposal, we defined a suite of 32 statement-level metrics, such as the number of binary and unary operators used in a statement. Then, we applied as learning model, long short-term memory (LSTM). We conducted experiments using 119,989 C/C++ programs within Code4Bench. The programs comprise 2,356,458 lines of code of which 292,064 lines are faulty. The benchmark comprises a diverse set of programs and versions, written by thousands of developers. Therefore, it tends to give a model that can be used for cross-project SDP. In the experiments, our trained model could successfully classify the unseen data (that is, fault-proneness of new statements) with average performance measures 0.979, 0.570, and 0.702 in terms of recall, precision, and accuracy, respectively. These experimental results suggest that SLDeep is effective for statement-level SDP. The impact of this work is twofold. Working at statement-level further alleviates developer's burden in pinpointing the fault locations. Second, cross-project feature of SLDeep helps defect prediction research become more industrially-viable. (C) 2020 Elsevier Ltd. All rights reserved.",3,提出了一种使用深度学习模型(SLDeep)的新技术，称为语句级软件缺陷预测。定义了一套32个语句级指标，例如语句中使用的二进制和一元操作符的数量。,软件缺陷预测(SDP)试图估计代码中容易出错的区域，从而将测试活动集中在更可疑的部分上。因此，高质量的软件以更少的时间和精力发布。然而，当前的SDP技术是在粗粒度的单元上工作的，比如模块或类，这给开发人员定位故障增加了一些负担。,"为了解决这个问题，我们提出了一种使用深度学习模型(SLDeep)的新技术，称为语句级软件缺陷预测。SLDeep对智能和专家系统的意义在于，它展示了深度学习模型的一种新用法，以解决软件开发人员面临的实际问题。为了验证我们的建议，我们定义了一套32个语句级指标，例如语句中使用的二进制和一元操作符的数量。然后，我们将长短期记忆(LSTM)作为学习模型。我们在Code4Bench中使用119,989个C/ c++程序进行了实验。这些程序包括2,356,458行代码，其中292,064行是错误的。基准测试包含一组不同的程序和版本，由数千名开发人员编写。因此，它倾向于给出一个可以用于跨项目SDP的模型。",在实验中，我们训练的模型可以成功地对未见过的数据(即新语句的错误倾向)进行分类，在召回率、精度和准确性方面的平均性能分别为0.979、0.570和0.702。这些实验结果表明，SLDeep对语句级SDP是有效的。这项工作的影响是双重的。在语句级工作进一步减轻了开发人员在精确定位故障位置方面的负担。其次，SLDeep的跨项目特性有助于缺陷预测研究在工业上变得更加可行。,,跨版本/跨项目,我们引入了32个语句级指标来捕获语句的复杂性，这可能会对语句的错误倾向产生不利影响。,,,"虽然我们在SLDeep上的实验中取得了很高的查全率，但是查准率并不高。我们从两个方面来考察这一结果。首先，这一结果在SDP文献中并不罕见。事实上，最好的模型通常以精度为代价实现高召回(Hosseini, 2017)。此外，在软件缺陷预测的上下文中，召回是关键的、决定性的度量，因为它显示了被模型标记为错误的真正错误语句的百分比。高召回率意味着我们的模型几乎不可能错过错误的陈述。","作为主题程序，我们使用了Code4Bench (Majd, 2019)中的C/ c++代码。Majd, A., Vahidi-Asl, M., Khalilian, A., Baraani-Dastjerdi, A., & Zamani, B. (2019). Code4Bench: A Multidimensional Benchmark of Codeforces Data for Different Program Analysis Techniques. Journal of Computer Languages.","在提取的数据集中，存在119,989个主题程序，总计2,356,458行代码，其中有292,064行错误。",公开,完成,C/C++,LSTM,语句级,故障倾向,"Accuracy, Precision, Recall, and F-Measure",
"Rhmann, Wasiur; Pandey, Babita; Ansari, Gufran; Pandey, D. K.",Software fault prediction based on change metrics using hybrid algorithms: An empirical study,JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES,10.1016/j.jksuci.2019.03.006,2020,"Quality of the developed software depends on its bug free operation. Although bugs can be introduced in any phase of the software development life-cycle but their identification in earlier phase can lead to reduce the allocation cost of testing and maintenance resources. Software defect prediction studies advocates the use of defect prediction models for identification of bugs prior to the release of the software. Use of bug prediction models can help to reduce the cost and efforts required to develop software. Defect prediction models use the historical data obtained from software projects for training the models and test the model on future release of the software. In the present work, software change metrics have been used for defect prediction. Performances of good machine learning and hybrid algorithms are accessed in prediction of defect with the change metrics. Android project has been used for experimental purpose. Git repository has been used to extract the v4-v5, v2-v5 of android for defect prediction. Obtained results showed that GFS-logitboost-c has best defect prediction capability. (C) 2019 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.",3,在目前的工作中，软件变更度量已被用于缺陷预测。利用变化度量来预测缺陷，可以获得良好的机器学习和混合算法的性能。,所开发软件的质量取决于其无bug的运行。尽管错误可以在软件开发生命周期的任何阶段引入，但是在早期阶段对它们进行识别可以减少测试和维护资源的分配成本。软件缺陷预测研究提倡在软件发布之前使用缺陷预测模型来识别bug。使用bug预测模型可以帮助减少开发软件所需的成本和工作量。缺陷预测模型使用从软件项目中获得的历史数据来训练模型，并在软件的未来版本中测试模型。,本研究的主要目的是建立基于软件变更度量的故障预测模型。以下研究问题(RQ)在本研究中解决。Q1。基于混合搜索的算法(HSBA)如何在使用变化度量的android软件中预测故障?Q2。HSBA和基于机器学习技术(MLT)的android软件预测模型的性能有什么区别?Q3研究中使用的不同技术在统计上是否相等?,探讨了SCM预测错误分类的方法。在使用混合算法时，GFS-loogitboost在精度和召回率方面表现出最好的性能。弗里德曼统计检验用于评估不同技术的性能是否有统计学差异。研究发现，用于缺陷预测的不同技术在性能方面在统计上是相同的。,,跨版本,1. LOC-ADDED是添加到文件中的程序代码行数2. LOC-DELETED是从文件中删除的程序代码行数3.LOC-CHANGED是从文件更改的程序代码行数4. MAX-LOC-ADDED是所有提交时删除的程序代码的最大行数5. MAX_LOC-CHANGED是添加到文件中的程序代码的最大行数6. MAX_LOC_DELETED是删除到文件的程序代码的最大行数7.code churn 代码变动被定义为考虑存储库中所有修订的文件的总和(添加的程序代码行和删除的程序代码行之间的差异)8. max code churn最大代码流失率被定义为软件中一个文件的最大(添加的程序行和删除的程序行之间的差异)，考虑到它在存储库中的所有修订9.average code churn 平均代码流失率被定义为软件中一个文件考虑其在存储库中的所有修订的平均值(添加的程序行和删除的程序行之间的差异),,,,两个安卓数据集,170、324个实例,公开,完成,JAVA,"研究中使用的MLT有Random Forest, Multilayer Perceptron和J48。随机森林是集成学习技术，多层感知器是基于神经网络的，J48是基于决策树的。本研究使用的HSBA为GFS-Adaboost-c和GFS-LoogitBoost-c。",文件级,故障倾向,Precision and recall,"在用于故障预测的两种HBSA中，GFS-LoogitBoost在精度和召回率方面的性能优于其他HBSA
与MLT相比，HBSA对两个数据集都显示出高精度和高召回值。因此，HBSA可以很好地用于支持向量机的故障预测。"
"Esteves, Geanderson; Figueiredo, Eduardo; Veloso, Adriano; Viggiato, Markos; Ziviani, Nivio",Understanding machine learning software defect predictions,AUTOMATED SOFTWARE ENGINEERING,10.1007/s10515-020-00277-4,2020,"Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.",3,我们提出了一种简单的模型抽样方法，该方法可以找到具有最小特征集的准确模型。我们的主要想法是，不能提高预测能力的特征不应该包含在模型中,软件缺陷在软件开发中是众所周知的，并且可能会给用户和开发人员带来一些问题。因此，研究人员采用了不同的技术来减轻源代码中这些缺陷的影响。最值得注意的技术之一是使用机器学习方法进行缺陷预测，它可以支持开发人员在将这些缺陷引入生产环境之前处理它们。这些研究提供了预测缺陷可能性的替代方法。然而，这些工作大多集中于从大量软件特性中预测缺陷。当前文献的另一个关键问题是缺乏对驱动软件到缺陷状态的原因的令人满意的解释。,具体来说，我们使用了一种树提升算法(XGBoost)，该算法接收一个训练集作为输入，该训练集包含每个模块易于计算的特征记录，并输出相应模块是否容易出现缺陷。为了利用预测能力和模型可解释性之间的联系，我们提出了一种简单的模型抽样方法，该方法可以找到具有最小特征集的准确模型。我们的主要想法是，不能提高预测能力的特征不应该包含在模型中。有趣的是，减少的特性集有助于增加模型的可解释性，这对于向开发人员提供与更容易出现缺陷的代码的每个模块相关的特性信息非常重要。,我们发现3.5%的模型(1997 - 287)优于Jureczko数据集中的7个经典基线模型。我们的发现还表明，软件缺陷预测是一项特定于项目的任务，也就是说，组成最佳执行模型的特征可能因项目而有很大差异。因此，理解影响模型决策的因素尤为重要。我们使用SHAP值来解释模型决策，我们发现表现最好的模型非常容易理解，由很少的特征和分布良好的值组成。因此，模型解释可以提供对代码的哪些特性更容易出现缺陷的洞察。,,版本内,CK度量集：1. 加权类方法(WMC):类中方法的复杂度。2. 继承树深度(DIT):每个类都有一个从对象层次结构顶部开始的继承级别度量。3.子女数(NOC):该类的直系后代的数量。4. 对象类之间的耦合(CBO):耦合到给定类的类的数量(传出耦合和传入耦合)。这些耦合可以通过方法调用或字段访问发生。5. 类的响应(RFC):当该类的对象接收到消息时可以执行的不同方法的数量。6. 方法缺乏内聚(LCOM):统计来自类的方法集，这些方法集在共享某些类字段时不相关。7. 方法内聚不足(LCOM3):分为三个方面。(a) m:类中方法的数量。(b) a:类中属性的个数。(c) μ(A):访问属性A的方法数。NPM (Number of Public Methods):统计一个类中所有被声明为Public的方法。9. 数据访问度量(DAM):私有(或受保护)属性的数量与目标类中声明的属性总数之比。10. 聚合度量(MOA):类型为用户定义类的类字段数量的计数。11. 功能抽象度量(MFA):类继承的方法数量与类的成员方法可访问的方法总数之比。12. 类方法间的内聚性(CAM):基于类方法的参数表计算类方法间的关联。该度量是使用每个方法中不同类型方法参数的数量除以整个类中不同类型方法参数的数量与方法数量的乘积的总和来计算的。13. 继承耦合(IC):给定的类在其中耦合的父类的数量。如果满足以下条件之一，则被认为是耦合的类:(A)它的一个继承方法使用了在新/重定义方法中定义的属性。(b)其中一个继承的方法调用了一个重新定义的方法。(c)它的一个继承方法被重新定义的方法调用，并使用在重新定义的方法中定义的参数。14. 方法间耦合(CBM):所有继承方法都耦合到的新方法/重定义方法的总数。15. 平均方法复杂度(AMC):衡量每个类的平均方法大小。大小是用方法中的代码行数来衡量的。16. 传入耦合(Ca):依赖于被测量类的类的数量。17. 传出耦合(Ce):被测量类所依赖的类的数量。18. McCabe的圈复杂度(CC):在所研究类的方法中，CC的值最大。19. McCabe的圈复杂度(CC):被研究类的CC值的算术平均值。20.代码行数(LOC):目标类中代码的总行数。,SHAP为特定预测中的每个特征分配一个重要值(正或负)。输出值包括基本值(验证集上的平均预测值)和这些主导值的总和。否则，SHAP允许我们总结重要的特征，并将低和高特征值与输出值的增加/减少(即预测)相关联。因此，SHAP应用了一个由所有预测构建的彩色编码小提琴图。红色表示重要的数字，蓝色表示不重要的数字。,,我们还指出，重要的功能可能因项目而异。一些最相关的特征是LOC、AMC(平均方法复杂度)、数据访问度量(DAM)、类响应(RFC)和公共方法数量(NPM)。,8个项目,449-69653个模块,公开,完成,JAVA,US XGBoost,模块级,故障倾向,AUC，F1值,
"Wen, Ming; Wu, Rongxin; Cheung, Shing-Chi",How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,10.1109/TSE.2018.2876256,2020,"Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Are the change sequences derived from such information useful to characterize buggy program modules? How can we leverage such sequences to build good defect prediction models? Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly. The improvements vary from 31.6 to 46.8 percent on average. In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.",3,我们利用递归神经网络(RNN)，这是一种深度学习技术，从序列数据中自动编码特征。在本文中，我们提出了一种名为Fences的新方法，该方法通过细粒度的变更分析提取了六种类型的变更序列，涵盖了软件变更的不同方面。,软件缺陷预测的目的是识别有缺陷的模块，它可以帮助开发人员发现错误并对有限的质量保证资源进行优先级排序。已经提出并评估了用于构建缺陷预测模型的各种特征。其中，过程度量是一个重要的类别。然而，现有的过程度量主要是根据变更历史手工编码的，忽略了软件演进过程中由变更产生的顺序信息。从这些信息中得到的变化序列是否对描述有缺陷的程序模块有用?我们如何利用这样的序列来构建良好的缺陷预测模型?与用于现有缺陷预测模型的传统过程度量不同，变更序列主要是可变长度的向量。这使得在由传统分类器驱动的预测模型中直接应用这些序列变得困难。,为了解决这一挑战，我们利用递归神经网络(RNN)，这是一种深度学习技术，从序列数据中自动编码特征。在本文中，我们提出了一种叫做FENCES的新方法，它通过细粒度的变化分析提取了六种类型的变化序列，涵盖了软件变化的不同方面。它通过将缺陷预测映射到可由RNN解决的序列标记问题来进行缺陷预测。,我们对10个开源项目的评估表明FENCES可以高性能地预测缺陷。特别是，我们的方法实现了0:657的平均f度量，这大大改进了基于传统度量的预测模型。平均改善幅度从31:6%到46:8%不等。在AUC方面，FENCES的平均值为0:892，相对于基线的改进从4:2%到16:1%不等。FENCES还优于通过深度学习从静态代码中自动学习语义特征的最先进技术。,,跨版本,"具体来说，我们提取了五种不同类型的元信息:作者身份、变更类型、变更间隔、代码搅动和共同变更。
对于基准算法用了右边这些特征",,,"变更序列可以预测缺陷。从变更序列中构建的缺陷预测模型明显优于那些从传统过程度量中构建的模型(从Fmeasure的平均值从31:6%到46:8%，从AUC的平均值从4:2%到16:1%不等)。基于变更序列构建的缺陷预测模型的性能明显优于传统静态代码度量模型，并且平均而言比基于自动学习的语义特征构建的模型的性能更好。从变更序列构建的缺陷预测模型优于从所有传统度量(过程和静态代码度量)构建的模型，并且改进是显著的。
序列特征与传统的过程度量是互补的，将序列特征与过程度量相结合可以显著提高预测模型的性能。",因此，在我们的评估中保留了10个Java项目和27个版本。表3给出了这些项目的描述。,135-965个文件,公开,完成,JAVA,LSTM,文件级,故障倾向,"Precision, Recall and F-measure，AUC",
"Shi, Meilong; He, Peng; Xiao, Haitao; Li, Huixin; Zeng, Cheng",An Approach to Semantic and Structural Features Learning for Software Defect Prediction,MATHEMATICAL PROBLEMS IN ENGINEERING,10.1155/2020/6038619,2020,"Research on software defect prediction has achieved great success at modeling predictors. To build more accurate predictors, a number of hand-crafted features are proposed, such as static code features, process features, and social network features. Few models, however, consider the semantic and structural features of programs. Understanding the context information of source code files could explain a lot about the cause of defects in software. In this paper, we leverage representation learning for semantic and structural features generation. Specifically, we first extract token vectors of code files based on the Abstract Syntax Trees (ASTs) and then feed the token vectors into Convolutional Neural Network (CNN) to automatically learn semantic features. Meanwhile, we also construct a complex network model based on the dependencies between code files, namely, software network (SN). After that, to learn the structural features, we apply the network embedding method to the resulting SN. Finally, we build a novel software defect prediction model based on the learned semantic and structural features (SDP-S2S). We evaluated our method on 6 projects collected from public PROMISE repositories. The results suggest that the contribution of structural features extracted from software network is prominent, and when combined with semantic features, the results seem to be better. In addition, compared with the traditional hand-crafted features, the F-measure values of SDP-S2S are generally increased, with a maximum growth rate of 99.5%. We also explore the parameter sensitivity in the learning process of semantic and structural features and provide guidance for the optimization of predictors.",3,在本文中，我们利用表征学习来生成语义和结构特征。具体而言，我们首先基于抽象语法树(ast)提取代码文件的标记向量，然后将标记向量馈送到卷积神经网络(CNN)中进行语义特征的自动学习。同时，我们还构建了一个基于代码文件之间依赖关系的复杂网络模型，即软件网络(SN)。,软件缺陷预测的研究在建模预测器方面取得了巨大的成功。为了构建更准确的预测器，提出了许多手工制作的特性，例如静态代码特性、流程特性和社会网络特性。然而，很少有模型考虑程序的语义和结构特征。理解源代码文件的上下文信息可以解释很多关于软件缺陷的原因。,在本文中，我们利用表征学习来生成语义和结构特征。具体而言，我们首先基于抽象语法树(ast)提取代码文件的标记向量，然后将标记向量馈送到卷积神经网络(CNN)中进行语义特征的自动学习。同时，我们还构建了一个基于代码文件之间依赖关系的复杂网络模型，即软件网络(SN)。然后，为了学习结构特征，我们对得到的SN应用网络嵌入方法。最后，我们建立了一种基于学习到的语义和结构特征的软件缺陷预测模型(SDP-S2S)。我们在从公共PROMISE存储库收集的6个项目上评估了我们的方法。),与传统手工特征相比，f测量值普遍提高，最大可达99.5%，表明结构特征的加入确实提高了SDP的性能。统计学上，从Cliff效应量的角度来看，SDP-S2S的优势尤为明显。更具体地说，语义特征和结构特征的结合是SDP的首选选择。此外，我们的结果还表明，过滤器长度最好为10，过滤器的最优数量为20，并且表示向量的维度对预测性能的影响非常有限。最后，我们还分析了软件网络嵌入学习过程中涉及的参数p和q。,"研究人员[9]证明，CNN优于DBN，因为CNN具有捕获局部模式的强大效率。为了更好地表示软件的全局结构，已有研究[10-12]利用复杂网络理论成功地将软件抽象为一个有向依赖网络，通常称为软件网络(software network, SN)，其中文件、类、包等软件组件是节点，它们之间的依赖关系是边。此外，利用网络分析技术，他们证明了网络结构信息在提高缺陷预测性能方面的有效性。",跨版本,AST抽象语义树,,,,6个项目，12个数据集,210-892个文件,公开,完成,JAVA,CNN,文件级,故障倾向,"Precision, Recall, and F-measure,",
"Zhu, Kun; Zhang, Nana; Zhang, Qing; Ying, Shi; Wang, Xu",Software Defect Prediction Based on Non-Linear Manifold Learning and Hybrid Deep Learning Techniques,CMC-COMPUTERS MATERIALS & CONTINUA,10.32604/cmc.2020.011415,2020,"Software defect prediction plays a very important role in software quality assurance, which aims to inspect as many potentially defect-prone software modules as possible. However, the performance of the prediction model is susceptible to high dimensionality of the dataset that contains irrelevant and redundant features. In addition, software metrics for software defect prediction are almost entirely traditional features compared to the deep semantic feature representation from deep learning techniques. To address these two issues, we propose the following two solutions in this paper: (1) We leverage a novel non-linear manifold learning method -SOINN Landmark Isomap (SL-Isomap) to extract the representative features by selecting automatically the reasonable number and position of landmarks, which can reveal the complex intrinsic structure hidden behind the defect data. (2) We propose a novel defect prediction model named DLDD based on hybrid deep learning techniques, which leverages denoising autoencoder to learn true input features that are not contaminated by noise, and utilizes deep neural network to learn the abstract deep semantic features. We combine the squared error loss function of denoising autoencoder with the cross entropy loss function of deep neural network to achieve the best prediction performance by adjusting a hyperparameter. We compare the SL-Isomap with seven state-of-the-art feature extraction methods and compare the DLDD model with six baseline models across 20 open source software projects. The experimental results verify that the superiority of SL-Isomap and DLDD on four evaluation indicators.",3,利用一种新颖的非线性流形学习方法-SOINN Landmark Isomap (SL-Isomap)，通过自动选择地标的合理数量和位置来提取具有代表性的特征，从而揭示隐藏在缺陷数据背后的复杂内在结构。(2)提出了一种基于混合深度学习技术的缺陷预测模型DLDD，该模型利用去噪自编码器学习不受噪声污染的真实输入特征，并利用深度神经网络学习抽象的深度语义特征。,软件缺陷预测在软件质量保证中起着非常重要的作用，它的目的是检查尽可能多的可能存在缺陷的软件模块。然而，预测模型的性能容易受到包含不相关和冗余特征的高维数据集的影响。此外，与深度学习技术的深度语义特征表示相比，用于软件缺陷预测的软件度量几乎完全是传统特征。,针对这两个问题，本文提出了以下两种解决方案:(1)利用一种新颖的非线性流形学习方法――SOINN Landmark Isomap (SLIsomap)，通过自动选择地标的合理数量和位置提取具有代表性的特征，从而揭示隐藏在缺陷数据背后的复杂内在结构。(2)提出了一种基于混合深度学习技术的缺陷预测模型DLDD，该模型利用去噪自编码器学习不受噪声污染的真实输入特征，并利用深度神经网络学习抽象的深度语义特征。我们将去噪自编码器的误差平方损失函数与深度神经网络的交叉熵损失函数相结合，通过调整超参数达到最佳的预测性能。我们将SL-Isomap与7种最先进的特征提取方法进行了比较，并将DLDD模型与20个开源软件项目中的6个基线模型进行了比较。,实验结果验证了SL-Isomap和DLDD在四个评价指标上的优越性,"Li, W.; Zhang, L. P.; Zhang, L. F.; Du, B. (2017): GPU parallel implementation of isometric mapping for hyperspectral classification. IEEE Geoscience and Remote Sensing Letters, vol. 14, no. 9, pp. 1532-1536.",版本内,不同度量数目,非线性流形学习方法- SOINN Landmark Isomap (SL-Isomap)提取特征,,我们的方法SL-Isomap在F1、MCC和G-measure方面的表现优于7种最先进的特征提取方法。在所有20个项目中，与7种特征提取方法相比，SL -Isomap在F1、MCC和G-measure方面的性能平均提高了8.96%、34.83%和11.35%。在pf方面，SL-Isomap获得的中位数低于其他7种方法获得的中位数。,20个软件项目，包括14个来自PROMISE数据存储库的项目和6个来自NASA数据存储库的项目,200-1988个实例,公开,完成,JAVA/C等,"结合去噪自编码器(DAE)的DNN深度神经网络 DLDD
将去噪自编码器的误差平方损失函数与深度神经网络的交叉熵损失函数相结合，通过对超参数的控制，进一步强化学习到的缺陷特征表示。",实例,故障倾向,"F1, MCC (Matthews correlation coefficient), pf and G-measure",
"Bashir, Kamal; Li, Tianrui; Yahaya, Mahama",A Novel Feature Selection Method Based on Maximum Likelihood Logistic Regression for Imbalanced Learning in Software Defect Prediction,INTERNATIONAL ARAB JOURNAL OF INFORMATION TECHNOLOGY,10.34028/iajit/17/5/5,2020,"The most frequently used machine learning feature ranking approaches failed to present optimal feature subset for accurate prediction of defective software modules in out-of-sample data. Machine learning Feature Selection (FS) algorithms such as Chi-Square (CS), Information Gain (IG), Gain Ratio (GR), RelieF (RF) and Symmetric Uncertainty (SU) perform relatively poor at prediction, even after balancing class distribution in the training data. In this study, we propose a novel FS method based on the Maximum Likelihood Logistic Regression (MLLR). We apply this method on six software defect datasets in their sampled and unsampled forms to select useful features for classification in the context of Software Defect Prediction (SDP). The Support Vector Machine (SVM) and Random Forest (RaF) classifiers are applied on the FS subsets that are based on sampled and unsampled datasets. The performance of the models captured using Area Ander Receiver Operating Characteristics Curve (AUC) metrics are compared for all FS methods considered. The Analysis Of Variance (ANOVA) F-test results validate the superiority of the proposed method over all the FS techniques, both in sampled and unsampled data. The results confirm that the MLLR can be useful in selecting optimal feature subset for more accurate prediction of defective modules in software development process.",3,在本研究中，我们提出了一种基于最大似然逻辑回归(MLLR)的FS方法。在软件缺陷预测(SDP)的背景下，,最常用的机器学习特征排序方法无法提供最优特征子集来准确预测样本外数据中有缺陷的软件模块。机器学习特征选择(FS)算法，如卡方(CS)、信息增益(IG)、增益比(GR)、缓解(RF)和对称不确定性(SU)在预测方面表现相对较差，即使在平衡训练数据中的类分布之后也是如此。,在本研究中，我们提出了一种基于最大似然逻辑回归(MLLR)的FS方法。在软件缺陷预测(SDP)的背景下，我们将该方法应用于六个软件缺陷数据集的采样和未采样形式，以选择有用的特征进行分类。将支持向量机(SVM)和随机森林(RaF)分类器应用于基于采样和未采样数据集的FS子集。使用面积下接收机工作特性曲线(AUC)指标捕获的模型的性能与所考虑的所有FS方法进行了比较。方差分析(ANOVA) f检验结果验证了所提出的方法优于所有FS技术，无论是在抽样数据还是未抽样数据中。,方差分析结果显著地表明，当在考虑的两种情况下使用任何一种分类器时，所提出的MLLR优于所有特征排序方法。研究结果也证实了先前研究报告的结论，即基于采样数据的FS优于基于原始数据的FS。此外，无论训练数据是使用MLLR FS子集还是在采样和未采样数据中使用整个特征集形成，缺陷预测模型的性能都不会受到显著影响。研究结果表明，在缺陷预测分类中选择正确的特征子集进行学习是非常重要的。在机器学习分类任务中，使用小维特征空间数据进行SDP建模比使用高维特征空间数据更有效。因此，本研究建议进行进一步调查，以挖掘MLLR对软件开发行业的有用潜力。,"从SDP模型经常使用的监督归纳学习的角度来看，FS通过应用以下三种技术中的一种来呈现一组候选特征:1。增强评估度量的指定数量的特征子集。2. 满足评价措施上的某些标准的子集的最小数目。3.在规模和评价度量中具有最佳保证的子集。
文献中有三种处理FS任务的一般方法。首先，过滤方法通过对预测目标概念的有用性进行排序来选择特征。为了估计他们的等级，采用统计检验和相关结果(即卡方、方差分析、皮尔逊相关)。第二种方法是包装方法，它生成不同的特征子集，并搜索适应特定学习算法的最优特征子集[16]。通过对算法的测试，选择出最优子集。使用向前选择和向后选择等不同的标准来选择子集的特征。最后，嵌入式方法是排名方法和包装方法的混合。有关FS方法的更全面的综述，感兴趣的读者可以参考[4]",版本内,未提及,Maximum Likelihood Logistic Regression (MLLR)最大似然逻辑回归在本研究中，我们提出了MLLR FS技术，其中最优特征子集通过Wald检验来验证估计的系数(95%置信区间)，并在此基础上选择重要特征。,本研究使用了五种广泛使用的基于滤波器的特征排序方法:CS、IG、GR、RF和SU。,one-way Analysis Of Variance (ANOVA) F-test证明MLLR 方法效果更好,其中PC1和Tomcat可以从软件项目数据库的存储库中公开访问[23]，ML、PDE、LC和JDT来自[7]。,691-1862个模块,公开/私有,完成,C等,支持向量机和随机森林。,模块级,故障倾向,AUC,"Chandrashekar G. and Sahin F., “A Survey on Feature Selection Methods,” Computers and Electrical Engineering, vol. 40, no. 1, pp. 16-28, 2014."
"Zhang, Nana; Zhu, Kun; Ying, Shi; Wang, Xu",Software Defect Prediction Based on Stacked Contractive Autoencoder and Multi-Objective Optimization,CMC-COMPUTERS MATERIALS & CONTINUA,10.32604/cmc.2020.011001,2020,"Software defect prediction plays an important role in software quality assurance. However, the performance of the prediction model is susceptible to the irrelevant and redundant features. In addition, previous studies mostly regard software defect prediction as a single objective optimization problem, and multi-objective software defect prediction has not been thoroughly investigated. For the above two reasons, we propose the following solutions in this paper: (1) we leverage an advanced deep neural network-Stacked Contractive AutoEncoder (SCAE) to extract the robust deep semantic features from the original defect features, which has stronger discrimination capacity for different classes (defective or non-defective). (2) we propose a novel multi-objective defect prediction model named SMONGE that utilizes the Multi-Objective NSGAII algorithm to optimize the advanced neural network-Extreme learning machine (ELM) based on state-of-the-art Pareto optimal solutions according to the features extracted by SCAE. We mainly consider two objectives. One objective is to maximize the performance of ELM, which refers to the benefit of the SMONGE model. Another objective is to minimize the output weight norm of ELM, which is related to the cost of the SMONGE model. We compare the SCAE with six state-of-the-art feature extraction methods and compare the SMONGE model with multiple baseline models that contain four classic defect predictors and the MONGE model without SCAE across 20 open source software projects. The experimental results verify that the superiority of SCAE and SMONGE on seven evaluation metrics.",3,本文提出了以下解决方案:(1)利用一种先进的深度神经网络-堆叠式自动编码器(SCAE)从原始缺陷特征中提取鲁棒深度语义特征，该特征对不同类别(缺陷或非缺陷)具有更强的区分能力。(2)提出了一种新的多目标缺陷预测模型SMONGE，该模型利用多目标NSGAII算法，根据SCAE提取的特征，基于最先进的Pareto最优解对高级神经网络-极限学习机(ELM)进行优化,软件缺陷预测在软件质量保证中起着重要的作用。然而，预测模型的性能容易受到不相关和冗余特征的影响。此外，以往的研究多将软件缺陷预测视为单目标优化问题，对多目标软件缺陷预测的研究还不够深入。,基于以上两个原因，本文提出了以下解决方案:(1)利用一种先进的深度神经网络-堆叠收缩自动编码器(SCAE)从原始缺陷特征中提取鲁棒深度语义特征，该特征对不同类别(缺陷或非缺陷)具有更强的区分能力。(2)提出了一种新的多目标缺陷预测模型SMONGE，该模型利用多目标NSGAII算法，根据SCAE提取的特征，基于最先进的Pareto最优解对高级神经网络-极限学习机(ELM)进行优化。我们主要考虑两个目标。一个目标是最大化ELM的性能，这是指SMONGE模型的好处。另一个目标是最小化ELM的输出权值范数，这与SMONGE模型的成本有关。我们将SCAE与六种最先进的特征提取方法进行比较，并将SMONGE模型与包含四个经典缺陷预测器的多个基线模型和没有SCAE的MONGE模型在20个开源软件项目中进行比较。,实验结果验证了SCAE和SMONGE在7个评价指标上的优越性。,,版本内,不同数据集具有不同度量,"网络堆叠压缩自动编码器(SCAE)提取特征
在本文中，我们训练了一个包含四个压缩自编码器的SCAE来提取和重构缺陷特征，其中第一个压缩自编码器的隐藏层的输出作为一阶特征表示，然后将一阶特征表示作为第二个压缩自编码器的隐藏层的输入，同样的策略也用于后续的压缩自编码器。",,与未使用SCAE的原始缺陷特征相比，深度神经网络SCAE提取的深度语义特征(适用于SMONGE)可以提高基于多目标NSGAII优化的ELM的预测性能。,20个真实的软件项目(即来自NASA数据存储库的5个项目和来自PROMISE数据存储库的15个项目),125-1988个实例,公开,完成,C/JAVA等,基于多目标NSGAII优化的极限学习机,实例,故障倾向,"accuracy, precision, recall, F1, pf, G-measure and MCC
MCC (Matthews correlation coefficient):实际产出与预测产出之间的相关性，是综合考虑TP、TN、FP和FN的综合评价。",
"Ren, Junhua; Liu, Feng",A Novel Approach for Software Defect prediction Based on the Power Law Function,APPLIED SCIENCES-BASEL,10.3390/app10051892,2020,"Power law describes a common behavior in which a few factors play decisive roles in one thing. Most software defects occur in very few instances. In this study, we proposed a novel approach that adopts power law function characteristics for software defect prediction. The first step in this approach is to establish the power law function of the majority of metrics in a software system. Following this, the power law function's maximal curvature value is applied as the threshold value for determining higher metric values. Furthermore, the total number of higher metric values is counted in each instance. Finally, the statistical data are clustered into different categories as defect-free and defect-prone instances. Case studies and a comparison were conducted based on twelve public datasets of Promise, SoftLab, and ReLink by using five different algorithms. The results indicate that the precision, recall, and F-measure values obtained by the proposed approach are the most optimal among the tested five algorithms, the average values of recall and F-measure were improved by 14.3% and 6.0%, respectively. Furthermore, the complexity of the proposed approach based on the power law function is O(2n), which is the lowest among the tested five algorithms. The proposed approach is thus demonstrated to be feasible and highly efficient at software defect prediction with unlabeled datasets.",3,在本研究中，我们提出了一种采用幂律函数特征进行软件缺陷预测的新方法。,幂律描述了一种共同的行为，其中几个因素在一件事中起决定性作用。大多数软件缺陷只在极少数情况下发生。,在本研究中，我们提出了一种采用幂律函数特征进行软件缺陷预测的新方法。这种方法的第一步是建立软件系统中大多数度量的幂律函数。随后，幂律函数的最大曲率值作为确定更高度量值的阈值。此外，在每个实例中计算较高度量值的总数。最后，统计数据被聚类成无缺陷和易缺陷实例的不同类别。基于Promise、SoftLab和ReLink的12个公共数据集，使用5种不同的算法进行了案例研究和比较。,结果表明，该方法得到的查准率(precision)、查全率(recall)和F-measure值是5种算法中最优的，查全率(recall)和F-measure的平均值分别提高了14.3%和6.0%。此外，基于幂律函数的算法复杂度为0 (2n)，是五种算法中复杂度最低的。因此，所提出的方法在未标记数据集的软件缺陷预测中是可行和高效的。,幂律描述了一种常见的行为，其中少数因素在一件事中起决定性作用，即少数样本具有很大的影响。同时，众所周知，在软件缺陷中，少数实例导致了许多错误或缺陷。软件度量在软件缺陷数据的分布中显示肥尾，这些数据的偏态和肥尾是幂律函数的属性。因此，幂律函数和软件度量之间可能存在关联。然而，据我们所知，很少有人在预测软件缺陷时考虑幂律函数。,版本内,20个度量等，不同数据集不同度量数,,曲线越靠近Y轴，曲率越小，曲线越远离Y轴，曲线越弯曲，曲率越大。在某一点上，曲线开始与X轴平行，然后曲率减小。这表明幂律函数曲线的曲率由小到大，再由大到小。因此，存在一个最大曲率点，它可能是指标从缺陷到无缺陷的转换点。也就是说，幂律函数的最大曲率点可以作为缺陷与无缺陷的分界点。因此，如果计算出这个过渡点，它就可以作为一个阈值来估计度量中的实体是否存在缺陷。因此，转换点将度量划分为两个部分，有缺陷的和无缺陷的。,在召回值方面，该方法的优势更为明显。它在12个数据集中的10个中表现最好，其平均值为0.790，是所测试方法中最高的。很明显，所提出的方法在几乎所有数据集上都比传统的缺陷预测模型表现得更好。与此同时，一些研究人员指出，低精度和高召回率的预测模型在许多工业情况下更有用[46]。该方法的查全率优于查准率，因此在这些领域具有更好的性能。,12个数据集,27-965个实例,公开,完成,JAVA等,幂律阈值,文件级,故障倾向,"precision, recall, and F-measure",无监督预测方法
"Yu, Qiao; Jiang, Shujuan; Qian, Junyan; Bo, Lili; Jiang, Li; Zhang, Gongjie",Process metrics for software defect prediction in object-oriented programs,IET SOFTWARE,10.1049/iet-sen.2018.5439,2020,"Software evolution is an important activity in the life cycle of a modern software system. In the process of software evolution, the repair of historical defects and the increasing demands may introduce new defects. Therefore, evolution-oriented defect prediction has attracted much attention of researchers in recent years. At present, some researchers have proposed the process metrics to describe the characteristics of software evolution. However, compared with the traditional software defect prediction methods, the research on evolution-oriented defect prediction is still inadequate. Based on the evolution data of object-oriented programs, this study presented two new process metrics from the defect rates of historical packages and the change degree of classes. To show the effectiveness of the proposed process metrics, the authors made comparisons with the code metrics and other process metrics. An empirical study was conducted on 33 versions of nine open-source projects. The results showed that adding the proposed process metrics could improve the performance of evolution-oriented defect prediction effectively.",3,对9个开源项目的33个版本进行了实证研究。结果表明，加入所提出的过程度量可以有效地提高面向进化的缺陷预测的性能。,软件演化是现代软件系统生命周期中的一项重要活动。在软件发展过程中，对历史缺陷的修复和不断增长的需求可能会引入新的缺陷。因此，基于进化的缺陷预测近年来受到了研究人员的广泛关注。目前，一些研究者提出了过程度量来描述软件演化的特征。然而，与传统的软件缺陷预测方法相比，面向进化的缺陷预测研究仍然不足。基于面向对象程序的演化数据，从历史包的缺陷率和类的变化程度两方面提出了两个新的过程度量。,在此基础上，本文从历史包的缺缺率和面向对象程序类的变化程度两方面提出了两种新的PM。为了显示所建议的过程度量的有效性，作者与代码度量和其他过程度量进行了比较。对9个开源项目的33个版本进行了实证研究。,结果表明，添加PPM可以有效地提高缺陷预测的性能，特别是当相邻版本之间的缺陷率稳定时。特别地，我们使用邻近版本的公共类进行实验。,,跨版本,3.1.1 PCDC -一个类别可能是次品类别的概率:3.1.2 pccm -变更CM的百分比:,,,"我们得出结论，在CM中加入PPM可以在一定程度上提高缺陷预测的性能。这也表明PPM对于缺陷预测是有效的。基于以上结果，我们发现项目管理的有效性可能与项目的演进模式有关。
我们得出结论，PPM可以有效地提高缺陷预测的性能，特别是对于那些稳定发展的项目。在实践中，我们可以从当前版本中选择一定百分比的样本作为测试集来验证PM的有效性。如果结果表明PPM有助于提高其性能，那么我们将继续预测当前版本中的其他类",我们使用了9个开源项目的33个版本进行实验，它们通常用于缺陷预测,125-965个类,公开,完成,JAVA,在我们的实验中，我们使用k近邻(KNN)[39]、逻辑回归(LR)[40]和朴素贝叶斯(NB)[41]作为预测模型。,类级,故障倾向,AUC,
"Aarti; Sikka, Geeta; Dhir, Renu",Novel Grey Relational Feature Extraction Algorithm for Software Fault-Proneness Using BBO (B-GRA),ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING,10.1007/s13369-020-04445-2,2020,"The inherent uncertainty of software gives a vague and imprecise solution when it is solved by human judgment. As the project expands, the issues of missing data values, outlier detection, feature subset selection and prediction of faultiness behaviour should be addressed. The feature selection process may lead to the production of high-dimensional data sets that may contribute to many irrelevant or redundant features. In this paper, we focussed on the optimal feature subset selection and fault prediction at the early stage of a project. We propose the novel approach of grey relational analysis (GRA) from grey system theory by optimizing the grey relational grade function using biogeography optimization referred to as B-GRA. The proposed algorithm gives resilience to users to select features for both continuous and categorical attributes. The issues such as feature subset selection, heterogeneity of data sets, outlier analysis and fault prediction are addressed, and then, B-GRA and GRA approaches on five publically available data sets are evaluated using statistical and machine learning techniques. Experimental results show significant results indicating that the proposed methodology can be used for the prediction of faults and produce conceivable results when compared with the GRA feature selection approach.",3,本文中，我们重点研究了项目早期最优特征子集的选择和故障预测。,软件固有的不确定性在通过人的判断来解决问题时，会产生模糊和不精确的结果。随着项目的扩展，缺失数据值、异常值检测、特征子集选择和错误行为预测等问题应该得到解决。特征选择过程可能导致产生高维数据集，这些数据集可能会产生许多不相关或冗余的特征。,在本文中，我们重点研究了项目早期最优特征子集的选择和故障预测。从灰色系统理论出发，利用生物地理学优化方法对灰色关联度函数进行优化，提出了一种新的灰色关联分析方法(GRA)。该算法为用户选择连续属性和分类属性的特征提供了弹性。讨论了特征子集选择、数据集异质性、离群值分析和故障预测等问题，然后利用统计和机器学习技术对5个公开可用数据集的B-GRA和GRA方法进行了评估。,实证研究表明，所提出的方法可以提高模型的能力。得到的结果在六个公开可用的数据集上进行了评估。所得结果与GRA特征提取技术相比，具有更高的精密度、查全率、灵敏度和特异度等优点。通过Wilcoxon sign -rank检验得到的结果表明，使用不同统计和机器学习技术的B-GRA模型产生了统计显著的预测。,,版本内,每个数据集具有不同的度量，利用GRA提取特征每个数据集特征,特征的选择取决于目标变量的域。特征与目标变量的相似度越高，这些特征的预测能力越强。GRA基本上从引用的元组中提取类似的指标。选择与被引用元组相似度较高的指标作为预测机制。,灰色关联分析(GRA)是灰色系统理论(GST)中的一种方法，它与传统的距离度量(如欧氏距离)不同，具有不同的度量。GRA找出不同情况之间的绝对点对点距离，并尽量减少距离的不确定性。GRA的主要目标是基于灰色关联度(GRG)从参考度量中找到n个相似的度量，并根据n个度量对故障倾向预测进行回归。本文的创新之处在于，基于GRA的相似性度量，对目标项目的数量采用了一种新的分类方法，将项目的数量分离到合适的聚类中。,,6个数据集,125-965个类,公开,完成,JAVA,朴素贝叶斯，多层感知器和逻辑回归。,类,故障倾向,Precision，Accuracy，Probability of detection (pd)，Probaility of false alarm (pf)，Sensitivity，Specificity,
"Sun, Jing; Ji, Yi-mu; Liu, Shangdong; Wu, Fei",Cost-Sensitive and Sparse Ladder Network for Software Defect Prediction,IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS,10.1587/transinf.2019EDL8198,2020,"Software defect prediction (SDP) plays a vital role in allocating testing resources reasonably and ensuring software quality. When there are not enough labeled historical modules, considerable semi-supervised SDP methods have been proposed, and these methods utilize limited labeled modules and abundant unlabeled modules simultaneously. Nevertheless, most of them make use of traditional features rather than the powerful deep feature representations. Besides, the cost of the misclassification of the defective modules is higher than that of defect-free ones, and the number of the defective modules for training is small. Taking the above issues into account, we propose a cost-sensitive and sparse ladder network (CSLN) for SDP. We firstly introduce the semi-supervised ladder network to extract the deep feature representations. Besides, we introduce the cost-sensitive learning to set different misclassification costs for defective-prone and defect-free-prone instances to alleviate the class imbalance problem. A sparse constraint is added on the hidden nodes in ladder network when the number of hidden nodes is large, which enables the model to find robust structures of the data. Extensive experiments on the AEEEM dataset show that the CSLN outperforms several state-of-the-art semi-supervised SDP methods.",3,我们提出了一种成本敏感的稀疏阶梯网络(CSLN)。我们首先引入半监督梯形网络来提取深度特征表示,软件缺陷预测在合理分配测试资源、保证软件质量方面起着至关重要的作用。在标记历史模块不足的情况下，人们提出了大量的半监督SDP方法，这些方法同时利用了有限的标记模块和大量的未标记模块。然而，它们大多使用传统特征，而不是强大的深度特征表示。此外，缺陷模块的错误分类成本高于无缺陷模块，并且用于培训的缺陷模块数量较少。,考虑到上述问题，我们提出了一种成本敏感的稀疏阶梯网络(CSLN)。我们首先引入半监督梯形网络来提取深度特征表示。此外，我们还引入了代价敏感学习，对易出现缺陷和无缺陷的实例设置不同的错误分类代价，以缓解类不平衡问题。当隐节点数量较大时，在梯形网络的隐节点上加入稀疏约束，使模型能够找到数据的鲁棒结构。在AEEEM数据集上的大量实验表明，CSLN优于几种最先进的半监督SDP方法,大量的实验表明，CSLN可以取得令人满意的结果，并且优于相关的半监督SDP方法。,,版本内？,61个度量,,,,"5个项目M. D’Ambros, M. Lanza, and R. Robbes, “An extensive comparison of bug prediction approaches,” IEEE Working Conference on Mining Software Repositories, pp.31C41, 2010.",324-1862个模块,公开,完成,JAVA,Cost-Sensitive and Sparse Ladder Network (CSLN)代价敏感稀疏阶梯网络(CSLN),模块,故障倾向,F-measure（Precision，Recall）,也不说清楚数据集具体用了多少，是否是跨版本，原数据集包含多个版本
"Deng, Jiehan; Lu, Lu; Qiu, Shaojian",Software defect prediction via LSTM,IET SOFTWARE,10.1049/iet-sen.2019.0149,2020,"Software quality plays an important role in the software lifecycle. Traditional software defect prediction approaches mainly focused on using hand-crafted features to detect defects. However, like human languages, programming languages contain rich semantic and structural information, and the cause of defective code is closely related to its context. Failing to catch this significant information, the performance of traditional approaches is far from satisfactory. In this study, the authors leveraged a long short-term memory (LSTM) network to automatically learn the semantic and contextual features from the source code. Specifically, they first extract the program's Abstract Syntax Trees (ASTs), which is made up of AST nodes, and then evaluate what and how much information they can preserve for several node types. They traverse the AST of each file and fed them into the LSTM network to automatically the semantic and contextual features of the program, which is then used to determine whether the file is defective. Experimental results on several opensource projects showed that the proposed LSTM method is superior to the state-of-the-art methods.",3,在这项研究中，作者利用长短期记忆(LSTM)网络从源代码中自动学习语义和上下文特征。具体来说，他们首先提取程序的抽象语法树(AST)，它由AST节点组成，然后评估它们可以为几种节点类型保留哪些信息以及保留多少信息,软件质量在软件生命周期中扮演着重要的角色。传统的软件缺陷预测方法主要集中在使用手工制作的特征来检测缺陷。然而，像人类语言一样，程序设计语言包含着丰富的语义和结构信息，代码缺陷的原因与其上下文密切相关。由于无法捕捉到这些重要信息，传统方法的性能远远不能令人满意。,在这项研究中，作者利用长短期记忆(LSTM)网络从源代码中自动学习语义和上下文特征。具体来说，他们首先提取程序的抽象语法树(AST)，它由AST节点组成，然后评估它们可以为几种节点类型保留哪些信息以及保留多少信息。它们遍历每个文件的AST，并将它们输入LSTM网络，以自动获取程序的语义和上下文特征，然后使用这些特征来确定文件是否有缺陷。几个开源项目的实验结果表明，所提出的LSTM方法优于目前最先进的方法。,"以Xalan项目为例，LR、DBN、CNN的F-measure值分别为0.344、0.513和0.460,DP-DBN和DP-CNN、DP-LSTM的F-measure值分别可以达到0.634、0.541和0.655。从表5中我们可以发现，DP-CNN和DP-DBN由于结合了深度学习生成的特征和手工特征而取得了更好的结果，而DP-LSTM在不结合手工特征的情况下取得了更好的结果。最后一行的平均结果表明，DP-LSTM优于其他基于深度学习的方法。","Hindle, A., Barr, E.T., Su, Z., et al.: ‘On the naturalness of software’. 2012 34th Int. Conf. on Software Engineering (ICSE), Zurich, Switzerland, 2012, pp. 837C847",跨版本,AST抽象语法树,,SMOTE,,5个数据集,149-918个文件,公开,完成,JAVA,LSTM,文件级,故障倾向,F-measure（Precision，Recall）,
"Alazzam, Iyad; Aleroud, Ahmed; Al Latifah, Zainab; Karabatis, George",Automatic Bug Triage in Software Systems Using Graph Neighborhood Relations for Feature Augmentation,IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS,10.1109/TCSS.2020.3017501,2020,"Bug triaging is the process of prioritizing bugs based on their severity, frequency, and risk in order to be assigned to appropriate developers for validation and resolution. This article introduces a graph-based feature augmentation approach for enhancing bug triaging systems using machine learning. A new feature augmentation approach that utilizes graph partitioning based on neighborhood overlap is proposed. Neighborhood overlap is a quite effective approach for discovering relationships in social graphs. Terms of bug summaries are represented as nodes in a graph, which is then partitioned into clusters of terms. Terms in strong clusters are augmented to the original feature vectors of bug summaries based on the similarity between the terms in each cluster and a bug summary. We employed other techniques such as term frequency, term correlation, and topic modeling to identify latent terms and augment them to the original feature vectors of bug summaries. Consequently, we utilized frequency, correlation, and neighborhood overlap techniques to create another feature augmentation approach that enriches the feature vectors of bug summaries to use them for bug triaging. The new modified vectors are used to classify bug reports into different priorities. Bug Triage in this context is to correctly recognize the priority of new bugs. Several classification algorithms are tested using the proposed methods. Experimental results on a data set with Eclipse bug reports extracted from the Bugzilla tracking system have shown that our approach outperformed the existing bug triaging systems including modern techniques that utilize deep learning.",3,本文介绍了一种基于图的特征增强方法，用于使用机器学习增强bug分类系统。提出了一种基于邻域重叠的图划分特征增强方法。邻域重叠是发现社交图中关系的有效方法。bug摘要的术语表示为图中的节点，然后将图划分为术语簇。基于每个聚类中的术语与缺陷摘要之间的相似性，将强聚类中的术语增强到缺陷摘要的原始特征向量。,Bug分类是根据严重程度、频率和风险对Bug进行优先级排序的过程，以便分配给适当的开发人员进行验证和解决。,本文介绍了一种基于图的特征增强方法，用于使用机器学习增强bug分类系统。提出了一种基于邻域重叠的图划分特征增强方法。邻域重叠是发现社交图中关系的有效方法。bug摘要的术语表示为图中的节点，然后将图划分为术语簇。基于每个聚类中的术语与缺陷摘要之间的相似性，将强聚类中的术语增强到缺陷摘要的原始特征向量。我们使用其他技术，如术语频率、术语相关性和主题建模来识别潜在术语，并将它们扩展到bug摘要的原始特征向量。因此，我们利用频率、相关性和邻域重叠技术来创建另一种特征增强方法，该方法丰富了bug摘要的特征向量，并将其用于bug分类。新的修改向量用于将bug报告划分为不同的优先级。在这种情况下，Bug分类是为了正确识别新Bug的优先级。,使用所提出的方法对几种分类算法进行了测试。从Bugzilla跟踪系统中提取的Eclipse bug报告的数据集上的实验结果表明，我们的方法优于现有的bug分类系统，包括利用深度学习的现代技术。,,项目内,bug报告特征提取,频率截断(RFSTFC和RFSHF):这一步骤的结果要么是使用术语频率截断(RFSTFC)的称为规则和汇总特征的TDM，其中RF表示规则特征，S表示汇总特征，TFC表示频率截断，要么是使用最高频率术语的TDM规则和汇总特征(RFSHF)，其中RF表示规则特征，S表示汇总特征，HF表示频率最高的术语。频率截断方法丢弃了对错误分类准确性贡献不大的异常项。频率截止有两种方式:最小频率截止和最大频率截止。“最小频率截止”忽略报告摘要中出现次数较少的术语。它可以应用于使用TF-idf或TF权重生成的时分复用(TDM)。我们主要采用最小频率截止来提高时分复用的质量。RFSTFC方法使用最小频率截止，识别频率≥cf的特征，其中cf是用户自定义的频率截止阈值。使用以下规则将截止阈值应用于每个优先级类，该规则识别具有最小频率cf的特征: ,这项工作通过一种混合的新特征增强机制，利用术语相关性(TC)、频率和邻域重叠来丰富bug报告的原始向量，从而为bug分类领域做出了贡献。我们使用得到的特征向量来确定bug的优先级,,Eclipse bug报告数据集,135 548 bug reports,公开,完成,JAVA,"1) RFs;2)使用词频的规则特征和总结特征;3) RFSTFC;4) RFSHF。
KNN、SVM和决策树（DT）分类",文件级,故障严重程度,精密度(Precision)、召回率(recall)、f值(F-measure)和准确度(accuracy)是评价指标,"summary features using term frequency cutoff (RFSTFC)
summary features using terms with the highest frequency (RFSHF)"
"Hassouneh, Yousef; Turabieh, Hamza; Thaher, Thaer; Tumar, Iyad; Chantar, Hamouda; Too, Jingwei",Boosted Whale Optimization Algorithm With Natural Selection Operators for Software Fault Prediction,IEEE ACCESS,10.1109/ACCESS.2021.3052149,2021,"Software fault prediction (SFP) is a challenging process that any successful software should go through it to make sure that all software components are free of faults. In general, soft computing and machine learning methods are useful in tackling this problem. The size of fault data is usually huge since it is obtained from mining software historical repositories. This data consists of a large number of features (metrics). Determining the most valuable features (i.e., Feature Selection (FS) is an excellent solution to reduce data dimensionality. In this paper, we proposed an enhanced version of the Whale Optimization Algorithm (WOA) by combining it with a single point crossover method. The proposed enhancement helps the WOA to escape from local optima by enhancing the exploration process. Five different selection methods are employed: Tournament, Roulette wheel, Linear rank, Stochastic universal sampling, and random-based. To evaluate the performance of the proposed enhancement, 17 available SFP datasets are adopted from the PROMISE repository. The deep analysis shows that the proposed approach outperformed the original WOA and the other six state-of-the-art methods, as well as enhanced the overall performance of the machine learning classifier.",3,确定最有价值的特征(即特征选择(FS))是降低数据维数的极好解决方案。在本文中，我们提出了一种将鲸鱼优化算法(WOA)与单点交叉方法相结合的增强版本,软件故障预测(SFP)是一个具有挑战性的过程，任何成功的软件都应该通过它来确保所有软件组件都没有故障。一般来说，软计算和机器学习方法对解决这个问题很有用。故障数据的大小通常是巨大的，因为它是从挖掘软件的历史存储库中获得的。该数据由大量的特征(指标)组成。确定最有价值的特征(即特征选择(FS))是降低数据维数的极好解决方案。,在本文中，我们提出了一种将鲸鱼优化算法(WOA)与单点交叉方法相结合的增强版本。所提出的改进通过提高勘探过程，帮助WOA摆脱局部最优。采用五种不同的选择方法:锦标赛，轮盘赌，线性排名，随机普遍抽样和随机基础。为了评估提出的增强的性能，从PROMISE存储库中采用了17个可用的SFP数据集。,在提出的WOA变体中，TBWOA在大多数数据集中保持了最佳性能。结果表明，自然选择方法不仅可以提高WOA的整体性能，而且可以去除不需要的属性。此外，实验结果表明，所提出的TBWOA以最高的AUC性能优于其他六种最先进的方法。我们的研究结果表明TBWOA是SFP应用中一个有用和可靠的工具。,"FS方法可以根据两个标准进行分类;子集生成和评估机制。在评估方面，FS方法可以进一步分为包装器和过滤器两种主要的FS模型。完整、启发式和随机搜索机制被认为是大多数FS方法中主要的子集生成机制。在FS模型中，包装器模型以其优异的性能被广泛采用。在该模型中，通常使用学习算法(如分类器)作为评估标准。因此，结果与所选择的学习算法相关联。包装器模型相对于过滤器的主要优点是，前者产生的特征子集能够最大限度地提高特定学习技术的性能。
搜索性能最佳的特性子集是设计FS方法时应该高度考虑的第二个方面。元启发式算法证明了它们在高性能水平上解决FS问题的能力。主要的两类元启发式算法是EA(如GA[30]和DE[31])和SI(如PSO[32]、HHO[33]、SMA[34]、GBO[35]和WOA[36])。",版本内,每个数据集包含20个特征,鲸鱼优化算法搭配5种自然选择方法（在这项工作中只使用了五种方法:基于线性排名的[82]，基于比例(轮盘赌)的[83]，基于随机的[84]，[85]，随机通用抽样[86]和基于锦标赛的[87]。）,,"与BWOA相比，具有DT的TBWOA（Tournament selection method with binary WOA二进制WOA的锦标赛选择方法）在所有数据集上都具有更好的鲁棒性。我们的研究结果表明，TBWOA不仅在kNN分类器中表现出优异的性能，而且在DT模型中也能正常工作。因此，TBWOA可以被认为是一种鲁棒算法。直观地看，DT分类器应用于SFP时的性能要比kNN分类器好得多。TBWOA不仅具有较高的AUC，而且保持较低的特征选择比。作为一个即时的结论，TBWOA被认为是这项工作中最好的BWOA变体。
表15描述了使用四种不同学习算法的TBWOA的结果。可以看出，带DT的TBWOA的AUC性能最高(总排名1.53)。结果表明，DT算法是SFP的最佳学习算法。第二好的学习算法是SVM，它比kNN和LDA要好得多。但从表15的复杂度结果可以看出，SVM的计算时间是最高的。",在本研究中，使用17个PROMISE数据集来评估所提出算法的性能,109-965个实例,公开,完成,JAVA,"SVM, DT, LDA, and kNN",实例级,故障倾向,AUC,
"Mehta, Sweta; Patnaik, K. Sridhar",Improved prediction of software defects using ensemble machine learning techniques,NEURAL COMPUTING & APPLICATIONS,10.1007/s00521-021-05811-3,2021,"Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work.",3,本文旨在减少缺陷预测中面临的两大问题的影响，即数据不平衡和缺陷数据集的高维。递归特征消除(RFE)、基于相关性的特征选择、Lasso、Ridge、ElasticNet和Boruta等特征选择技术来评估各种软件度量。逻辑回归、决策树、k近邻、支持向量机和集成学习是机器学习中的一些算法，这些算法与特征提取和特征选择技术结合使用,一个重要环节。通常，开发人员所犯的错误会在软件开发过程的后期得到修复。这增加了缺陷的影响。为了防止这种情况，需要在软件开发的最初几天预测缺陷，这反过来有助于有效地利用测试资源。缺陷预测过程包括将软件模块分为易缺陷和非易缺陷两类。,本文旨在减少缺陷预测中面临的两大问题的影响，即数据不平衡和缺陷数据集的高维。在这项研究工作中，使用递归特征消除(RFE)、基于相关性的特征选择、Lasso、Ridge、ElasticNet和Boruta等特征选择技术来评估各种软件度量。逻辑回归、决策树、k近邻、支持向量机和集成学习是机器学习中的一些算法，这些算法与特征提取和特征选择技术结合使用，用于将软件中的模块分类为容易出现缺陷和不容易出现缺陷。该模型采用偏最小二乘(PLS)回归与RFE相结合的降维方法，并结合数据集的不平衡性，进一步采用了合成少数派过采样技术。,已经观察到，与研究工作中使用的算法相比，XGBoost和堆叠集成技术在所有数据集上都给出了最好的结果，缺陷预测精度超过0.9。,特征提取是将原始特征集转换为更相关和更重要的特征集的过程，与初始数据集相比，该特征集在数据处理时更易于管理。,版本内,22个特征,"PLS Regression偏最小二乘回归是一种特征提取技术，它结合了主成分分析(PCA)和多元回归的特征，以提供更广义的输出。首先通过PLS回归提取特征来降维。然后选择减少冗余和增加相关性的特征。该操作通过递归特征消除(Wrapper)和交叉验证来执行
将PLS回归特征提取技术与RFE、Lasso、Ridge、ElasticNet、Boruta、correlation等多种特征选择技术相结合，对归一化的数据集进行降维处理。",SMOTE,"在Lasso、ElasticNet、Ridge、Boruta、RFE和基于相关性的特征选择中，RFE对大多数数据集都有更好的性能。XGBoost, Stacking, Random Forest, Extra Trees和AdaBoost算法在与RFE一起使用时表现出良好的性能。","公开可用的数据集，如NASA数据集，PROMISE存储库数据集被用于本研究
CM1,PC1.KC1,KC2",498-2109个实例,公开,完成,C/C++,MLP LR DT KNN SVM RF ET Bagging AdaBoost Gradient Boosting XGB Stacking,模块级,故障倾向,"accuracy, precision, recall, specificity, F-Measure, G-Mean.",用的数据集较简单
"Farid, Ahmed Bahaa; Fathy, Enas Mohamed; Eldin, Ahmed Sharaf; Abd-Elmegid, Laila A.",Software defect prediction using hybrid model (CBIL) of convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM),PEERJ COMPUTER SCIENCE,10.7717/peerj-cs.739,2021,"In recent years, the software industry has invested substantial effort to improve software quality in organizations. Applying proactive software defect prediction will help developers and white box testers to find the defects earlier, and this will reduce the time and effort. Traditional software defect prediction models concentrate on traditional features of source code including code complexity, lines of code, etc. However, these features fail to extract the semantics of source code. In this research, we propose a hybrid model that is called CBIL. CBIL can predict the defective areas of source code. It extracts Abstract Syntax Tree (AST) tokens as vectors from source code. Mapping and word embedding turn integer vectors into dense vectors. Then, Convolutional Neural Network (CNN) extracts the semantics of AST tokens. After that, Bidirectional Long Short-Term Memory (Bi-LSTM) keeps key features and ignores other features in order to enhance the accuracy of software defect prediction. The proposed model CBIL is evaluated on a sample of seven open-source Java projects of the PROMISE dataset. CBIL is evaluated by applying the following evaluation metrics: F-measure and area under the curve (AUC). The results display that CBIL model improves the average of F-measure by 25% compared to CNN, as CNN accomplishes the top performance among the selected baseline models. In average of AUC, CBIL model improves AUC by 18% compared to Recurrent Neural Network (RNN), as RNN accomplishes the top performance among the selected baseline models used in the experiments.",3,在本研究中，我们提出了一种称为CBIL的混合模型。CBIL可以预测源代码的缺陷区域。它从源代码中提取抽象语法树(AST)标记作为向量。映射和词嵌入将整数向量转化为密集向量,近年来，软件行业投入了大量的精力来提高组织中的软件质量。应用前瞻性的软件缺陷预测将帮助开发人员和白盒测试人员更早地发现缺陷，这将减少时间和工作量。传统的软件缺陷预测模型集中于源代码的传统特征，包括代码复杂性、代码行数等。然而，这些特性无法提取源代码的语义。,"在本研究中，我们提出了一种称为CBIL的混合模型。CBIL可以预测源代码的缺陷区域。它从源代码中提取抽象语法树(AST)标记作为向量。映射和词嵌入将整数向量转化为密集向量。然后，卷积神经网络(CNN)提取AST令牌的语义。之后，双向长短期记忆(Bidirectional Long - short - Memory, Bi-LSTM)保留关键特征，忽略其他特征，以提高软件缺陷预测的准确性。提出的模型CBIL在PROMISE数据集的七个开源Java项目样本上进行了评估。","CBIL通过以下评价指标进行评价:F -measure和曲线下面积(AUC)。结果表明，与CNN相比，CBIL模型将F -measure的平均值提高了25%，因为CNN在所选的基线模型中实现了最高的性能。在AUC的平均值上，CBIL模型的AUC比RNN (Recurrent Neural Network, RNN)提高了18%，因为RNN在实验中所选择的基线模型中表现最好。",应用软件缺陷预测模型将其分为两种方法:第一种方法专注于源代码的传统特征，包括代码行数、平均方法复杂性等。然而，传统特征无法提取程序的语义信息，因为两个程序具有不同的语义，可能具有相同的传统特征值。提出了第二种方法，重点是确定如何提取程序的语义表示。近年来，深度学习在自动提取语义特征、提高软件缺陷预测精度和性能方面取得了重大进展。程序包含定义良好的语法结构和隐藏在两种程序表示中的语义信息(Li et al.， 2019b)。首先是抽象语法树(AST)，其次是控制流图(CFG)。在软件缺陷预测的研究中选择AST表示而不是CFG表示，因为它保留了源代码的详细信息。,跨版本/跨项目,"AST
选择以下类型的AST节点作为令牌生成:(1)控制流节点，如if/while/do语句，记录为节点的类型。(2).类实例创建和方法调用的节点，记录为类或方法的名称，不带括号(3).方法/类声明等声明的节点，记录为其名称。删除其他AST节点，因为它可能影响所选AST节点的重要性。选择的AST节点如图6所示。我们应用Python包“javalang”将源代码解析为AST。",CNN提取特征,为了保证数据的完整性，采用了“imblearn randomoverampler”方法进行过采样。它将随时间随机复制少数类的实例。,结果表明，在WPDP的F -measure平均值上，CBIL比基线模型提高了30%，比CNN提高了25%，因为CNN是所有基线模型中性能最好的。在平均AUC上，CBIL提高了基线模型21%，RNN提高了18%，因为RNN是所有基线模型中性能最好的。所提出的CBIL模型对WPDP和CPDP均取得了较好的效果。,从PROMISE数据集中抽取了7个用Java语言编写的开源项目,442-1837个文件,公开,完成,JAVA,CNN+biLSTM在测试集上应用逻辑回归分类器生成文件缺陷的概率。,文件级,故障倾向,F -measure和曲线下面积(AUC)，Precision and Recall,
"Qu, Yu; Yin, Heng",Evaluating network embedding techniques' performances in software bug prediction,EMPIRICAL SOFTWARE ENGINEERING,10.1007/s10664-021-09965-5,2021,"Software bug prediction techniques can be very helpful in testing and code inspection. Over the past decade, network measures have been successfully used in bug prediction. Following the same intuition, recently, researchers started using network embedding techniques in bug prediction. However, existing studies only evaluated the Skip-gram and CBOW models with random walk. Considering network embedding is a fast-developing research direction, it is important to evaluate other network embedding techniques' performances in bug prediction. Moreover, existing studies have not investigated the application and performance of network embedding in effort-aware bug prediction, which is thought to be a more realistic scenario that evaluates the cost effectiveness of bug prediction models. In this paper, we conduct an extensive empirical study to evaluate network embedding algorithms in bug prediction by utilizing and extending node2defect, a newly proposed bug prediction model that combines the embedded vectors with traditional software engineering metrics through concatenation. Experiments are conducted based on seven network embedding algorithms, two effort-aware models, and 13 open-source Java systems. Experimental results show that node2defect outperforms traditional metrics by + 14.64% in terms of MCC score, and by + 7.51% to + 16.57% in effort-aware bug prediction. More interestingly, when combined with CBS + , the embedded vectors alone can achieve the best performance. Among different network embedding algorithms, the newly proposed algorithm ProNE has the best performance.",3,本文利用并扩展了新提出的bug预测模型node2defect，将嵌入向量与传统软件工程度量通过串联结合起来，对网络嵌入算法在bug预测中的应用进行了广泛的实证研究。,软件bug预测技术在测试和代码检查中非常有用。在过去的十年中，网络度量已经成功地用于bug预测。根据同样的直觉，最近，研究人员开始在bug预测中使用网络嵌入技术。然而，现有的研究只评估了随机游走的Skip-gram和CBOW模型。考虑到网络嵌入是一个快速发展的研究方向，评估其他网络嵌入技术在bug预测中的性能是非常重要的。此外，现有研究尚未对网络嵌入在努力感知bug预测中的应用和性能进行研究，这被认为是评估bug预测模型成本效益的更现实的场景。,本文利用并扩展了新提出的bug预测模型node2defect，将嵌入向量与传统软件工程度量通过串联结合起来，对网络嵌入算法在bug预测中的应用进行了广泛的实证研究。实验基于7种网络嵌入算法、2种努力感知模型和13个开源Java系统。,实验结果表明，node2defect在MCC得分方面优于传统指标+ 14.64%，在努力感知错误预测方面优于传统指标+ 7.51% ~ + 16.57%。更有趣的是，当与CBS+结合使用时，单独使用嵌入向量可以达到最佳性能。在不同的网络嵌入算法中，新提出的算法性能最好。,本文使用的七种网络嵌入技术的基本信息:DeepWalk、GraRep、Line、node2vec、ProNE、SDNE和walklets。,版本内,网络度量、传统度量（代码度量和过程度量）,,在生成的CDN（类依赖网络）基础上，采用DeepWalk、GraRep、Line、node2vec、ProNE、SDNE、Walklets等7种网络嵌入技术，自动学习将CDN的结构编码为低维向量空间。,"我们认为这个结论非常有趣，因为它意味着与node2defect相比，单独的嵌入向量在工作感知错误预测中可以获得更好的性能，这意味着网络嵌入甚至可以在工作感知错误预测中取代传统的软件工程度量(CM)。此外，我们可以得出结论，努力感知模型CBS+更适合与网络嵌入一起用于bug预测。
实验结果表明，在不同的网络嵌入技术中，ProNE通常具有最好的性能。当使用ProNE时，node2defect在MCC得分方面优于传统软件工程指标+ 14.64%，并将AUC得分提高+ 4.92%。在努力感知错误预测实验中，当使用Ree和CBS+时，node2defect的性能分别优于传统指标+ 7.51%到+ 16.57%。更有趣的是，当嵌入向量单独与CBS+结合时，它们可以获得接近最优的性能，并且显著优于传统指标(+ 27.17%)，这意味着在这种设置下，网络嵌入可以取代传统指标进行努力感知的bug预测。总之，我们建议从业者在构建bug预测模型时总是使用网络嵌入技术，尤其是ProNE。此外，新提出的技术ProNE的优越性表明，软件bug预测可以不断受益于网络嵌入技术的最新进展。在努力感知的bug预测实践中，嵌入向量可以与CBS+相结合以获得最佳性能。在其他学科系统、评估场景和基线度量上的实验显示了我们结论的普遍性。",13个大型开源Java软件系统的数据集,25-311kLOC,公开,完成,JAVA,:随机森林(RF) (Breiman 2001)，逻辑回归(LR) (Hosmer et al. 2013)和支持向量机(SVM) ,类级,故障倾向,"Precision, Recall, F-measure, AUC, and MCC
使用两个努力件模型(Ree (Yang et al. 2015)和CBS+ (Huang et al. 2019))来生成测试集中类的排名列表",
"Munir, Hafiz Shahbaz; Ren, Shengbing; Mustafa, Mubashar; Siddique, Chaudry Naeem; Qayyum, Shazib",Attention based GRU-LSTM for software defect prediction,PLOS ONE,10.1371/journal.pone.0247444,2021,"Software defect prediction (SDP) can be used to produce reliable, high-quality software. The current SDP is practiced on program granular components (such as file level, class level, or function level), which cannot accurately predict failures. To solve this problem, we propose a new framework called DP-AGL, which uses attention-based GRU-LSTM for statement-level defect prediction. By using clang to build an abstract syntax tree (AST), we define a set of 32 statement-level metrics. We label each statement, then make a three-dimensional vector and apply it as an automatic learning model, and then use a gated recurrent unit (GRU) with a long short-term memory (LSTM). In addition, the Attention mechanism is used to generate important features and improve accuracy. To verify our experiments, we selected 119,989 C/C++ programs in Code4Bench. The benchmark tests cover various programs and variant sets written by thousands of programmers. As an evaluation standard, compared with the state evaluation method, the recall, precision, accuracy and F1 measurement of our well-trained DP-AGL under normal conditions have increased by 1%, 4%, 5%, and 2% respectively.",3,我们提出了一个新的框架DP-AGL，它使用基于注意力的GRU-LSTM进行语句级缺陷预测。通过使用clang构建抽象语法树(AST)，我们定义了一组32个语句级指标。我们标记每个语句，然后制作三维向量并将其作为自动学习模型，然后使用具有长短期记忆(LSTM)的门控循环单元(GRU)。,软件缺陷预测(SDP)可以用于生产可靠、高质量的软件。当前的SDP是在程序粒度组件(如文件级、类级或函数级)上实践的，它不能准确地预测故障。,"为了解决这个问题，我们提出了一个新的框架DP-AGL，它使用基于注意力的GRU-LSTM进行语句级缺陷预测。通过使用clang构建抽象语法树(AST)，我们定义了一组32个语句级指标。我们标记每个语句，然后制作一个三维向量并将其应用于自动学习模型，然后使用具有长期短期记忆(LSTM)的聚合循环单元(GRU)。此外，注意机制用于生成重要特征和提高准确性。为了验证我们的实验，我们在code4bench中选择了119,989个C/ c++程序。基准测试涵盖了由数千名程序员编写的各种程序和变体集。","我们在100,000个code4bench C/ c++程序上对DP-AGL进行了评估。我们训练良好的DP-AGL模型在召回率、精密度、准确度和F1指标方面的平均性能分别为0.98、0.617、0.75和0.757。DP-AGL是句子级粒度的新方法，比SLDeep和Random Forest更有效。","包含这些类型的结构信息和缺陷预测语义的功能应该提高性能。代码语义和语法结构的丰富功能具有特定的统计功能，而ast[10]隐藏了这些特定的统计功能，有助于更准确地定位和分析故障
我们可以用两种方式表达代码的语法和语义信息。一种是控制流图(CFG)，另一种是抽象语法树(AST)[38]。",跨版本,AST，图中所示节点定义了22个内部线性度量和10个外部线性度量,,,,Code4Bench用于C/ c++代码[16]，其中包含由不同开发人员针对不同问题编写的代码,"119,989个主题程序包含2,356,458行代码和2,920,64行缺陷行",公开,完成,C/C++,"基于注意力的GRU-LSTM (DP-AGL)
Bi-LSTM和门控循环单元(GRU)",语句级,故障倾向,"accuracy, precision, recall and F-measurement",随机森林和SLDeep是怎样训练的
"Mumtaz, Bushra; Kanwal, Summrina; Alamri, Sultan; Khan, Faiza",Feature Selection Using Artificial Immune Network: An Approach for Software Defect Prediction,INTELLIGENT AUTOMATION AND SOFT COMPUTING,10.32604/iasc.2021.018405,2021,"Software Defect Prediction (SDP) is a dynamic research field in the software industry. A quality software product results in customer satisfaction. However, the higher the number of user requirements, the more complex will be the software, with a correspondingly higher probability of failure. SDP is a challenging task requiring smart algorithms that can estimate the quality of a software component before it is handed over to the end-user. In this paper, we propose a hybrid approach to address this particular issue. Our approach combines the feature selection capability of the Optimized Artificial Immune Networks (Opt-aiNet) algorithm with benchmark machine-learning classifiers for the better detection of bugs in software modules. Our proposed methodology was tested and validated using 5 open-source National Aeronautics and Space Administration (NASA) data sets from the PROMISE repository: CM1, KC2, JM1, KC1 and PC1. Results were reported in terms of accuracy level and of an AUC with highest accuracy, namely, 94.82%. The results of our experiments indicate that the detection capability of benchmark classifiers can be improved by incorporating Opt-aiNet as a feature selection (FS) method.",3,本文中，我们提出了一种混合方法来解决这一特定问题。我们的方法结合了优化人工免疫网络(Opt-aiNet)算法的特征选择能力和基准机器学习分类器，以便更好地检测软件模块中的错误。,软件缺陷预测(SDP)是软件行业的一个动态研究领域。高质量的软件产品会使客户满意。然而，用户需求的数量越多，软件就越复杂，相应的故障概率也就越高。SDP是一项具有挑战性的任务，需要能够在软件组件交付给最终用户之前评估其质量的智能算法。,"在本文中，我们提出了一种混合方法来解决这一特定问题。我们的方法结合了优化人工免疫网络(Opt-aiNet)算法的特征选择能力和基准机器学习分类器，以便更好地检测软件模块中的错误。我们提出的方法使用来自PROMISE存储库的5个开源美国国家航空航天局(NASA)数据集进行了测试和验证:CM1,KC2,JM1, kc1和PC1。",。实验结果表明，该方法具有较好的性能。结果还表明，具有Opt-aiNet特征的DT分类器的选择技术优于所有其他分类器。它显著提高了所有项目的预测精度，JM1数据集的精度提高最多，为94.82%，CM1数据集的精度提高最少，为84.55%。,"但令人遗憾的是，FS对于构建一致和高性能预测模型的重要性经常被忽视。如果应用FS技术从数据集中消除不相关的特征，则这些模型的性能会提高[5,6]。",版本内,22个方法级度量,Opt-aiNet（Optimized Artificial Immune Network (Opt-aiNet)）这是一种离散免疫网络算法，通过克隆扩展、突变、选择和相互作用产生群体[27]。种群由抗体网络(被优化函数的候选解)组成。然后根据目标函数、克隆扩增、突变、选择和相互作用对群体进行评价。Opt-aiNet创建一组记忆抗体，代表(随着时间的推移)目标函数的最佳候选解决方案。Opt-aiNet能够进行单模态和多模态优化。,,结果表明，Opt-aiNet在FS分类器中的应用显著提高了分类器的性能。,NASA开源MDP数据集是最常用于SDP问题的数据集[27]。本研究使用了五个最常用的数据集，分别是KC1、KC2、CM1、PC1和JM1,505-10885个模块,公开,完成,C/C++,支持向量机(SVM)、k近邻(KNN)、朴素贝叶斯(NB)、决策树(DT)、线性判别分析(LDA)和随机森林(RF)，,模块级,故障倾向,accuracy and AUC.,
"Balogun, Abdullateef O.; Basri, Shuib; Mahamad, Saipunidzam; Capretz, Luiz Fernando; Imam, Abdullahi Abubakar; Almomani, Malek A.; Adeyemo, Victor E.; Kumar, Ganesh",A Novel Rank Aggregation-Based Hybrid Multifilter Wrapper Feature Selection Method in Software Defect Prediction,COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,10.1155/2021/5069016,2021,"The high dimensionality of software metric features has long been noted as a data quality problem that affects the performance of software defect prediction (SDP) models. This drawback makes it necessary to apply feature selection (FS) algorithm(s) in SDP processes. FS approaches can be categorized into three types, namely, filter FS (FFS), wrapper FS (WFS), and hybrid FS (HFS). HFS has been established as superior because it combines the strength of both FFS and WFS methods. However, selecting the most appropriate FFS (filter rank selection problem) for HFS is a challenge because the performance of FFS methods depends on the choice of datasets and classifiers. In addition, the local optima stagnation and high computational costs of WFS due to large search spaces are inherited by the HFS method. Therefore, as a solution, this study proposes a novel rank aggregation-based hybrid multifilter wrapper feature selection (RAHMFWFS) method for the selection of relevant and irredundant features from software defect datasets. The proposed RAHMFWFS is divided into two stepwise stages. The first stage involves a rank aggregation-based multifilter feature selection (RMFFS) method that addresses the filter rank selection problem by aggregating individual rank lists from multiple filter methods, using a novel rank aggregation method to generate a single, robust, and non-disjoint rank list. In the second stage, the aggregated ranked features are further preprocessed by an enhanced wrapper feature selection (EWFS) method based on a dynamic reranking strategy that is used to guide the feature subset selection process of the HFS method. This, in turn, reduces the number of evaluation cycles while amplifying or maintaining its prediction performance. The feasibility of the proposed RAHMFWFS was demonstrated on benchmarked software defect datasets with Naive Bayes and Decision Tree classifiers, based on accuracy, the area under the curve (AUC), and F-measure values. The experimental results showed the effectiveness of RAHMFWFS in addressing filter rank selection and local optima stagnation problems in HFS, as well as the ability to select optimal features from SDP datasets while maintaining or enhancing the performance of SDP models. To conclude, the proposed RAHMFWFS achieved good performance by improving the prediction performances of SDP models across the selected datasets, compared to existing state-of-the-arts HFS methods.",3,本研究提出了一种新的基于秩聚集的混合多滤波器包装特征选择(RAHMFWFS)方法，用于从软件缺陷数据集中选择相关和非冗余特征。,软件度量特征的高维性一直是影响软件缺陷预测(SDP)模型性能的数据质量问题。它的缺点使得在SDP过程中应用特征选择(FS)算法成为必要。FS方法可以分为三种类型，即过滤器FS (FFS)、包装器FS (WFS)和混合FS (HFS)。HFS结合了FFS和WFS两种方法的优点，具有较强的优越性。然而，为HFS选择最合适的FFS(过滤器等级选择问题)是一个挑战，因为FFS方法的性能取决于数据集和分类器的选择。此外，HFS方法还继承了WFS方法由于搜索空间大而导致的局部最优停滞和计算成本高的缺点,因此，作为解决方案，本研究提出了一种新的基于秩聚集的混合多滤波器包装特征选择(RAHMFWFS)方法，用于从软件缺陷数据集中选择相关和不冗余的特征。他提出的RAHMFWFS分为两个阶段。第一阶段涉及基于秩聚合的多过滤器特征选择(RMFFS)方法，该方法通过聚合来自多个过滤器方法的单个秩列表来解决过滤器秩选择问题，使用一种新颖的秩聚合方法来生成单个、鲁棒且不分离的秩列表。第二阶段，采用基于动态重排序策略的增强型包装器特征选择(EWFS)方法对聚合排序后的特征进行预处理，该方法用于指导HFS方法的特征子集选择过程。，从而减少了评估周期的次数，同时放大或保持了其预测性能。基于准确率、曲线下面积(AUC)和f测量值，利用纳维贝叶斯和决策树分类器在基准软件缺陷数据集上验证了所提出的RAHMFWFS的可行性。,实验结果证明了RAHMFWFS技术的有效性，在大多数情况下，与现有的HFS方法相比，RAHMFWFS技术对NB和DT模型的预测性能有更大的积极影响。因此，所提出的RAHMFWFS方法能够通过部署和集成基于秩聚合的多过滤器方法和针对这两个问题的动态重新排序策略解决方案，分别解决HFS方法中的过滤器秩选择和局部停滞问题。此外，RAHMFWFS方法记录了从SDP数据集中选择最优特征的能力，同时保持或增强了SDP模型的性能。,"研究人员一致认为特征选择(FS)方法是解决高维问题的有效方法。对于每个SDP过程，这些FS方法本质上是从初始软件缺陷数据集中选择有价值和关键的软件特征[23-26]。FS方法有三种，即过滤器FS (FFS)、包装器FS (WFS)和混合FS (HFS)。FFS方法的计算复杂度较低，但分类算法对此类过滤后的数据的预测性能无法保证[30-32]。另一方面，WFS方法保证了良好的预测性能，但代价是计算复杂度高，缺乏泛化能力[31,33]。HFS方法结合了FFS和WFS方法的优点[34,35]。然而，过滤等级选择问题和复杂的搜索策略是HFS方法固有的局限性/缺点。特别是，为HFS选择最合适的过滤方法是困难的，因为FFS方法的性能取决于数据集和分类器的选择[36-41]。",版本内,不同项目具有不同度量,基于秩聚合的混合多滤波器包装特征选择(RAHMFWFS)方法，第一阶段涉及基于秩聚合的多滤波器特征选择(RMFFS)方法。在第二阶段，利用基于重新排序策略的增强包装器特征选择(EWFS)方法对聚合的排序特征进行进一步预处理。,,总之，所提出的RAHMFWFS侧重于为SDP过程选择最优特征，同时保持或增强SDP模型的预测性能。实验结果证明了所提出的RAHMFWFS的优越性，根据经验和统计检验结果，该方法优于现有的HFS方法。在大多数实验中，RAHMFWFS显著优于RMFFS和EWFS。这可以归因于RAHMFWFS是RMFFS和EWFS方法的混合。因此，这些结果表明，RAHMFWFS可以有效和实际地用于SDP过程中的高维问题。,使用了来自四个可公开访问的存储库的缺陷数据集。从PROMISE、NASA、AEEEM和ReLink存储库中选择了25个不同粒度的数据集,56-1862个模块,公开,完成,JAVA/C等,决策树(DT)和朴素贝叶斯(NB),模块级,故障倾向,"accuracy, the area under the curve (AUC), and F-measure",
"Ali, Aftab; Khan, Naveed; Abu-Tair, Mamun; Noppen, Joost; McClean, Sally; McChesney, Ian",Discriminating features-based cost-sensitive approach for software defect prediction,AUTOMATED SOFTWARE ENGINEERING,10.1007/s10515-021-00289-8,2021,"Correlated quality metrics extracted from a source code repository can be utilized to design a model to automatically predict defects in a software system. It is obvious that the extracted metrics will result in a highly unbalanced data, since the number of defects in a good quality software system should be far less than the number of normal instances. It is also a fact that the selection of the best discriminating features significantly improves the robustness and accuracy of a prediction model. Therefore, the contribution of this paper is twofold, first it selects the best discriminating features that help in accurately predicting a defect in a software component. Secondly, a cost-sensitive logistic regression and decision tree ensemble-based prediction models are applied to the best discriminating features for precisely predicting a defect in a software component. The proposed models are compared with the most recent schemes in the literature in terms of accuracy, area under the curve, and recall. The models are evaluated using 11 datasets and it is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.",3,首先，它选择了最好的区分特征，帮助准确地预测软件组件中的缺陷。其次，将成本敏感逻辑回归和基于决策树集成的预测模型应用于最佳判别特征，以精确预测软件组件中的缺陷。,从源代码存储库中提取的相关质量度量可以用来设计一个模型来自动预测软件系统中的缺陷。很明显，提取的度量将导致高度不平衡的数据，因为在一个高质量的软件系统中缺陷的数量应该远远少于正常实例的数量。事实上，选择最佳的判别特征可以显著提高预测模型的鲁棒性和准确性。,因此，本文的贡献是双重的，首先，它选择了最好的区分特征，帮助准确地预测软件组件中的缺陷。其次，将成本敏感逻辑回归和基于决策树集成的预测模型应用于最佳判别特征，以精确预测软件组件中的缺陷。提出的模型在准确性、曲线下面积和召回率方面与文献中最新的方案进行了比较。使用11个数据集对模型进行了评估，,将所提方案的性能与现有方案进行了比较，结果表明所提方案在准确率、AUC和召回率方面表现更好。,方差分析(ANOVA) Freedman(2009)是一种用于检查两个或多个特征的均值是否彼此显著不同的统计度量。,版本内,每个数据集具有不同度量,对于特征选择过程，我们使用方差分析f值(即输入度量和输出度量之间的线性程度的估计)。ANOVA f值依次应用于所有特征，然后根据类别选择那些更具区别性的特征。基于方差分析f值的特征选择过程将尽可能频繁地从数据集中去除冗余和不相关的特征，并选择最优特征子集来精确预测缺陷。重要或最佳特征对任何分类算法的结果都有影响，即使在减少训练数据集的情况下也可以提高性能效率。显著/最佳特征分析提高了分类器训练和测试的可扩展性和处理效率。,,,使用了来自PROMISE Shirabad和Menzies(2005)软件工程存储库的11个数据集,未知,公开,完成,C等,基于最佳特征的成本敏感逻辑回归(CLR)和决策树集成(CDTE)模型来预测软件缺陷,未知,故障倾向,"准确度、曲线下面积(AUC)、召回率、精密度、f值、平均绝对误差(MAE)和均方根误差(RMSE)。accuracy, area under the curve (AUC), recall, precision, F-measure, Mean Absolute Error (MAE), and root mean square error (RMSE).",
"Harzevili, Nima Shiri; Alizadeh, Sasan H.",Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables,NEUROCOMPUTING,10.1016/j.neucom.2021.05.043,2021,"Software defect prediction constitutes an important discipline in software development life-cycle. Among the techniques employed in this domain, Naive Bayes (NB) classifier is cited by a large number of researchers for its simple structure and remarkable classification performance notwithstanding the concern of whether it is theoretically justified or not. More concisely, NB is fundamentally built on the strong assumption of conditional independence of attributes, and the major question here is the compliance of software metrics with this assumption. To address this question, we propose a novel framework MLMNB-SDP equipped with a statistical hypothesis testing method to detect those software metrics with a significant conditional dependency. MLMNB-SDP is designed to handle conditional dependencies via a single latent variable in a predefined structure which is responsible for preserving the connection between pairs of software metrics when the class variables are instantiated. We evaluate the effectiveness of our approach based on its capability to measure conditional dependency of software metrics and defect prediction performance. For the former one, we employ Conditional Mutual Information (CMI), and for the later one we use three settings for defect prediction; (1) Within-Project Defect Prediction (WPDP), (2) Cross-Project Defect-Prediction (CPDP), and (3) stratified k-fold cross validation. Our metrics dependency analysis results indicate that traditional file-level software metrics demonstrate a significant conditional mutual dependency and the application of naive Bayes classifier in this domain is not theoretically acceptable. Our results based on the three settings indicate that MLMNB-SDP improves naive Bayes classifier 5.45% to 75.86% and outperforms well-known benchmark classifiers, i.e., Random Forest and Logistic Regression, regarding a significant increase in Precision, Recall, and F1 Score, Mathew's Correlation Coefficient (MCC), and area under the ROC curve (AUC) values. (c) 2021 Elsevier B.V. All rights reserved.",3,"我们基于测量软件度量的条件依赖性和缺陷预测性能的能力来评估我们方法的有效性,指标依赖分析","软件缺陷预测是软件开发生命周期中的一门重要学科。在该领域所采用的技术中，朴素贝叶斯分类器(Naive Bayes, NB)因其结构简单、分类性能优异而被大量研究人员引用，但其理论是否合理一直备受关注。更简单地说，NB从根本上是建立在属性条件独立的强大假设之上的，这里的主要问题是软件度量是否符合这个假设。",为了解决这个问题，我们提出了一个新的框架“MLMNB-SDP”，它配备了一个统计假设检验方法来检测那些具有显著条件依赖性的软件指标。MLMNB-SDP旨在通过预定义结构中的单个潜在变量来处理条件依赖性，该结构负责在类变量实例化时保留软件度量对之间的连接。我们基于测量软件度量的条件依赖性和缺陷预测性能的能力来评估我们方法的有效性。对于前者，我们采用了条件互信息(CMI)，对于后者，我们使用了三种设置来进行缺陷预测;(1)项目内缺陷预测(WPDP)，(2)跨项目缺陷预测(CPDP)，(3)分层k-fold交叉验证。,我们的指标依赖分析结果表明，传统的文件级软件指标表现出显著的条件相互依赖，朴素贝叶斯分类器在该领域的应用在理论上是不可接受的。我们基于这三种设置的结果表明，MLMNB-SDP将朴素贝叶斯分类器的准确率提高了5.45%至75.86%，并且在精度、召回率、F1分数、马修相关系数(MCC)和ROC曲线下面积(AUC)值方面显著提高，优于随机森林和Logistic回归等知名基准分类器。,,跨版本/跨项目,JAVA的和C/C++的数据集具有不同度量,选择k - best metrics:在本文中，我们选择k个对分类贡献最大的最佳指标,,在跨项目领域，我们从不同版本的项目中选择训练集和测试集。我们在这种情况下获得的结果表明，与基准算法相比，MLMNB-SDP提高了缺陷分类性能。更具体地说，改进的范围是12.50%到40.62%。为了进行10倍交叉验证，我们使用了来自NASA存储库的4个数据集以及来自Java项目的22个数据集。在这个设置中，我们使用单独的版本进行培训和测试操作。我们的研究结果表明，MLMNB-SDP显著改善了基准分类算法。例如，就F1 Score、MCC和AUC而言，根据表19所示的排名测试结果，我们的框架是第二好的分类器。,在这项研究中，我们分析了10个Java项目，对于每个项目，我们使用了PROMISE软件工程存储库中的两个版本，还有4个来自NASA,122-740个实例,公开,完成,C/C++/JAVA,"MLMNB[22]确实是朴素贝叶斯分类器的扩展，它在其结构中加入了一个离散潜在变量来模拟属性之间的条件依赖性。N.S. Harzevili, S.H. Alizadeh, Mixture of latent multinomial naive bayes classifier, Appl. Soft Comput.",文件级,故障倾向,"Precision, Recall, and F1 Score, Mathew’s Correlation Coefficient (MCC), and area under the ROC curve (AUC)",
"Aziz, Syed Rashid; Khan, Tamim Ahmed; Nadeem, Aamer",Exclusive use and evaluation of inheritance metrics viability in software fault prediction an experimental study,PEERJ COMPUTER SCIENCE,10.7717/peerj-cs.563,2021,"Software Fault Prediction (SFP) assists in the identification of faulty classes, and software metrics provide us with a mechanism for this purpose. Besides others, metrics addressing inheritance in Object-Oriented (OO) are important as these measure depth, hierarchy, width, and overriding complexity of the software. In this paper, we evaluated the exclusive use, and viability of inheritance metrics in SFP through experiments. We perform a survey of inheritance metrics whose data sets are publicly available, and collected about 40 data sets having inheritance metrics. We cleaned, and filtered them, and captured nine inheritance metrics. After preprocessing, we divided selected data sets into all possible combinations of inheritance metrics, and then we merged similar metrics. We then formed 67 data sets containing only inheritance metrics that have nominal binary class labels. We performed a model building, and validation for Support Vector Machine(SVM). Results of Cross-Entropy, Accuracy, F-Measure, and AUC advocate viability of inheritance metrics in software fault prediction. Furthermore, ic, noc, and dit metrics are helpful in reduction of error entropy rate over the rest of the 67 feature sets.",3,本文通过实验对SFP中继承度量的独占性和可行性进行了评价。我们对数据集公开可用的继承指标进行了调查，并收集了大约40个具有继承指标的数据集。,软件故障预测(SFP)有助于识别故障类，软件度量为我们提供了一种机制。除此之外，在面向对象(OO)中处理继承的度量也很重要，因为这些度量深度、层次、宽度和覆盖软件的复杂性。,本文通过实验对SFP中继承度量的独占性和可行性进行了评价。我们对数据集公开可用的继承指标进行了调查，并收集了大约40个具有继承指标的数据集。我们清理并过滤了它们，并捕获了9个继承指标。预处理后，我们将选定的数据集划分为所有可能的继承指标组合，然后合并相似的指标。然后，我们形成67个数据集，其中仅包含具有标称二进制类标签的继承度量。我们对支持向量机(SVM)进行了模型构建和验证。,交叉熵、精度、F-Measure和AUC的结果支持继承度量在软件故障预测中的可行性。此外，ic、noc和dit指标有助于减少67个特征集中其余部分的错误熵率。,,版本内,67个不同的继承度量,,,"支持向量机的一致性表明，具有一组共同特征的继承度量可以实现最小的熵率。整体{fanIn, fanOut, noc, noai, nomi}和单独{dit, ic, noc, mfa}被证明是熵率最小的最佳预测因子，而{dit}， {noc}， {ic}有助于降低熵率。我们报告说，添加继承度量对于预测错误是有用的。这些发现也通过准确性、F-Measure和AUC的性能测量得到验证。",对40个原数据集进行度量组合成为365个数据集,7-18471个实例,公开,完成,JAVA等,SVM,实例级,故障倾向,"cross entropy losses, Accuracy, F-Measure and AUC",
"Yang, Xingguang; Yu, Huiqun; Fan, Guisheng; Yang, Kang",DEJIT: A Differential Evolution Algorithm for Effort-Aware Just-in-Time Software Defect Prediction,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194021500108,2021,"Software defect prediction is an effective approach to save testing resources and improve software quality, which is widely studied in the field of software engineering. The effort-aware just-in-time software defect prediction (JIT-SDP) aims to identify defective software changes in limited software testing resources. Although many methods have been proposed to solve the JIT-SDP, the effort-aware prediction performance of the existing models still needs to be further improved. To this end, we propose a differential evolution (DE) based supervised method DEJIT to build JIT-SDP models. Specifically, first we propose a metric called density-percentile-average (DPA), which is used as optimization objective on the training set. Then, we use logistic regression (LR) to build a prediction model. To make the LR obtain the maximum DPA on the training set, we use the DE algorithm to determine the coefficients of the LR. The experiment uses defect data sets from six open source projects. We compare the proposed method with state-of-the-art four supervised models and four unsupervised models in cross-validation, cross-project-validation and timewise-cross-validation scenarios. The empirical results demonstrate that the DEJIT method can significantly improve the effort-aware prediction performance in the three evaluation scenarios. Therefore, the DEJIT method is promising for the effort-aware JIT-SDP.",3,我们提出了一种基于差分进化(DE)的监督方法DEJIT来构建JIT-SDP模型。具体来说，我们首先提出了一种称为密度-百分位数-平均(DPA)的度量,软件缺陷预测是节省测试资源、提高软件质量的有效手段，在软件工程领域得到了广泛的研究。实时软件缺陷预测(JIT-SDP)的目标是在有限的软件测试资源中识别有缺陷的软件变更。虽然已经提出了许多方法来解决JIT-SDP问题，但现有模型的努力感知预测性能仍有待进一步提高。,为此，我们提出了一种基于差分进化(DE)的监督方法DEJIT来构建JIT-SDP模型。具体来说，我们首先提出了一种称为密度-百分位数-平均(DPA)的度量，将其用作训练集上的优化目标。然后，我们使用逻辑回归(LR)来建立预测模型。为了使LR在训练集上获得最大的DPA，我们使用DE算法来确定LR的系数。该实验使用了来自六个开源项目的缺陷数据集。我们在交叉验证、跨项目验证和时间交叉验证场景中将所提出的方法与最先进的四个监督模型和四个无监督模型进行了比较。,实验结果表明，与最佳基线模型相比，DEJIT方法在交叉验证、跨项目验证和时间交叉验证场景下的Popt分别提高了15.4%、13.3%和8.9%。此外，与最佳基线模型相比，DEJIT方法在三种情景下的ACC指标分别提高了25.8%、28.9%和30.7%。因此，我们建议使用DEJIT来解决努力感知的JITSDP问题。,,版本内/跨版本,"我们提出了一个称为DPA的度量来评估模型关于缺陷密度的排名性能。
为了准确地预测变更的缺陷倾向，Kamei等人[6]设计了14个与缺陷相关的度量。这些指标可以分为五个维度，即传播、规模、目的、历史和经验",,,,实验使用了Bugzilla (BUG)、Columba (COL)、Eclipse JDT (JDT)、Mozilla (MOZ)、Eclipse Platform (PLA)、PostgreSQL (POS) 6个开源项目的缺陷数据集。,4-98k个变更,公开,完成,JAVA等,逻辑回归,语句级,故障倾向,ACC and Popt,
"Muhammad, Rizwan; Nadeem, Aamer; Sindhu, Muddassar Azam",Vovel metrics-novel coupling metrics for improved software fault prediction,PEERJ COMPUTER SCIENCE,10.7717/peerj-cs.590,2021,"Software is a complex entity, and its development needs careful planning and a high amount of time and cost. To assess quality of program, software measures are very helpful. Amongst the existing measures, coupling is an important design measure, which computes the degree of interdependence among the entities of a software system. Higher coupling leads to cognitive complexity and thus a higher probability occurrence of faults. Well in time prediction of fault-prone modules assists in saving time and cost of testing. This paper aims to capture important aspects of coupling and then assess the effectiveness of these aspects in determining fault-prone entities in the software system. We propose two coupling metrics, i.e., Vovel-in and Vovel-out, that capture the level of coupling and the volume of information flow. We empirically evaluate the effectiveness of the Vovel metrics in determining the fault-prone classes using five projects, i.e., Eclipse JDT, Equinox framework, Apache Lucene, Mylyn, and Eclipse PDE UI. Model building is done using univariate logistic regression and later Spearman correlation coefficient is computed with the existing coupling metrics to assess the coverage of unique information. Finally, the least correlated metrics are used for building multivariate logistic regression with and without the use of Vovel metrics, to assess the effectiveness of Vovel metrics. The results show the proposed metrics significantly improve the predicting of fault prone classes. Moreover, the proposed metrics cover a significant amount of unique information which is not covered by the existing well-known coupling metrics, i.e., CBO, RFC, Fan-in, and Fan-out. This paper, empirically evaluates the impact of coupling metrics, and more specifically the importance of level and volume of coupling in software fault prediction. The results advocate the prudent addition of proposed metrics due to their unique information coverage and significant predictive ability.",3,我们提出了两个耦合度量，即Vovel-in和Vovel-out，它们捕获耦合级别和信息流的数量。,软件是一个复杂的实体，它的开发需要仔细的计划和大量的时间和成本。要评估程序的质量，软件度量是非常有帮助的。在现有的度量中，耦合是一个重要的设计度量，它计算软件系统实体之间的相互依赖程度。更高的耦合导致认知复杂性，从而导致更高的故障发生概率。对易发生故障的模块进行及时的预测，有助于节省测试时间和成本。,本文旨在捕捉耦合的重要方面，然后评估这些方面在确定软件系统中易出错实体方面的有效性。我们提出了两个耦合度量，即vovelin和Vovelout，它们捕获耦合级别和信息流的量。我们使用五个项目，即Eclipse JDT、Equinox框架、Apache Lucene、Mylyn和Eclipse PDE UI，对Vovel指标在确定易出错类方面的有效性进行了实证评估。利用单变量逻辑回归建立模型，然后利用现有的耦合度量计算Spearman相关系数来评估唯一信息的覆盖率。最后，最小相关指标用于建立多元逻辑回归，有无使用Vovel指标，以评估Vovel指标的有效性。,结果表明，所提出的指标显著提高了对易故障类别的预测。此外，建议的指标涵盖了大量的唯一信息，而现有的知名耦合指标(即CBO、RFC、Fan-in和Fan-out)没有涵盖这些信息。本文对耦合度量的影响进行了实证评估，更具体地说，是对耦合水平和耦合量在软件故障预测中的重要性进行了评估。由于其独特的信息覆盖范围和显著的预测能力，结果提倡谨慎地添加所提议的度量。,,版本内,"我们提出了两个新的耦合度量，命名为;vovel-in和vovel-out分别为向内和向外。
之前的度量Ce CBO RFC Fan-in Fan-out",,,,"五个项目的故障数据集：Eclipse JDT Core 3.4 (www.eclipse. org/jdt/core/), Equinox framework 3.4 (www.eclipse.org/equinox/), Apache Lucene 2.4 (lucene.apache.org), Mylyn 3.1 (www.eclipse.org/mylyn/), and Eclipse PDE UI 3.4.1 (www.eclipse.org/pde/pde-ui/).",,公开,完成,JAVA,多元逻辑回归MLR,,故障倾向,"F1 score, AUC, and MCC.",
"Ulan, Maria; Lowe, Welf; Ericsson, Morgan; Wingkvist, Anna",Weighted software metrics aggregation and its application to defect prediction,EMPIRICAL SOFTWARE ENGINEERING,10.1007/s10664-021-09984-2,2021,"It is a well-known practice in software engineering to aggregate software metrics to assess software artifacts for various purposes, such as their maintainability or their proneness to contain bugs. For different purposes, different metrics might be relevant. However, weighting these software metrics according to their contribution to the respective purpose is a challenging task. Manual approaches based on experts do not scale with the number of metrics. Also, experts get confused if the metrics are not independent, which is rarely the case. Automated approaches based on supervised learning require reliable and generalizable training data, a ground truth, which is rarely available. We propose an automated approach to weighted metrics aggregation that is based on unsupervised learning. It sets metrics scores and their weights based on probability theory and aggregates them. To evaluate the effectiveness, we conducted two empirical studies on defect prediction, one on ca. 200 000 code changes, and another ca. 5 000 software classes. The results show that our approach can be used as an agnostic unsupervised predictor in the absence of a ground truth.",3,我们提出了一种基于无监督学习的加权指标聚合的自动化方法。,在软件工程中，为了各种目的(比如它们的可维护性或它们包含bug的倾向)，聚合软件度量来评估软件工件是一个众所周知的实践。对于不同的目的，不同的度量标准可能是相关的。然而，根据它们对各自目的的贡献对这些软件度量进行加权是一项具有挑战性的任务。基于专家的手动方法不能随度量的数量而扩展。此外，如果指标不是独立的，专家也会感到困惑，而这种情况很少发生。基于监督学习的自动化方法需要可靠和可推广的训练数据，这是一个基本事实，很少可用。,我们提出了一种基于无监督学习的加权指标聚合的自动化方法。它根据概率论设置度量分数和它们的权重，并汇总它们。为了评估有效性，我们对缺陷预测进行了两项实证研究，一项针对大约20万个代码变更，另一项针对大约5000个软件类。,结果表明，在缺乏基本事实的情况下，我们的方法可以用作不可知的无监督预测器。,,版本内,代码变更度量和CK，OO度量,,通过将不同度量聚合为一个值来衡量软件质量，并对其进行排序,但我们既不主张也不打算提出最好的bug预测方法。它只表明，当缺乏真实数据时，质量目标不可知、无监督聚合方法是一种合适的替代方法(即使在bug预测中也是如此)。,具有两个数据集,"4-98k变更
300-1800个类",公开,完成,JAVA等,"聚合技术
无监督方法",类级,故障倾向,"Popt , Recall, Precision,andF1 score",无监督预测方法
"Shao, Yanli; Zhao, Jingru; Wang, Xingqi; Wu, Weiwei; Fang, Jinglong",Research on Cross-Company Defect Prediction Method to Improve Software Security,SECURITY AND COMMUNICATION NETWORKS,10.1155/2021/5558561,2021,"As the scale and complexity of software increase, software security issues have become the focus of society. Software defect prediction (SDP) is an important means to assist developers in discovering and repairing potential defects that may endanger software security in advance and improving software security and reliability. Currently, cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) are widely studied to improve the defect prediction performance, but there are still problems such as inconsistent metrics and large differences in data distribution between source and target projects. Therefore, a new CCDP method based on metric matching and sample weight setting is proposed in this study. First, a clustering-based metric matching method is proposed. The multigranularity metric feature vector is extracted to unify the metric dimension while maximally retaining the information contained in the metrics. Then use metric clustering to eliminate metric redundancy and extract representative metrics through principal component analysis (PCA) to support one-to-one metric matching. This strategy not only solves the metric inconsistent and redundancy problem but also transforms the cross-company heterogeneous defect prediction problem into a homogeneous problem. Second, a sample weight setting method is proposed to transform the source data distribution. Wherein the statistical source sample frequency information is set as an impact factor to increase the weight of source samples that are more similar to the target samples, which improves the data distribution similarity between the source and target projects, thereby building a more accurate prediction model. Finally, after the above two-step processing, some classical machine learning methods are applied to build the prediction model, and 12 project datasets in NASA and PROMISE are used for performance comparison. Experimental results prove that the proposed method has superior prediction performance over other mainstream CCDP methods.",3,本文提出了一种基于度量匹配和样本权值设置的CCDP方法,"随着软件规模和复杂性的增加，软件安全问题已成为社会关注的焦点。软件缺陷预测(Software defect prediction, SDP)是帮助开发人员提前发现和修复可能危及软件安全的潜在缺陷，提高软件安全性和可靠性的重要手段。目前，为了提高缺陷预测的性能，跨项目缺陷预测(CPDP)和跨公司缺陷预测(CCDP)得到了广泛的研究，但仍存在度量不一致、源项目和目标项目之间数据分布差异大等问题。",因此，本文提出了一种基于度量匹配和样本权值设置的CCDP方法。首先，提出一种基于聚类的度量匹配方法。提取多粒度度量特征向量，统一度量维度，最大限度地保留度量中包含的信息。然后利用度量聚类消除度量冗余，并通过主成分分析(PCA)提取有代表性的度量，实现一对一的度量匹配。该策略不仅解决了度量不一致和冗余问题，而且将跨公司的异质缺陷预测问题转化为同质问题。其次，提出了一种样本权值设置方法来变换源数据的分布;其中，将统计源样本频率信息作为影响因子，增加与目标样本更相似的源样本权重，提高源项目与目标项目之间数据分布的相似度，从而构建更准确的预测模型。最后，在经过上述两步处理后，应用经典机器学习方法构建预测模型，并使用NASA和PROMISE的12个项目数据集进行性能比较。,实验结果表明，该方法具有优于其他主流CCDP方法的预测性能。,CCDP(跨公司)的目标是在具有不同度量、不同数据集大小和不同数据分布的跨公司项目之间实现准确的缺陷预测。CPDP主要是指当源项目和目标项目的度量数和含义基本相同时的缺陷预测,跨项目(跨公司),NASA和PROMISE的度量数分别为37和20，具体度量含义如表3和表4所示;,充足的基于选择的权重设置:即使度量是统一的，源数据集和目标数据集在数据分布上仍然存在差异，这降低了缺陷预测模型的有效性和准确性。因此，采用基于样本选择的样本权重设置方法来调整源数据的分布。关键是通过增加与目标样本相似的源样本的权重来提高数据分布的相似度，从而提高缺陷预测的精度。,"提出了一种基于聚类的度量匹配方法。提取多粒度度量特征向量，统一源项目和目标项目之间的度量维度。利用度量聚类消除度量冗余，提取有代表性的度量，便于后续一对一的度量匹配。
度量聚类:在度量维度统一后，分别对源项目和目标项目采用相同簇数的K-means聚类方法。用欧几里得距离作为聚类度量，欧几里得距离可以描述度量之间的相似性。同时，采用主成分分析[30](PCA)方法提取每个聚类的代表性特征向量，为后续的一对一度量匹配做准备。",,所有的实验数据集都来自NASA[37]和PROMISE，,229-1000个样本,公开,完成,JAVA/C/C++,逻辑回归模型(LR)[32]、朴素贝叶斯(NB)[33]和k近邻(KNN)来构建缺陷预测模型。,文件级,故障倾向,"事实上，一个好的分类器应该有更高的Pd(recall)和更低的Pf, F-measure和AUC是平衡Pd和Pf性能的权衡度量，更高的F-measure意味着更好的预测性能。
使用Pd、Pf、F1和AUC来评估预测性能。",
"Chen, Liqiong; Song, Shilong; Wang, Can",A Novel Effort Measure Method for Effort-Aware Just-in-Time Software Defect Prediction,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194021500364,2021,"Just-in-time software defect prediction (JIT-SDP) is a fine-grained software defect prediction technology, which aims to identify the defective code changes in software systems. Effort-aware software defect prediction is a software defect prediction technology that takes into consideration the cost of code inspection, which can find more defective code changes in limited test resources. The traditional effort-aware defect prediction model mainly measures the effort based on the number of lines of code (LOC) and rarely considers additional factors. This paper proposes a novel effort measure method called Multi-Metric Joint Calculation (MMJC). When measuring the effort, MMJC takes into account not only LOC, but also the distribution of modified code across different files (Entropy), the number of developers that changed the files (NDEV) and the developer experience (EXP). In the simulation experiment, MMJC is combined with Linear Regression, Decision Tree, Random Forest, LightGBM, Support Vector Machine and Neural Network, respectively, to build the software defect prediction model. Several comparative experiments are conducted between the models based on MMJC and baseline models. The results show that indicators ACC and Popt of the models based on MMJC are improved by 35.3% and 15.9% on average in the three verification scenarios, respectively, compared with the baseline models.",3,提出了一种新的力度量方法――多度量联合计算(MMJC)。在度量工作量时，MMJC不仅要考虑LOC，还要考虑跨不同文件的修改代码分布(Entropy)、更改文件的开发人员数量(NDEV)和开发人员经验(EXP),JIT-SDP (Just-in-time software defect prediction)是一种细粒度的软件缺陷预测技术，旨在识别软件系统中有缺陷的代码变更。缺陷感知软件缺陷预测是一种软件缺陷预测技术，它考虑了代码检查的成本，可以在有限的测试资源中发现更多有缺陷的代码更改。传统的缺陷感知缺陷预测模型主要基于代码行数(LOC)来度量缺陷，很少考虑其他因素。,提出了一种新的力度量方法――多度量联合计算(MMJC)。在度量工作量时，MMJC不仅要考虑LOC，还要考虑跨不同事件的代码分布(Entropy)、更改事件的开发人员数量(NDEV)和开发人员经验(EXP)。在仿真实验中，MMJC分别与线性回归、决策树、随机森林、LightGBM、支持向量机和神经网络相结合，构建软件缺陷预测模型。对基于MMJC的模型与基线模型进行了对比实验。,实验结果表明，基于MMJC的模型的预测性能明显优于基线模型。最后选取EALR和MEALR作为代表，对其预测结果进行显著性检验。实验结果表明，基线模型与基于MMJC的模型在预测性能上存在显著差异。本文的研究还证明了代码混乱并不是一种很好的缺陷度量方法，它会影响缺陷预测模型的性能。,,跨版本/跨项目,"提出了一种新的力度量方法――多度量联合计算法。除了LA和LD, MMJC还增加了三个指标来衡量e?输出，即熵、NDEV和EXP。其中LA表示通过更改添加的LOC, LD表示通过更改删除的LOC。熵来衡量代码变化的分散。开发者之间的合作与交流也需要占用开发资源。因此，本文用NDEV来描述这种合作与交流。EXP是开发人员在当前更改之前所做的更改的数量。",14个度量,,本文的研究还证明了代码混乱并不是一种很好的缺陷度量方法，它会影响缺陷预测模型的性能。,本文使用的数据集是JIT-SDP中广泛使用的六个开源数据集,4400-90000个改变,公开,完成,未知,采用线性回归(LR)、决策树(DT)、随机森林(RF)、LightGBM (LGB)、支持向量机(SVM)、全连接神经网络(NN)等六种机器学习方法构建预测模型。,语句级,故障倾向,ACC and Popt，Popt表示当前预测模型与最佳模型之间的差距,
Xu Xiaolong; Chen Wen; Wang Xinheng,RFC: a feature selection algorithm for software defect prediction,JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS,10.23919/JSEE.2021.000032,2021,"Software defect prediction (SDP) is used to perform the statistical analysis of historical defect data to find out the distribution rule of historical defects, so as to effectively predict defects in the new software. However, there are redundant and irrelevant features in the software defect datasets affecting the performance of defect predictors. In order to identify and remove the redundant and irrelevant features in software defect datasets, we propose ReliefF-based clustering (RFC), a cluster-based feature selection algorithm. Then, the correlation between features is calculated based on the symmetric uncertainty. According to the correlation degree, RFC partitions features into k clusters based on the k-medoids algorithm, and finally selects the representative features from each cluster to form the final feature subset. In the experiments, we compare the proposed RFC with classical feature selection algorithms on nine National Aeronautics and Space Administration (NASA) software defect prediction datasets in terms of area under curve (AUC) and F-value. The experimental results show that RFC can effectively improve the performance of SDP.",3,软件缺陷数据集中存在冗余和不相关的特征，影响缺陷预测器的性能。为了识别和去除软件缺陷数据集中冗余和不相关的特征，提出了一种基于聚类的特征选择算法relief -based clustering (RFC)。0,"软件缺陷预测(Software defect prediction, SDP)是对历史缺陷数据进行统计分析，找出历史缺陷的分布规律，从而有效地预测新软件中的缺陷。然而，软件缺陷数据集中存在冗余和不相关的特征，影响缺陷预测器的性能。",为了识别和去除软件缺陷数据集中冗余和不相关的特征，提出了一种基于聚类的特征选择算法relief -based clustering (RFC)。然后，基于对称不确定性计算特征之间的相关性。RFC根据相关度，基于k-medoids算法将特征划分为k个聚类，最后从每个聚类中选择具有代表性的特征组成最终的特征子集。在实验中，我们在9个美国国家航空航天局(NASA)软件缺陷预测数据集上，从曲线下面积(AUC)和f值两方面比较了所提出的RFC和经典特征选择算法。,实验结果表明，RFC可以有效地提高SDP的性能。,,版本内,SDP数据集的度量由代码行数(LOC)计数、Halstead复杂度和McCabe复杂度组成。,RFC去除不相关的特征，然后基于对称不确定性(SU)将特征划分为k个聚类，最后从每个聚类中选择具有代表性的特征。,基于ReliefF计算特征与目标类之间的相关性，然后根据阈值去除不相关的特征,,我们从NASA Metrics Data Program (MDP)存储库[29]中选取了9个软件缺陷数据集,125-2109个模块,公开,完成,C/C++,朴素贝叶斯与J48分类算法,模块级,故障倾向,F-value，AUC,
"Wang, Hao; Zhuang, Weiyuan; Zhang, Xiaofang",Software Defect Prediction Based on Gated Hierarchical LSTMs,IEEE TRANSACTIONS ON RELIABILITY,10.1109/TR.2020.3047396,2021,"Software defect prediction, aimed at assisting software practitioners in allocating test resources more efficiently, predicts the potential defective modules in software products. With the development of defect prediction technology, the inability of traditional software features to capture semantic information is exposed, hence related researchers have turned to semantic features to build defect prediction models. However, sometimes traditional features such as lines of code (LOC) also play an important role in defect prediction. Most of the existing researches only focus on using a single type of feature as the input of the model. In this article, a defect prediction method based on gated hierarchical long short-term memory networks (GH-LSTMs) is proposed, which uses hierarchical LSTM networks to extract both semantic features from word embeddings of abstract syntax trees (ASTs) of source code files, and traditional features provided by the PROMISE repository. More importantly, we adopt a gated fusion strategy to combine the outputs of the hierarchical networks properly. Experimental results show that GH-LSTMs outperforms existing methods under both noneffort-aware and effort-aware scenarios.",3,本文提出了一种基于门控分层长短期记忆网络(gh -LSTM)的缺陷预测方法，该方法利用分层长短期记忆网络从源代码文件的抽象语法树(ast)的词嵌入中提取语义特征，,软件缺陷预测，旨在帮助软件从业者更有效地分配测试资源，预测软件产品中潜在的缺陷模块。随着缺陷预测技术的发展，传统的软件特征无法捕捉语义信息的问题暴露出来，相关研究人员开始利用语义特征来构建缺陷预测模型。然而，有时候像代码行(LOC)这样的传统特征在缺陷预测中也扮演着重要的角色。现有的研究大多集中在使用单一类型的特征作为模型的输入。,本文提出了一种基于门控分层长短期记忆网络(gh -LSTM)的缺陷预测方法，该方法利用分层长短期记忆网络从源代码文件的抽象语法树(ast)的词嵌入中提取语义特征，并利用PROMISE存储库提供的传统特征提取语义特征。更重要的是，我们采用门控融合策略来适当地组合分层网络的输出。,结果表明，我们提出的GH-LSTMs方法在无努力感知场景下的F -测量方面明显优于最先进的方法。此外，在努力感知场景下，与最先进的方法相比，gh - lstm在PofB20和IFA方面明显优于它们，在Popt方面也取得了相当的性能。,根据现有的研究，通常通过两种技术获得语义特征:DBN[6]和词嵌入[13]，与DBN相比，词嵌入能更好地利用AST节点序列的上下文。通常，词嵌入是通过word2vec[16]或global vectors (GloVe)[17]来完成的。,跨版本,AST和传统度量,本文使用GloVe2将AST节点令牌(作为一个单词)转换为由实数组成的向量是根据单词之间的语义关系，如频率和类比来计算的。首先，构建AST节点序列语料库，并利用该语料库构造协同矩阵。矩阵中的每个元素Xij表示单词i和单词j在特定大小的上下文窗口中同时出现的次数。在此基础上，GloVe提出了一个加权递减函数来计算共现次数:decay =1/d，根据上下文窗口中两个单词之间的距离d来计算权重，即距离越长，两个单词在总计数中的权重越小。在建立了协发生矩阵之后，可以基于这个损失函数来训练GloVe模型,,2)利用这两种特征来提高缺陷预测性能是有效的。然而，当使用多种特征时，需要适当的融合策略来帮助预测模型有效地提取不同类型的特征，并学习最优的融合比例。我们的GH-LSTMs模型中使用的门控合并层能够分别过滤提取的传统特征和语义特征的噪声信息，使得融合特征更具代表性，缺陷预测更加精确。,我们从promise存储库中选择了10个开源java项目。,122-815个文件,公开,完成,JAVA,为了同时利用语义特征和传统特征，我们构建了一个由语义级LSTM和传统级LSTM组成的分层LSTM模型,文件级,故障倾向,"F -measure被定义为精密度和召回率的调和平均值
Popt是努力感知性能指标的标准化版本，基于Alberg图的概念[33]，它展示了预测模型的努力感知性能
IFA被定义为测试人员根据预测模型给出的错误概率找到第一个真正缺陷之前遇到的错误警报的数量。现有的研究表明，当IFA很高时，开发人员会感到沮丧，并且不太可能继续检查其他变化[6]。
PofB20被定义为当整个检查工作完成20%时，从所有错误实例中捕获的错误实例的百分比。PofB20在实际场景中非常有意义，因为不是每个测试团队都有足够的资源来测试所有的源文件。缺陷预测模型的更高的PofB20性能意味着，当只检查有限数量的LOC时，捕获的错误的百分比更高。",
"Balogun, Abdullateef O.; Basri, Shuib; Mahamad, Saipunidzam; Abdulkadir, Said Jadid; Capretz, Luiz Fernando; Imam, Abdullahi A.; Almomani, Malek A.; Adeyemo, Victor E.; Kumar, Ganesh",Empirical Analysis of Rank Aggregation-Based Multi-Filter Feature Selection Methods in Software Defect Prediction,ELECTRONICS,10.3390/electronics10020179,2021,"Selecting the most suitable filter method that will produce a subset of features with the best performance remains an open problem that is known as filter rank selection problem. A viable solution to this problem is to independently apply a mixture of filter methods and evaluate the results. This study proposes novel rank aggregation-based multi-filter feature selection (FS) methods to address high dimensionality and filter rank selection problem in software defect prediction (SDP). The proposed methods combine rank lists generated by individual filter methods using rank aggregation mechanisms into a single aggregated rank list. The proposed methods aim to resolve the filter selection problem by using multiple filter methods of diverse computational characteristics to produce a dis-joint and complete feature rank list superior to individual filter rank methods. The effectiveness of the proposed method was evaluated with Decision Tree (DT) and Naive Bayes (NB) models on defect datasets from NASA repository. From the experimental results, the proposed methods had a superior impact (positive) on prediction performances of NB and DT models than other experimented FS methods. This makes the combination of filter rank methods a viable solution to filter rank selection problem and enhancement of prediction models in SDP.",3,提出了一种基于秩聚合的多滤波器特征选择方法。提出的方法利用秩聚合机制，将各个筛选方法生成的秩列表合并为一个聚合的秩列表。,选择最合适的过滤方法来产生具有最佳性能的特征子集仍然是一个开放的问题，被称为过滤器秩选择问题。一个可行的解决方案是独立应用混合过滤方法并评估结果。,针对软件缺陷预测(SDP)中的高维数和滤波器秩选择问题，提出了一种基于秩聚合的多滤波器特征选择方法。提出的方法利用秩聚合机制，将各个筛选方法生成的秩列表合并为一个聚合的秩列表。所提出的方法旨在通过使用具有不同计算特征的多个滤波器方法来产生优于单个滤波器秩方法的不相交且完整的特征秩列表来解决滤波器选择问题。利用决策树(DT)和Na?ve贝叶斯(NB)模型对NASA缺陷数据集进行了有效性评估。,从实验结果来看，所提出的方法对NB和DT模型的预测性能的影响(正)优于其他实验FS方法。这使得滤波器秩方法的组合成为解决SDP中滤波器秩选择问题和增强预测模型的可行方法。,"由于软件度量的扩散，具有大量特性的软件系统通常由冗余和嘈杂的特性组成。这种现象通常被称为高维问题。研究表明，高维问题会对SDP模型的预测性能产生负面影响[19-21]。文献表明，特征选择(FS)方法是解决高维问题的重要方法。主要是，对于任何SDP进程，所有FS方法都只从原始软件缺陷数据集中剔除不冗余且重要的软件特征[22-24]。
通常，FS方法可以分为两组:过滤器特征选择(FFS)和包装器特征选择(WFS)。FFS方法基于数学或统计措施对数据集的特征进行评估和排序。然后，根据预先确定的阈值选择排名靠前的特征[22,23]。FFS简单且独立于ML分类算法(通常称为基线分类器)。与FSS不同，WFS方法根据其对提高底层基线分类器准确性的积极影响来评估和选择特征。这使得WFS在计算上昂贵且难以实现[27-29]。",版本内,每个数据集具有不同特征,"通过聚合具有不同计算特征的多个滤波器FS方法的秩列表来解决滤波器选择问题，从而产生比所采用的单个滤波器方法更稳定(即不相交)和完整的特征秩列表
即Rank Aggregation-Based Multi-Filter Feature Selection (RMFFS) Method基于秩聚合的多滤波器特征选择方法
从给定的数据集生成CS、REF和IG过滤方法的单独排名列表。这些单独的排名列表是相互排斥的，因为所考虑的每种过滤方法都基于不同的计算特征。这是为了确保为预测过程选择不同的特征表示。然后，使用表2所示的秩聚合函数将生成的秩列表聚合在一起。各自的排名聚合函数通过利用归属于各个排名列表上的每个特征的相关性得分，将各个排名列表合并为单个聚合列表。最小和最大排序函数分别选择聚合排序列表产生的最小和最大关联分数。范围排序函数根据关联分数计算的范围值从聚合列表中选择特征。算术平均数、几何平均数和调和平均数秩函数通过分别计算单个秩表上每个特征的相关分数的算术平均数、几何平均数和调和平均数，将单个秩表组合成一个聚合表。这是为了平等地表示和考虑每个排名表中的每个特征。聚合列表上具有高相关性分数的特征表明这些特征在单个排名列表中排名较低，因此可以删除。将一种新的基于几何平均函数的动态自动阈值应用于聚合列表中以选择相关特征。计算聚合相关分数的几何平均值，并选择聚合相关分数小于或等于计算的阈值的特征。几何平均函数在计算中考虑了特征之间的相关性和复合效应。最后，选择最优特征作为RMFFS方法的结果特征。",,从实验结果分析可以看出RMFFS方法的有效性和优越性，在大多数情况下，RMFFS方法对NB和DT分类器的预测性能比其他实验FS方法有更大的正向影响。也就是说，所提出的RMFFS能够生成最能代表所研究数据集的更稳定和完整的特征子集。因此，这使得单个滤波器秩方法的组合成为解决SDP中滤波器秩选择问题和增强预测模型的可行方法。,这些数据集是从NASA存储库中挑选出来的,194-1711个模块,公开,完成,C等,本研究采用决策树(DT)和Na?ve贝叶斯(NB)算法拟合基线预测模型。,模块级,故障倾向,"Accuracy, F-Measure, and Area under Curve (AUC)",
"Balaram, A.; Vasundra, S.",Prediction of software fault-prone classes using ensemble random forest with adaptive synthetic sampling algorithm,AUTOMATED SOFTWARE ENGINEERING,10.1007/s10515-021-00311-z,2022,"The process of predicting fault module in software is known as Software Fault Prediction (SFP) which is important for releasing software versions that are dependent on the predefined metrics due to historical faults in software. The fault prediction in software such as components, classes and modules, at an early stage in the development cycle, is important as it significantly contributes to time reduction and cost reduction. Therefore, the modules that are used for processing each step is reduced by the unnecessary efforts eliminated the faults during development process. However, the problem of imbalanced dataset becomes a significant challenge during SFP for software fault prediction at an early stage. The limitations such as inclusion of software metric for SFP models, cost effectiveness of the fault and the fault density prediction, are still few obstacles faced by research. The proposed Butterfly optimization performs feature selection that helps to predict meticulous and remarkable results by developing the applications of Machine Learning techniques. The present research uses Ensemble Random Forest with Adaptive Synthetic Sampling (E-RF-ADASYN) for fault prediction by using various classifiers which is mentioned in the proposed method section. The proposed E-RF-ADASYN obtained Area Under Curve (AUC) of 0.854767 better when compared with the existing method Rough-KNN Noise-Filtered Easy Ensemble (RKEE) of 0.771.",3,提出的Butterfly优化执行特征选择，通过开发机器学习技术的应用，有助于预测细致而显著的结果。本研究使用集成随机森林与自适应合成采样(E-RF-ADASYN)，通过使用各种分类器进行故障预测。,预测软件故障模块的过程称为软件故障预测(SFP)，它对于发布依赖于软件历史故障预定义度量的软件版本具有重要意义。在软件(如组件、类和模块)开发周期的早期阶段进行故障预测，对于缩短开发时间和降低开发成本具有重要意义。因此，通过在开发过程中消除故障，减少了处理每个步骤所使用的模块。然而，数据不平衡问题成为SFP软件早期故障预测的一个重大挑战。SFP模型中包含软件度量、故障的成本效益和故障密度预测等限制仍然是研究面临的一些障碍,提出的Butterfly优化执行特征选择，通过开发机器学习技术的应用，有助于预测细致而显著的结果。本研究使用集成随机森林与自适应合成采样(E-RFADASYN)进行故障预测，使用各种分类器，在提出的方法部分中提到。,与现有的粗糙knn噪声滤波Easy Ensemble (RKEE)方法相比，本文提出的E-RF-ADASYN方法获得的曲线下面积(AUC)为0.854767，将提出的E-RF-ADASYN模型与现有的KNN、DT分类器等模型在“灵敏度”、“特异性”、“AUC”等性能参数上进行比较，并与提出的ERF分类器对类不平衡问题进行分类。由此提出的ERF-ADASYN模型可作为准确预测软件故障的有效模型。,,版本内,数据集被选择为面向对象的度量，每个项目有20个特征和1个二进制输出作为故障值。,butterfly optimization algorithmBOA是一种基于蝴蝶觅食行为而设计的特征选择方法。BOA的主要框架是基于通过香味吸引蝴蝶的食物。这种香味可以帮助蝴蝶寻找食物，也可以帮助它们寻找交配对象。BOA具有解决各种优化问题的能力，从而找到觅食的最佳交配对象，从而识别蝴蝶的伴侣行为。,自适应合成采样(ADASYN)Adaptive synthetic sampling (ADASYN),结果表明，该方法选择了最相关的特征，显著提高了BFO算法的性能，提高了效率。当研究所选特征的数量时，所提出的E-RF-ADASYN的行为表现得更好。,数据集为:Camel- 1.0、Ant-1.7、Camel-1.4、Camel-1.2、Jedit-3.2、Camel- 1.6、Jedit-4.1、Jedit- 4.0、Jedit-4.2、log4j-1.0、Jedit-4.3、log4j-1.2、log4j-1.1、Xalan- 2.7和Xalan-2.4。,未知,公开,完成,JAVA,随机森林,类级别,故障倾向,Sensitivity，Specificity，The?Area Under?Curve (AUC),
"Ali, Asad; Gravino, Carmine",Evaluating the impact of feature selection consistency in software prediction,SCIENCE OF COMPUTER PROGRAMMING,10.1016/j.scico.2021.102715,2022,"Many empirical software engineering studies have employed feature selection algorithms to exclude the irrelevant and redundant features from the datasets with the aim to improve prediction accuracy achieved with machine learning-based estimation models as well as their generalizability. However, little has been done to investigate how consistently these feature selection algorithms produce features/metrics across different training samples, which is an important point for the interpretation of the trained models. The interpretation of the models largely depends on the features of the analyzed datasets, so it is recommended to evaluate the potential of various feature selection algorithms in terms of how consistently they extract features from the employed datasets. In this study, we consider eight different feature selection algorithms to evaluate how consistently they select features across different folds of k-fold cross-validation as well as when small changes are made in the training data. To provide a stable and generalized conclusion, we investigate data from two different domains, i.e., six datasets from the domain of Software Development Effort Estimation (SDEE) and six datasets from the Software Fault Prediction (SFP) domain. Our results reveal that a feature selection algorithm could produce 20-100% inconsistent features with an SDEE dataset and 18.8-95.3% inconsistent features in the case of an SFP dataset. The analysis also reveals that it is not necessarily true that the most consistent feature selection algorithm results to be the most accurate one (i.e., leads to better prediction accuracy) in the case of SDEE datasets, while with SFP datasets, the analysis highlights that the most consistent feature selection algorithm also results to be the most accurate in predicting faults. (c) 2021 Elsevier B.V. All rights reserved.",3,在本研究中，我们考虑了八种不同的特征选择算法，以评估它们在k-fold交叉验证的不同折叠中选择特征的一致性，以及当训练数据发生微小变化时。为了提供一个稳定和广义的结论，我们研究了来自两个不同领域的数据，即来自软件开发工作量估算(SDEE)领域的六个数据集和来自软件故障预测(SFP)领域的六个数据集,许多经验软件工程研究采用特征选择算法从数据集中排除不相关和冗余的特征，目的是提高基于机器学习的估计模型的预测精度及其泛化性。然而，很少有人研究这些特征选择算法在不同训练样本中产生特征/指标的一致性，这是解释训练模型的重要一点。模型的解释在很大程度上取决于所分析数据集的特征，因此建议评估各种特征选择算法的潜力，看看它们从所使用的数据集中提取特征的一致性。,在本研究中，我们考虑了八种不同的特征选择算法，以评估它们在k-fold交叉验证的不同折叠中选择特征的一致性，以及当训练数据发生微小变化时。为了提供一个稳定和广义的结论，我们研究了来自两个不同领域的数据，即来自软件开发工作量估算(SDEE)领域的六个数据集和来自软件故障预测(SFP)领域的六个数据集。,"我们的研究结果表明，特征选择算法在SDEE数据集上可以产生20-100%的不一致特征，在SFP数据集上可以产生18.8-95.3%的不一致特征。分析还发现，对于SDEE数据集，最一致的特征选择算法不一定是最准确的(即预测精度更高)，而对于SFP数据集，分析强调最一致的特征选择算法在预测故障时也是最准确的。
此外，我们要强调的是，最一致的特征选择算法不一定也能提供更好的预测精度。事实上，对于SDEE数据，提供更好预测精度的特征选择算法(即HS)是一致性最低的特征选择算法。然而，对于SFP数据，我们发现最一致的特征选择算法(即Best-First (backward))也提供了更好的预测精度。SQA团队通常需要同时处理SDEE和SFP数据，因此如果使用SDEE数据，只有当目的是提高预测精度时才应该使用HS，而不管数据类型是SDEE还是SFP，如果SQA团队需要洞察/解释预测模型，则应该优先使用Best-First (backward)搜索。从RQ3和RQ4的分析中我们可以看出，SDEE数据比SFP数据对训练数据的变化更敏感，如果从业者/SQA团队的目的是解释预测模型，建议避免SDEE数据的变化。","这些特征选择算法有助于降低维数，因此试图解决两个重要问题:(a)提高所采用的估计技术(例如随机森林)的预测精度;(b)识别有助于理解问题本身的最重要特征[38]
许多研究已经讨论了特征选择算法，这些算法可以提高预测精度[7,8,17,18]，",版本内,每个数据集具有不同特征,"Genetic Algorithm (GA):
粒子群算法(PSO)
禁忌搜索(TS)
和谐搜索(HS)。
最佳优先搜索(BFS)在本研究中，我们采用了两个版本的BFS，即BFS forward (fwd)和BFS backward (bwd)。
Subset Size Forward Selection (SSFS)
贪婪逐步搜索(GSS)",,综上所述，生物启发算法的参数优化使SDEE数据集的特征一致性提高了33.3%，SFP数据集的特征一致性提高了112%。因此，我们建议SQA团队应该仔细配置生物启发算法的参数，例如种群大小和迭代次数，因为一致性的结果可能会发生重大变化。,我们总共使用了12个不同的数据集:6个来自SFP领域(Ant 1.7、Xalan 2.6、Xerces 1.3、Lucene 2.0、Synapse 1.1和Velocity 1.6)[28],195-885个类,公开,完成,JAVA,"随机森林(Random Forest, RF)",类级别,故障倾向,"Mean Absolute Error (MAE),平均绝对误差，",综上所述，我们可以强调，在产生不同折叠的相同指标子集时，10倍CV的表现优于3倍CV和5倍CV。
"Zhang, Nana; Ying, Shi; Zhu, Kun; Zhu, Dandan",Software defect prediction based on stacked sparse denoising autoencoders and enhanced extreme learning machine,IET SOFTWARE,10.1049/sfw2.12029,2022,"Software defect prediction is an important software quality assurance technique. Nevertheless, the prediction performance of the constructed model is easily susceptible to irrelevant or redundant features in the software projects and is not predominant enough. To address these two issues, a novel defect prediction model called SSEPG based on Stacked Sparse Denoising AutoEncoders (SSDAE) and Extreme Learning Maching (ELM) optimised by Particle Swarm Optimisation (PSO) and another complementary Gravitational Search Algorithm (GSA) are proposed in this paper, which has two main merits: (1) employ a novel deep neural network - SSDAE to extract new combined features, which can effectively learn the robust deep semantic feature representation. (2) integrate strong exploitation capacity of PSO with strong exploration capability of GSA to optimise the input weights and hidden layer biases of ELM, and utilise the superior discriminability of the enhanced ELM to predict the defective modules. The SSDAE is compared with eleven state-of-the-art feature extraction methods in effect and efficiency, and the SSEPG model is compared with multiple baseline models that contain five classic defect predictors and three variants across 24 software defect projects. The experimental results exhibit the superiority of the SSDAE and the SSEPG on six evaluation metrics.",3,为了解决这两个问题，本文提出了一种新的缺陷预测模型SSEPG，该模型基于堆叠稀疏去噪自动编码器(SSDAE)和粒子群优化(PSO)优化的极限学习机器(ELM)和另一种互补的引力搜索算法(GSA)，有效地学习鲁棒的深度语义特征表示,软件缺陷预测是一种重要的软件质量保证技术。然而，构建模型的预测性能很容易受到软件项目中不相关或冗余特征的影响，并且不够突出。,针对这两个问题，本文提出了一种新的缺陷预测模型dssepg，该模型基于堆栈稀疏去噪自动编码器(SSDAE)和粒子群优化(PSO)优化的极值学习机器学习(ELM)和另一种互补的引力搜索算法(GSA)，该模型具有以下优点:(1)利用深度神经网络- SSDAE提取新的组合特征，可以有效地学习强大的深度语义特征表示。(2)将pso的强大挖掘能力与gsa的强大探索能力相结合，优化elm的输入权值和隐藏层偏差，利用增强elm的优越可分辨性对缺陷模块进行预测。将sepg模型与11种最先进的特征提取方法进行了无效和低效的比较，并将sepg模型与包含5个经典缺陷预测因子和3个变量的多个基线模型进行了比较。,实验结果显示了该方法和sepg在六个评价指标上的优势。,Jiarpakdee等等。[3]已经证明了1010个开源缺陷数据集中10% - 67%的特征是不相关或冗余的。如果使用所有这些软件特征来构建缺陷预测模型，将严重降低模型的预测性能和泛化能力。,项目内,每个数据集具有不同特征,,利用深度神经网络-堆叠稀疏降噪自动编码器(SSDAE)[13]将传统特征与新特征相结合，可以有效地学习深度语义特征表示。,本文方法在模型性能间差、G-measure和mcc方面优于11种（使用SPE(随机邻近嵌入)[52]、SymSNE(对称随机邻居嵌入)[53]、PCA(主成分分析)[6]、MCML(最大坍缩度量学习)[54]、KPCA(g) (kernelpcawiththe高斯核函数)[55]、KPCA(p) (kernelpcawiththe多项式核函数)[56]、GDA(g)(高斯核函数的广义判别分析)[57]、GDA(p)(多项式核函数的广义判别分析)[57]、FA(FactorAnalysis)[58]、DM(Diffusion Maps)[59]和mc (Manifold chart)）最先进的特征提取方法，并且达到了除SymSNE之外的最佳平均性能间差。,在三个数据集上对24个软件重新项目进行了广泛的实验，其中包括来自NASA数据库的6个项目，来自promise数据库的15个项目和来自the link数据库的3个项目,56-1988个样本,公开,完成,C/C++等,"极限学习机(extreme LearningMachine, ELM)[14]作为缺陷预测器",文件级,故障倾向,"precision, recall, F1,pf,G-measure and MCC",
"Gong, Lina; Rajbahadur, Gopi Krishnan; Hassan, Ahmed E.; Jiang, Shujuan",Revisiting the Impact of Dependency Network Metrics on Software Defect Prediction,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,10.1109/TSE.2021.3131950,2022,"Software dependency network metrics extracted from the dependency graph of the software modules by the application of Social Network Analysis (SNA metrics) have been shown to improve the performance of the Software Defect prediction (SDP) models. However, the relative effectiveness of these SNA metrics over code metrics in improving the performance of the SDP models has been widely debated with no clear consensus. Furthermore, some of the common SDP scenarios like predicting the number of defects in a module (Defect-count) in Cross-version and Cross-project SDP contexts remain unexplored. Such lack of clear directive on the effectiveness of SNA metrics when compared to the widely used code metrics prevents us from potentially building better performing SDP models. Therefore, through a case study of 9 open source software projects across 30 versions, we study the relative effectiveness of SNA metrics when compared to code metrics across 3 commonly used SDP contexts (Within-project, Cross-version and Cross-project) and scenarios (Defect-count, Defect-classification (classifying if a module is defective) and Effort-aware (ranking the defective modules w.r.t to the involved effort)). We find the SNA metrics by themselves or along with code metrics improve the performance of SDP models over just using code metrics on 5 out of the 9 studied SDP scenarios (three SDP scenarios across three SDP contexts). However, we note that in some cases the improvements afforded by considering SNA metrics over or alongside code metrics might only be marginal, whereas in other cases the improvements could be potentially large. Based on these findings we suggest that the future work should: consider SNA metrics alongside code metrics in their SDP models; as well as consider Ego metrics and Global metrics, the two different types of the SNA metrics separately when training SDP models as they behave differently.",3,我们研究了SNA度量与跨3种常用SDP上下文(项目内、跨版本和跨项目)和场景(缺陷计数、缺陷分类(如果模块有缺陷进行分类)和努力感知(将有缺陷的模块按所涉及的工作进行排序)的代码度量相比较时的相对有效性。,"应用社会网络分析(Social network Analysis, SNA)度量从软件模块的依赖图中提取软件依赖网络度量，可以提高软件缺陷预测(Software Defect prediction, SDP)模型的性能。然而，在改进SDP模型的性能方面，这些SNA度量相对于代码度量的相对有效性一直存在广泛的争论，没有明确的共识。此外，一些常见的SDP场景，比如在跨版本和跨项目的SDP环境中预测模块中的缺陷数量(缺陷计数)，仍然没有被探索。与广泛使用的代码度量相比，缺乏对SNA度量有效性的明确指示，阻碍了我们构建性能更好的SDP模型。",因此，通过对跨30个版本的9个开源软件项目的案例研究，我们研究了SNA度量与跨3种常用SDP上下文(项目内、跨版本和跨项目)和场景(缺陷计数、缺陷分类(如果模块有缺陷进行分类)和努力感知(将有缺陷的模块按所涉及的工作进行排序)的代码度量相比较时的相对有效性。,我们发现SNA度量本身或与代码度量一起提高了SDP模型的性能，而不是仅仅使用代码度量来研究9个SDP场景中的5个(跨3个SDP上下文的3个SDP场景)。然而，我们注意到，在某些情况下，通过考虑SNA指标而不是代码指标所提供的改进可能只是微不足道的，而在其他情况下，改进可能是巨大的。基于这些发现，我们建议未来的工作应该:在SDP模型中考虑SNA度量和代码度量;同时考虑自我度量和全局度量，这两种不同类型的SNA度量在训练SDP模型时分别进行，因为它们的行为不同,"努力感知场景是指一个模型(努力感知模型)根据软件模块存在缺陷的概率以及识别缺陷所需的努力来对其进行排序[6,18,27,39]。例如，根据软件模块出现缺陷的概率和识别缺陷需要检查的代码行对模块进行排序。",版本内/跨版本/跨项目,"Code metrics
SNA metrics（Social Network Analysis）",Variance Inflation Factor (VIF) filter方差膨胀因子(VIF)过滤器,,我们案例研究的结果表明，单独考虑SNA度量或与代码度量一起考虑SNA度量可以潜在地改善模型的性能，至少在9个被研究的SDP场景中的5个(跨3个SDP上下文的3个SDP场景)。然而，我们确实注意到，在某些情况下，通过使用SNA度量和简单地使用代码度量来提高性能可能是微不足道的。而在其他情况下，它可能很大。我们不主张我们所观察到的结果具有普遍性。相反，我们只是观察到存在这样的软件项目，在这些项目中，单独使用SNA度量或者与代码度量一起使用SNA度量可以在几个SDP上下文和场景中产生更好的SDP模型,包含9个开源软件项目的32个版本，包括ActiveMQ、Camel、Derby、Groovy、HBase、Hive、JRuby、Lucene和Wicket。,63-529kLOC,公开,完成,JAVA等,"在项目内部环境中，我们使用随机森林学习器。
在跨版本上下文中，我们使用与Within-project上下文中相同的随机森林学习器。
在Cross-project上下文中，我们使用了Cruz和Ochimizu提出的log+NavieBayes模型",模块级,"故障数量
故障倾向
努力感知","故障数量：平均绝对误差MAE、校正R方Adj R2、均方根误差RMSE和Spearman相关系数
故障倾向：(AUC)、Matthews相关系(MCC)、Precision、Recall和Brier评分
努力感知：cost-effectiveness (CE) curve [4, 48] and effort reduction (ER) measures [48, 80].” ",
"Zhou, Chunying; He, Peng; Zeng, Cheng; Ma, Ju",Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2022.107057,2022,"Context: Most defect prediction methods consider a series of traditional manually designed static code metrics. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional Neural Network (CNN) to capture the potential semantic information based on the program's Syntax Trees (ASTs). In recent years, leveraging the dependency relationships between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in defect prediction. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN. Objective: This study aims to validate the feasibility and performance of the proposed method in software defect prediction. Method: Abstract Syntax Trees and a Class Dependency Network (CDN) are first generated based on the source code. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a Graph Convolutional Network (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction. Results: The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks.Conclusion: The proposed method of combining semantic and structural information can improve the performance of software defect prediction.",3,"本文同时考虑了语义信息和结构信息，提出了一种称为CGCN的方法。目的:本研究旨在验证所提出的方法在软件缺陷预测中的可行性和性能。方法:首先基于源代码生成抽象语法树和类依赖网络(Class Dependency Network, CDN)。对于ast，提取符号标记并将其编码为向量。",大多数缺陷预测方法考虑一系列传统的手工设计的静态代码度量。然而，只使用这些手工制作的功能是不切实际的。一些研究人员使用卷积神经网络(CNN)来捕获基于程序语法树(ast)的潜在语义信息。近年来，利用软件模块之间的依赖关系构建软件网络，利用网络嵌入模型捕获结构信息，有助于缺陷预测。本文同时考虑了语义信息和结构信息，提出了一种称为CGCN的方法。,"本研究旨在验证所提出的方法在软件缺陷预测中的可行性和性能。方法:首先基于源代码生成抽象语法树和类依赖网络(Class Dependency Network, CDN)。对于ast，提取符号标记并将其编码为向量。然后将数值向量作为CNN的输入来捕获语义信息。对于CDN，使用图卷积网络(GCN)来自动学习网络的结构信息。然后，对学习到的语义信息和结构信息进行不同权重的组合。最后，我们将学习到的特征与传统的手工特征连接起来，以训练一个更准确的缺陷预测分类器。",在21个开源项目中，所提出的方法在项目内预测(包括版本内和跨版本)和跨项目预测方面都优于目前最先进的缺陷预测模型。一般来说，版本内预测在三个预测任务中获得了更好的性能。结论:提出的语义信息与结构信息相结合的方法可以提高软件缺陷预测的性能。,,版本内/跨版本/跨项目,AST、类依赖网络(CDN)和传统度量,,然后使用CNN来捕获ast中的语义信息(内部特征)，GCN用于捕获软件网络中的结构信息(外部特征),"CGCN更适合于版本内预测。不同版本或项目中的数据具有分布差异，因此源项目训练的预测模型对于目标项目可能表现不佳。虽然跨版本预测也属于项目内缺陷预测(WithinProject Defect prediction, WPDP)，但其预测性能远不如版本内预测。这可能是由于软件更改，例如源文件的数量、依赖项和代码样式
表明内部和外部特征的贡献没有显著差异。结果表明，与所有基线模型相比，CGCN- α的性能最好。CGCN在版本内预测方面表现良好，但在跨版本和跨项目预测方面表现不佳。结果总体上验证了我们的直觉，即在组合不同类型的特征时考虑权重策略可以提高模型的预测性能和稳定性。",7个Java开源项目(每个项目选择3个版本，共21个数据集)和3个任务,未知,公开,完成,JAVA,我们利用RF作为版本内预测的分类器，并利用MLP进行跨版本和跨项目预测。,类级,故障倾向,Accuracy and F1-measure，AUC,
"Yang, Shunkun; Gou, Xiaodong; Yang, Minghao; Shao, Qi; Bian, Chong; Jiang, Ming; Qiao, Yongjie",Software Bug Number Prediction Based on Complex Network Theory and Panel Data Model,IEEE TRANSACTIONS ON RELIABILITY,10.1109/TR.2022.3149658,2022,"Accurate software bug number prediction makes software test resource allocation, maintenance, and release time cost efficient. However, it is a challenge to accurately predict the number of software bugs when there fluctuations caused by many uncertain factors faced by the complex software. Considering this, a new method for software bug number prediction based on a panel data model from the perspective of complex networks is proposed in this article. Using complex network theory, we constructed the software code network and calculated the static metrics of the network structure, and the percolation threshold of change in the network structure based on percolation theory as a dynamic metric. These network metrics were then normalized as inputs and a panel data model was used for bug prediction. The proposed method can predict the number of bugs for both within-project and cross-project. Empirical studies were performed on data obtained from 120 releases of eight open-source software projects (Lua, SQLite, Redis, Linux kernel, ant, jmeter, poi, and tomcat), the experimental results indicated that network metrics are effective bug indicators, and the proposed method outperformed ten baseline methods (with an average improvement of 28.05%). This article is expected to provide insights into more smart software quality and reliability assurance.",3,本文提出了一种基于复杂网络视角的面板数据模型的软件bug数预测新方法。利用复杂网络理论构建了软件代码网络，计算了网络结构的静态度量,准确的软件错误数预测使软件测试资源分配、维护和发布时间成本有效。然而，当复杂的软件面临许多不确定因素导致的波动时，如何准确预测软件bug的数量是一个挑战。,鉴于此，本文提出了一种基于复杂网络视角的面板数据模型的软件bug数预测新方法。利用复杂网络理论构建了软件代码网络，计算了网络结构的静态度量，并基于渗流理论计算了网络结构变化的渗流阈值作为动态度量。然后将这些网络指标归一化为输入，并使用面板数据模型进行bug预测。该方法可以预测项目内和跨项目的bug数量。对8个开源软件项目(Lua、SQLite、Redis、Linux kernel、ant、jmeter、poi、tomcat) 120个版本的数据进行了实证研究，,WP预测平均TA率为76.52%，平均MAE为0.2496。预测CP的平均TA率达到79.92%，平均MAE为0.1873，优于对比基线方法。其中，PD的预测性能比MLR、WNN、BP、RBF、SVR、DNN、BCV、RF、NB、DSI分别提高20.59%、18.18%、43.75%、10%、10%、40%、49.06%、18.18%、27.03%、43.75%，平均提高28.05%。,"Wahono[19]指出77.46%的SBP研究与分类方法(即bug-proneness预测)有关，只有14.08%的SBP研究与估计方法(即数量预测)有关。
Gong等人[36]发现，在研究的9个SBP场景中，有5个场景与简单使用代码度量相比，单独使用网络度量或与代码度量一起使用网络度量提高了SBP模型的性能;换句话说，网络度量是有效的软件度量。",跨版本/跨项目,"网络度量：网络指标:在我们的方法中，我们选择节点、边缘、AD、幂律指数α、平均最短路径长度(ASPL)、平均聚类系数(ACC)、社区和模块化作为软件指标。
我们还引入了动态参数PT作为新的bug指标",,"建立软件度量向量(SMV)，并计算相邻软件版本之间的余弦距离，以表示代码更改的程度。
具体来说，我们使用静态和动态网络度量作为软件度量，并使用网络度量的余弦距离来度量软件的变化，而不是使用代码文件变化的熵。","N、S、P分别代表网络指标、静态指标和PT。：从图4可以初步得出，NP是最佳的度量组合，SP是最差的度量组合。包括网络指标(即NSP、NS和NP)在内的所有软件指标组合的TA和MAE在WP和CP预测中都更好，这表明网络指标(N)是SBP的关键指标。NSP的TA和MAE的平均改进都是负的，这意味着从NSP中去除PT (P)会降低预测性能。同样，NP的TA和MAE的平均改善均为正;可以认为静态指标的加入降低了预测性能。
总之，我们从与不同软件度量的比较结果中得出以下三个推论。1)网络指标(N)是SBP的关键指标，对预测性能起决定性作用。2) PT (P)是SBP的重要指标，P的加入提高了预测性能。3)静态指标(S)是SBP的负指标，S的加入降低了预测性能。",选择了四个C软件项目，分别是Lua、SQLite、Redis和Linux kernel，以及四个Java软件项目，分别是Apache的ant、jmeter、poi和tomcat。,未知,公开,完成,JAVA/C,"本文选择固定效应(fixed effects, FE)模型作为bug预测模型。因此，我们选择EFER模型作为bug预测模型，这是一种截距随实体变化的FE模型。",文件级,故障数量,trend accuracy (TA) and MAE.,
"Chen, Li-qiong; Wang, Can; Song, Shi-long",Software defect prediction based on nested-stacking and heterogeneous feature selection,COMPLEX & INTELLIGENT SYSTEMS,10.1007/s40747-022-00676-y,2022,"Software testing guarantees the delivery of high-quality software products, and software defect prediction (SDP) has become an important part of software testing. Software defect prediction is divided into traditional software defect prediction and just-in-time software defect prediction (JIT-SDP). However, most of the existing software defect prediction frameworks are relatively simplified, which makes it extremely difficult to provide developers with more detailed reference information. To improve the effectiveness of software defect prediction and realize effective software testing resource allocation, this paper proposes a software defect prediction framework based on Nested-Stacking and heterogeneous feature selection. The framework includes three stages: data set preprocessing and feature selection, Nested-Stacking classifier, and model classification performance evaluation. The novel heterogeneous feature selection and nested custom classifiers in the framework can effectively improve the accuracy of software defect prediction. This paper conducts experiments on two software defect data sets (Kamei, PROMISE), and demonstrates the classification performance of the model through two comprehensive evaluation indicators, AUC, and F1-score. The experiment carried out large-scale within-project defect prediction (WPDP) and cross-project defect prediction (CPDP). The results show that the framework proposed in this paper has an excellent classification performance on the two types of software defect data sets, and has been greatly improved compared with the baseline models.",3,种基于嵌套叠加和异构特征选择的软件缺陷预测框架。该框架包括三个阶段:,软件测试是交付高质量软件产品的保证，软件缺陷预测(SDP)已成为软件测试的重要组成部分。软件缺陷预测分为传统的软件缺陷预测和即时软件缺陷预测。然而，大多数现有的软件缺陷预测框架都是相对简化的，这使得为开发人员提供更详细的参考信息变得极其困难。,"为了提高软件缺陷预测的有效性，实现有效的软件测试资源分配，本文提出了一种基于嵌套叠加和异构特征选择的软件缺陷预测框架。该框架包括三个阶段:数据集预处理和特征选择、嵌套堆叠分类器和模型分类性能评估。在该框架中引入了新的异构特征选择和嵌套自定义分类器，可以有效地提高软件缺陷预测的准确性。本文在两个软件缺陷数据集(Kamei, PROMISE)上进行实验，通过AUC和F1-score两个综合评价指标来论证模型的分类性能。实验进行了大规模的项目内缺陷预测(WPDP)和跨项目缺陷预测(CPDP)。",实验通过了项目内StratifiedKFold (K = 10)交叉验证和跨项目验证，显示了该模型在两个粒度级别上对软件缺陷数据的有效性。这证明了嵌套堆栈可以为软件测试提供可靠的决策支持。此外，该框架采用异构集成方法，基础学习器和元学习器是不同领域的算法。因此，该方法可以提高模型的拟合能力和泛化能力，优于目前流行的软件缺陷预测方法。然而，巢式叠加的缺点是基线模型的最优组合是由复杂的实验得出的，并且过程效率不高,"Yang X, Yu H, Fan G et al (2019) Local versus global models for just-in-time software defect prediction. Sci Program, pp 1-13",跨版本/跨项目,此外，本实验选取的20个静态度量特征均由Jureczko等[30]为面向对象的编程语言设计提取，包括继承树深度(depth of inheritance tree)、子类数量(number of Children)、代码行数(Line of code)以及相关代码复杂度特征等，如表4所示。,"在嵌套叠加框架中，每个基线模型可以执行不同的特征选择，我们称之为异构特征选择。利用基线模型在每个模型中选择表现最好的特征(特征不一定相同)，对其预测结果进行叠加，可以提高巢式堆叠的整体分类效果。
巢式堆叠分类器的核心是构建多个不同的基线模式并将其堆叠以获得更好的分类性能。
嵌套堆叠分类器总共包含三层。第一层集成了LightGBM、CatBoost和AdaBoost三种增强算法，并嵌套了包含MLP和RandomForest的简单叠加模型。元分类器是梯度增强决策树。最后一层是LogisticRegression的元分类器，它执行最终的分类预测",,,本研究采用Kamei[28]和PROMISE[29]作为实验数据集。,"4k-98k个变更
",公开,完成,JAVA等,nest-stacking classifier ,变更级,故障倾向,"AUC, and F1-score.",
"Rath, Suneel Kumar; Sahu, Madhusmita; Das, Shom Prasad; Bisoy, Sukant Kishoro; Sain, Mangal",A Comparative Analysis of SVM and ELM Classification on Software Reliability Prediction Model,ELECTRONICS,10.3390/electronics11172707,2022,"By creating an effective prediction model, software defect prediction seeks to predict potential flaws in new software modules in advance. However, unnecessary and duplicated features can degrade the model's performance. Furthermore, past research has primarily used standard machine learning techniques for fault prediction, and the accuracy of the predictions has not been satisfactory. Extreme learning machines (ELM) and support vector machines (SVM) have been demonstrated to be viable in a variety of fields, although their usage in software dependability prediction is still uncommon. We present an SVM and ELM-based algorithm for software reliability prediction in this research, and we investigate factors that influence prediction accuracy. These worries incorporate, first, whether all previous disappointment information ought to be utilized and second, which type of disappointment information is more fitting for expectation precision. In this article, we also examine the accuracy and time of SVM and ELM-based software dependability prediction models. Then, after the comparison, we receive experimental results that demonstrate that the ELM-based reliability prediction model may achieve higher prediction accuracy with other parameters, such as specificity, recall, precision, and F1-measure. In this article, we also propose a model for how feature selection utilization with ELM and SVM. For testing, we used NASA Metrics datasets. Further, in both technologies, we are implementing feature selection techniques to get the best result in our experiment. Due to the imbalance in our dataset, we initially applied the resampling method before implementing feature selection techniques to obtain the highest accuracy.",3,本文提出了一种基于SVM和elm极限学习机(ELM）的软件可靠性预测算法，并对影响预测精度的因素进行了研究。我们还提出了一个如何利用ELM和SVM进行特征选择的模型。,通过创建一个有效的预测模型，软件缺陷预测寻求提前预测新软件模块中的潜在缺陷。然而，不必要的和重复的特征会降低模型的性能。此外，过去的研究主要使用标准的机器学习技术进行故障预测，预测的准确性并不令人满意。极限学习机(ELM)和支持向量机(SVM)已被证明在许多领域是可行的，尽管它们在软件可靠性预测中的应用仍然不常见。,本文提出了一种基于SVM和elm的软件可靠性预测算法，并对影响预测精度的因素进行了研究。这些担忧包括，首先，是否应该利用所有先前的失望信息，其次，哪种类型的失望信息更适合期望精度。在本文中，我们还研究了基于SVM和基于elm的软件可靠性预测模型的准确性和时间。然后，经过比较，我们得到的实验结果表明，基于elm的可靠性预测模型可以在特异性、召回率、精度和F1-measure等其他参数下获得更高的预测精度。在本文中，我们还提出了一个如何利用ELM和SVM进行特征选择的模型。为了进行测试，我们使用了NASA Metrics数据集。此外，在这两种技术中，我们都实现了特征选择技术，以在我们的实验中获得最佳结果。由于我们的数据集不平衡，我们首先采用重采样方法，然后再实现特征选择技术，以获得最高的精度,我们得到的实验结果表明，基于elm的可靠性预测模型可以在特异性、召回率、精度和F1-measure等其他参数下获得更高的预测精度。,,版本内,22个度量,两种最流行的特征选择技术是Kbest和ANOVA。在本研究中，我们采用了Kbest特征选择,,,The NASA Metrics Data Program,"10,885 cases ",公开,完成,C/C++,"SVM,ELM极限学习机",模块级,故障倾向,"F1-measure, Precision, Recall, and Specificity",
"Chen, Jinfu; Wang, Xiaoli; Cai, Saihua; Xu, Jiaping; Chen, Jingyi; Chen, Haibo",A software defect prediction method with metric compensation based on feature selection and transfer learning,FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING,10.1631/FITEE.2100468,2022,"Cross-project software defect prediction solves the problem of insufficient training data for traditional defect prediction, and overcomes the challenge of applying models learned from multiple different source projects to target project. At the same time, two new problems emerge: (1) too many irrelevant and redundant features in the model training process will affect the training efficiency and thus decrease the prediction accuracy of the model; (2) the distribution of metric values will vary greatly from project to project due to the development environment and other factors, resulting in lower prediction accuracy when the model achieves cross-project prediction. In the proposed method, the Pearson feature selection method is introduced to address data redundancy, and the metric compensation based transfer learning technique is used to address the problem of large differences in data distribution between the source project and target project. In this paper, we propose a software defect prediction method with metric compensation based on feature selection and transfer learning. The experimental results show that the model constructed with this method achieves better results on area under the receiver operating characteristic curve (AUC) value and F1-measure metric.",3,本文提出了一种基于特征选择和迁移学习的度量补偿软件缺陷预测方法。,跨项目软件缺陷预测解决了传统缺陷预测训练数据不足的问题，克服了将从多个不同源项目中学习到的模型应用到目标项目中的挑战。与此同时，出现了两个新的问题:(1)模型训练过程中过多的不相关和冗余特征会影响训练效率，从而降低模型的预测精度;(2)由于开发环境等因素，不同项目间度量值的分布差异较大，导致模型实现跨项目预测时预测精度较低。,在该方法中，引入Pearson特征选择方法来解决数据冗余问题，并使用基于度量补偿的迁移学习技术来解决源项目和目标项目之间数据分布差异较大的问题。本文提出了一种基于特征选择和迁移学习的度量补偿软件缺陷预测方法。,实验结果表明，用该方法构建的模型在接收机工作特性曲线(AUC)值下面积和f1 -测度指标上都取得了较好的效果。,Spearman和Kendall系数一般适用于常阶变量。皮尔逊系数通常用于分析特征与响应变量之间的相关程度。模块缺陷类别是显示非线性趋势波动的恒定比率变量，并且在软件模块特征和缺陷类别预测之间存在一些相关性(即，在软件模块特征对缺陷类别预测的贡献程度上存在变化)。Cai et al.(2020)使用Pearson系数来衡量模块测度之间的相关性和模块类别线性相关性来过滤掉影响,跨项目,不同数据集不同度量集,在模型训练阶段，根据Pearson系数过滤掉与缺陷类别无关的冗余特征，然后使用传递分量分析(TCA)和双向度量补偿的组合来减少源项目和目标项目之间特征的分布差异,SMOTE,,"NASA度量数据程序(MDP)、Relink和AEEEM数据集
AEEEM是apache lucene (LC)、equinox (EQ)、eclipse JDT核心(JDT)、eclipse PDE UI (PDE)和Mylyn (ML)项目的集合。
Relink：Apache HTTP Server、Safe和Zxing",56-10000个模块,公开,完成,C/C++/JAVA,决策树分类器,对于NASA MDP数据集，模块粒度为方法，对于AEEEM数据集，模块粒度为类，对于Relink数据集，模块粒度为文件。,故障倾向,F1-measure，AUC,
"Walunj, Vijay; Gharibi, Gharib; Alanazi, Rakan; Lee, Yugyung",Defect prediction using deep learning with Network Portrait Divergence for software evolution,EMPIRICAL SOFTWARE ENGINEERING,10.1007/s10664-022-10147-0,2022,"Understanding software evolution is essential for software development tasks, including debugging, maintenance, and testing. As a software system evolves, it grows in size and becomes more complex, hindering its comprehension. Researchers proposed several approaches for software quality analysis based on software metrics. One of the primary practices is predicting defects across software components in the codebase to improve agile product quality. While several software metrics exist, graph-based metrics have rarely been utilized in software quality. In this paper, we explore recent network comparison advancements to characterize software evolution and focus on aiding software metrics analysis and defect prediction. We support our approach with an automated tool named GraphEvoDef. Particularly, GraphEvoDef provides three major contributions: (1) detecting and visualizing significant events in software evolution using call graphs, (2) extracting metrics that are suitable for software comprehension, and (3) detecting and estimating the number of defects in a given code entity (e.g., class). One of our major findings is the usefulness of the Network Portrait Divergence metric, borrowed from the information theory domain, to aid the understanding of software evolution. To validate our approach, we examined 29 different open-source Java projects from GitHub and then demonstrated the proposed approach using 9 use cases with defect data from the the PROMISE dataset. We also trained and evaluated defect prediction models for both classification and regression tasks. Our proposed technique has an 18% reduction in the mean square error and a 48% increase in squared correlation coefficient over the state-of-the-art approaches in the defect prediction domain.",3,在本文中，我们探索了最近的网络比较进展，以表征软件进化，并专注于帮助软件度量分析和缺陷预测。我们使用名为graphhevodef的自动化工具来支持我们的方法。,理解软件演进对于软件开发任务(包括调试、维护和测试)是必不可少的。随着软件系统的发展，它的规模越来越大，变得越来越复杂，这阻碍了它的理解。研究人员提出了几种基于软件度量的软件质量分析方法。主要的实践之一是预测代码库中软件组件之间的缺陷，以提高敏捷产品的质量。虽然存在几种软件度量标准，但基于图的度量标准很少用于软件质量。,在本文中，我们的目标是对从软件调用图中提取的度量和度量使用深度学习技术(Grove et al. 1997)来研究和调查软件进化和缺陷预测。我们探索了最近的网络比较进展，以表征软件进化，并专注于帮助软件度量分析和缺陷预测。我们使用名为graphhevodef的自动化工具来支持我们的方法。特别是，GraphEvoDef提供了三个主要的贡献:(1)使用调用图检测和可视化软件进化中的重要事件，(2)提取适合软件理解的度量，以及(3)检测和估计给定代码实体(例如，类)中的缺陷数量。我们的主要发现之一是从图论领域借来的网络肖像发散度量的有用性，以帮助理解软件进化。为了验证我们的方法，我们检查了来自GitHub的29个不同的开源Java项目，然后使用来自PROMISE数据集的缺陷数据的9个用例演示了建议的方法。我们还训练并评估了分类和回归任务的缺陷预测模型。,我们提出的技术在缺陷预测领域的均方误差减少了18%，平方相关系数增加了48%。,,项目内/跨项目,包含21个静态代码指标的类文件和网络肖像发散度量，软件网络,ANOVA,将软件表示为网咯，控制流程图,CAM、LOC和RFC是最具影响力的指标。,29个开源Java软件系统的384个版本，来自PROMISE数据集(Shirabad and Menzies 2005)的9个基于java的开源项目的数据集,大型,公开,完成,JAVA,ANN人工神经网络,类级,故障倾向/故障数量,我们对分类任务使用了度量F1，对回归任务使用了MSE和R2。,
"Goyal, Somya",Genetic Evolution-Based Feature Selection for Software Defect Prediction Using SVMs,JOURNAL OF CIRCUITS SYSTEMS AND COMPUTERS,10.1142/S0218126622501614,2022,"Software Defect Prediction (SDP) involves the early detection of fault-prone modules and reduces the testing efforts and cost. Support Vector Machine (SVM)-based SDP classifiers use large amount of high-dimensional data, and hence feature selection (FS) is applied for better accuracy. Search-based feature selection is found effective to improve the efficiency of predictors. This paper proposes a genetic evolution (GeEv) technique to select features. The GeEv technique involves introduction of diversity at intermediate level by the genetic evolution of random offspring with better survival capability. GeEv searches the feature space for an optimal feature subset using the performance of classification and number of features selected as the fitness function. The FS is modeled as an optimization problem and optimal solution is sought using GeEv. The performance is compared with baseline technique. From the experimental results, it is shown GeEv outperforms the competing FS approach and can achieve better accuracy than others statistically.",3,采用特征选择(FS)来提高准确率。基于搜索的特征选择可以有效地提高预测器的效率。本文提出了一种遗传进化(GeEv)技术来选择特征。,"软件缺陷预测(Software Defect Prediction, SDP)技术可以早期发现易发生故障的模块，减少测试时间和成本。基于支持向量机(SVM)的SDP分类器使用大量高维数据，因此采用特征选择(FS)来提高准确率。基于搜索的特征选择可以有效地提高预测器的准确率。",本文提出了一种遗传进化(GeEv)技术来选择特征。GeEv技术是通过随机选择具有更好生存能力的后代，在中间水平引入多样性。GeEv使用分类的性能和选择作为特征函数的特征数量来搜索特征空间中最优的特征子集。将FS建模为一个优化问题，并利用GeEv寻求最优解。并与基线技术进行了性能比较。,实验结果表明，GeEv方法在统计上优于竞争对手的FS方法，具有更好的准确率。,,版本内,NASA项目拥有一组静态代码度量的特性：LOC计数，Halstead和McCabe复杂性指标。,遗传进化(GeEv)来选择SDP分类问题的特征:提出的GeEv是一种基于搜索的启发式优化技术,,,NASA存储库,124-7720个模块,公开,完成,C/C++,svm,模块级,故障倾向,Area Under the ROC Curve (AUC)，Accuracy，F1-measure,
"Cui, Mengtian; Long, Songlin; Jiang, Yue; Na, Xu",Research of Software Defect Prediction Model Based on Complex Network and Graph Neural Network,ENTROPY,10.3390/e24101373,2022,"The goal of software defect prediction is to make predictions by mining the historical data using models. Current software defect prediction models mainly focus on the code features of software modules. However, they ignore the connection between software modules. This paper proposed a software defect prediction framework based on graph neural network from a complex network perspective. Firstly, we consider the software as a graph, where nodes represent the classes, and edges represent the dependencies between the classes. Then, we divide the graph into multiple subgraphs using the community detection algorithm. Thirdly, the representation vectors of the nodes are learned through the improved graph neural network model. Lastly, we use the representation vector of node to classify the software defects. The proposed model is tested on the PROMISE dataset, using two graph convolution methods, based on the spectral domain and spatial domain in the graph neural network. The investigation indicated that both convolution methods showed an improvement in various metrics, such as accuracy, F-measure, and MCC (Matthews correlation coefficient) by 86.6%, 85.8%, and 73.5%, and 87.5%, 85.9%, and 75.5%, respectively. The average improvement of various metrics was noted as 9.0%, 10.5%, and 17.5%, and 6.3%, 7.0%, and 12.1%, respectively, compared with the benchmark models.",3,本文从复杂网络的角度提出了一种基于图神经网络的软件缺陷预测框架。,软件缺陷预测的目标是利用模型挖掘历史数据进行预测。现有的软件缺陷预测模型主要关注软件模块的代码特征。但是，它们忽略了软件模块之间的连接。,本文从复杂网络的角度提出了一种基于图神经网络的软件缺陷预测框架。首先，我们将软件视为一个图，其中节点表示类，边表示类之间的依赖关系。然后，我们使用群体检测算法将图划分为多个子图。第三，通过改进的图神经网络模型学习节点的表示向量。最后，利用节点表示向量对软件缺陷进行分类。采用基于图神经网络的谱域和空间域的两种图卷积方法，在PROMISE数据集上对该模型进行了测试。,研究表明，两种卷积方法在准确率、f值和MCC (Matthews相关系数)等各项指标上分别提高了86.6%、85.8%和73.5%，以及87.5%、85.9%和75.5%。与基准模型相比，各种指标的平均改进分别为9.0%、10.5%和17.5%，以及6.3%、7.0%和12.1%。,,版本内,"复杂网络：将软件源代码中的类视为网络中的节点，将类之间的依赖关系视为网络的边缘
和20个传统度量",,,,PROMISE数据集,229-965个类,公开,完成,JAVA,基于谱域的图卷积神经网络GCN和基于空间域的图卷积神经网络GIN进行研究+MLP,类级,故障倾向,"accuracy rate, F-measure, and MCC value",
"Goyal, Somya",Software fault prediction using evolving populations with mathematical diversification,SOFT COMPUTING,10.1007/s00500-022-07445-6,2022,"Software fault prediction (SFP) plays a vital role into fostering high quality throughout the software development process. It allows to identify the fault-prone modules in early development phases and facilitates the focused and effective testing over the fault-prone modules. Machine learning (ML)-based classifiers are prominently being used for fault prediction in the software industry. The accuracy of the ML models depends upon the training data and its quality. The curse of high dimensionality adversely impacts the classification power of a ML model. The presence of inter-correlated, insignificant and/or redundant features (or attributes) in the training data hinders the performance of ML classifiers. Feature preprocessing (or feature selection (FS)) is the solution to this issue. Meta-heuristics is the key method to find out the most significant feature subset. In this paper, a novel feature selection method is devised using mathematical diversification for genetic evolution. It avoids the local optimums by utilizing arithmetic diversification among the candidate solutions (or populations). The survival of fittest is the working principle of evolving populations with crossover and mutation operations. The selected feature subset is fed to five classification algorithms, namely artificial neural network, support vector machine, decision tree, k-nearest neighbor and naive Bayes. The proposed model is trained and tested over five datasets from NASA corpus, namely CM1, JM1, KC1, KC2 and PC1. In total, 100 SFP models are implemented (4 feature selection methods x 5 datasets x 5 classification algorithms). From the experiments, it is observed that the SFP models with proposed feature selection technique of evolving populations with mathematical diversification (FS-EPwMD) are better than other models. It can be concluded that the proposed SFP model built using proposed FS-EPwMD with artificial neural networks performs statistically best among all the competing 100 SFP models irrespective of the datasets used.",3,本文提出了一种基于数学多样化的遗传进化特征选择方法。它利用候选解(或种群)之间的算术多样化来避免局部最优。适者生存是通过交叉和突变操作进化的种群的工作原理。,软件故障预测(SFP)在整个软件开发过程中对提高软件质量起着至关重要的作用。它允许在早期开发阶段识别易出错模块，并有助于对易出错模块进行集中有效的测试。基于机器学习(ML)的分类器主要用于软件行业的故障预测。机器学习模型的准确性取决于训练数据及其质量。高维的诅咒会对机器学习模型的分类能力产生不利影响。训练数据中存在相互关联的、不重要的和/或冗余的特征(或属性)会阻碍ML分类器的性能。特征预处理(或特征选择(FS))是解决这个问题的方法。元启发式是找出最显著特征子集的关键方法。,本文提出了一种基于数学多样化的遗传进化特征选择方法。它利用候选解(或种群)之间的算术多样化来避免局部最优。适者生存是通过交叉和突变操作进化的种群的工作原理。选择的特征子集被馈送到5种分类算法，即人工神经网络、支持向量机、决策树、k近邻和纳维贝叶斯。该模型在NASA语料库CM1、JM1、KC1、KC2和PC1 5个数据集上进行了训练和测试。总共实现了100个SFP模型(4种特征选择方法 5个数据集 5种分类算法)。,实验结果表明，基于数学多样化进化种群特征选择技术的SFP模型(FS-EPwMD)优于其他模型。可以得出结论，无论使用何种数据集，使用拟议的FS-EPwMD和人工神经网络构建的拟议SFP模型在所有竞争的100个SFP模型中都具有统计上的最佳性能。,,版本内,NASA项目拥有一组静态代码度量的特性，例如LOC计数、Halstead和McCabe复杂性度量，其中21个指标包括5个基于代码行度量的指标，3个是从McCabe的复杂度中提取的指标，4个基于Halstead度量的指标，8个来自Halstead度量的指标，1个是分支计数的指标。,算法优化算法(Abualigah et al. 2021)与最先进、最可靠的元启发式算法，即遗传进化(Ali and Gravino 2020)完美融合。,,,本研究使用的是清洁过的NASA储存库,498-10000个模块,公开,完成,C/C++,ANN人工神经网络、SVM支持向量机、DT决策树、KNNk近邻和NB朴素贝叶斯,模块级,故障倾向,AUC，accuracy,与Genetic Evolution-Based Feature Selection for Software Defect Prediction Using SVMs这篇文章非常相似，包括数据集和方法
"Tao, Chuanqi; Wang, Tao; Guo, Hongjing; Zhang, Jingxuan",An Approach to Software Defect Prediction Combining Semantic Features and Code Changes,INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING,10.1142/S0218194022500504,2022,"Software defect prediction (SDP), which predicts defective code regions, can help developers reasonably allocate limited resources for locating bugs and prioritizing their testing efforts. Previous work on defect prediction has used machine learning and artificial software metrics. However, traditional defect prediction features extracted from artificial software metrics often fail to capture the syntactic and semantic information of defective modules. This work on defect prediction mostly focuses on abstract syntax tree (AST). Moreover, because current research on AST technology is relatively mature, it is difficult to further improve the accuracy of defect prediction when only using AST to characterize codes. In this paper, in order to capture more semantic features, we extract semantic information both from the sequences of AST tokens and code change tokens. In addition, to leverage the traditional features extracted from statistical metrics, we also combine the semantic features with traditional defect prediction features to perform SDP, and use the gated fusion mechanism to determine the combination ratio of the two kinds of features. In our empirical studies, 10 open-source Java projects from the PROMISE repository are chosen as our empirical subjects. Experimental results show that our proposed approach can perform better than several state-of-the-art baseline SDP methods.",3,在本文中，为了捕获更多的语义特征，我们从AST标记和代码更改标记的序列中提取语义信息。,软件缺陷预测(SDP)，它预测有缺陷的代码区域，可以帮助开发人员合理地分配有限的资源来定位错误，并优先安排他们的测试工作。以前在缺陷预测方面的工作使用了机器学习和人工软件度量。然而，传统的从人工软件度量中提取的缺陷预测特征往往不能捕获缺陷模块的语法和语义信息。缺陷预测方面的工作主要集中在抽象语法树(AST)上。此外，由于目前对AST技术的研究相对成熟，仅使用AST来表征代码时，很难进一步提高缺陷预测的准确性。,在本文中，为了捕获更多的语义特征，我们从AST标记和代码更改标记的序列中提取语义信息。此外，为了利用统计度量提取的传统特征，我们还将语义特征与传统缺陷预测特征结合起来进行SDP，并利用门控融合机制确定两种特征的组合比例。在我们的实证研究中，从PROMISE存储库中选择了10个开源Java项目作为我们的实证对象。,实验结果表明，我们提出的方法比几种最先进的基线SDP方法性能更好。,https://github.com/c2nes/javalang.,跨版本,"Abstract Syntax Tree (AST)：(1)记录为方法名的函数调用和类实例创建节点;(2)方法声明、类型声明和类声明等声明节点;(3)控制节点，如while语句、catch子句、if语句、throw语句等。
代码变更：我们主要基于扩展的ChangeDistiller工具提取三种类型的代码更改:调用相关节点、声明相关节点和控件相关节点的插入、删除和更新。
传统度量如右图",,我们使用BiLSTM网络从源代码自动生成语义特征，以提高缺陷预测。,,PROMISE存储库中选择了10个开源java项目,150-800个文件,公开,完成,JAVA,逻辑回归LR,文件级,故障倾向,"一般场景：precision, recall，F measure, and MCC，努力感知场景：我们选择PofB20[18]，它可以根据缺陷预测模型给出的结果度量代码检查的成本效率。",
"Anbu, M.",Improved mayfly optimization deep stacked sparse auto encoder feature selection scorched gradient descent driven dropout XLM learning framework for software defect prediction,CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE,10.1002/cpe.7240,2022,"Software testing is the process of improving software quality by classifying and removing defects in the software development. Previously, several methods were used for software defect prediction, but any one method did not provide sufficient accuracy. To overcome this issue, an improved may fly optimization with deep stacked sparse auto encoder feature selection scorched gradient descent driven dropout extreme learning machine framework (SDP-IMFOFS-GDDDXLMC) is proposed in this article for software defect prediction. Here, an IMFO method is considered for feature selection techniques. In feature selection technique, features are selected, such as PC1, PC4, and MC1 for selecting the probable minimal attribute. Then, GDDDXLMC approach is used to classify buggy and clean software detection. The proposed approach is implemented in MATLAB platform. The performance metrics, such as accuracy, precision, F-measure, sensitivity, specificity, Mathew correlation coefficient (MCC) is examined to examine the performance of the proposed method. The simulation performance of the proposed SDP-IMFOFS-GDDDXLMC method attains higher accuracy 99.75%, 97.85%, 95.13%, 14.89%, 16.34%, 17.89%, and 98.79, higher sensitivity 96.34%, 91.23%, 89.12%, 12.67%, 17.56%, 18.90%, and 87.25% higher specificity 14.89%, 16.89%, 20.67%, 93.67%, 92.37%, 98.47%, and 94.78% compared with the existing methods, like SDP-MLP-PSO, SDP-BPNN-RBFNN, SDP-CNN-RNN-LSTM, SDP-KBN-LIME, SDP-SLDeep-LSTM, SDP-K-PCA-ELM, and SDP-CNN-PHI forest, respectively.",3,本文提出了一种改进的基于深度堆叠稀疏自编码器特征选择的梯度下降驱动dropout极限学习机框架(SDP-IMFOFS-GDDDXLMC)，用于软件缺陷预测 本文考虑了一种用于特征选择技术的IMFO方法,软件测试是通过对软件开发过程中的缺陷进行分类和剔除，从而提高软件质量的过程。以前，有几种方法被用于软件缺陷预测，但是任何一种方法都不能提供足够的准确性。,为了克服这一问题，本文提出了一种改进的基于深度堆叠稀疏自编码器特征选择的梯度下降驱动dropout极限学习机框架(SDP-IMFOFS-GDDDXLMC)，用于软件缺陷预测。本文考虑了一种用于特征选择技术的IMFO方法。在特征选择技术中，选择特征，如PC1、PC4和MC1来选择可能的最小属性。然后，采用GDDDXLMC方法对软件检测中的bug和clean进行分类。该方法在MATLAB平台上实现。通过准确度、精密度、f值、灵敏度、特异性、马修相关系数(MCC)等性能指标来检验该方法的性能。,与现有的SDP-MLP-PSO、SDP-BPNN-RBFNN、sdp - cnn - lstm、SDP-KBN-LIME、SDP-SLDeep-LSTM、SDP-K-PCA-ELM、SDP-CNN-PHI forest等方法相比，所提出的SDP-IMFOFS-GDDDXLMC方法的准确率分别达到99.75%、97.85%、95.13%、14.89%、16.34%、89.12%、12.67%、17.56%、18.90%和87.25%，灵敏度分别达到14.89%、16.89%、20.67%、93.67%、92.37%、98.47%和94.78%。,基于代码的矩阵(CBMs)软件变更度量(scm)被用来对软件中的缺陷进行分类。cbm用于预测缺陷部件scm用于计算软件版本的变化，cbm用于计算由于bug导致的软件复杂性增长以及软件技术在生命周期内功能变化的代码大小。在缺陷预测应用中，CBM比SCM更可行,版本内,不同度量数目,"采用改进的可飞优化深度堆叠稀疏自编码器技术进行特征选择。
蜉蝣的优化是通过飞行行为和交配过程来激发的。通过多目标优化的收敛行为来衡量蜉蝣的性能，该收敛行为用于现实世界不同的流水车间调度问题。苍蝇是昆虫，它不过是古翅目昆虫。这是一种高质量的元启发式优化方法，它在三个模型中进行优化:单模态、多模态、固定维度。它在全局搜索的同时优化了局部搜索的概率。",,,输入数据是通过NASA的数据集收集的,136-10000个模块,公开,完成,JAVA,梯度下降驱动dropout XLM学习方法,模块级,故障倾向,"precision, F-score, accuracy, sensitivity, specificity, MCC",
"Yang, Fengyu; Huang, Yaxuan; Xu, Haoming; Xiao, Peng; Zheng, Wei",Fine-Grained Software Defect Prediction Based on the Method-Call Sequence,COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE,10.1155/2022/4311548,2022,"Currently, software defect-prediction technology is being extensively researched in the design of metrics. However, the research objects are mainly limited to coarse-grained entities such as classes, files, and packages, and there is a wide range of defects that are difficult to predict in actual situations. To further explore the information between sequences of method calls and to learn the code semantics and syntactic structure between methods, we generated a method-call sequence that retains the code context structure information and the token sequence representing semantic information. We embedded the token sequence into the method-call sequence and encoded it into a fixed-length real-valued vector. We then built a defect-prediction model based on the transformer, which maps the code-vector representation containing the method-call sequences to a low-dimensional vector space to generate semantic features and syntactic structure features and also predicts the defect density of the method-call sequence. We conducted experiments on 10 open-source projects using the ELFF dataset. The experimental results show that the method-call sequence-level prediction effect is better than the class-level effect, and the prediction results are more stable than those of the method level. The mean absolute error (MAE) value of our approach was 8% lower than that of the other deep-learning methods.",3,我们建立了一个基于转换器的缺陷预测模型，该模型将包含方法调用序列的代码向量表示映射到低维向量空间，以生成语义特征和句法结构特征，,目前，软件缺陷预测技术在度量设计中得到了广泛的研究。然而，研究对象主要局限于粗粒度的实体，例如类、les和包，并且存在许多在实际情况下难以预测的缺陷。,为了进一步探索方法调用序列之间的信息，并了解方法之间的代码语义和语法结构，我们生成了一个方法调用序列，该序列保留了代码上下文结构信息和表示语义信息的标记序列。我们将记号序列嵌入到方法调用序列中，并将其编码为一个长度为x的实值向量。然后，我们建立了一个基于转换器的缺陷预测模型，该模型将包含方法调用序列的代码向量表示映射到低维向量空间，以生成语义特征和句法结构特征，并预测方法调用序列的缺陷密度。我们使用ELFF数据集在10个开源项目上进行了实验。,结果表明，方法调用序列级别的缺陷预测优于类级别的缺陷预测，并且比方法级别的缺陷预测更稳定。TSASS模型在学习程序语义特征方面也优于所比较的深度学习模型，其MAE和MSE值均低于其他深度模型。就缺陷预测的总体性能而言，TSASS方法的MAE和MSE值低于基线方法。,,版本内,在AST上只选择三种类型的节点:方法调用和类实例创建节点、声明节点和控制流节点。,,通过TSASS模型提取语义和句法结构特征，最后将特征输入缺陷预测模型进行训练和预测。,,选择了ELFF[32]数据集中的10个Java开源项目作为我们的评估数据集。,919-9000个方法,公开,完成,JAVA,基于transformer建立了一个叫做TSASS的神经网络模型逻辑回归,方法级,故障密度/故障数量,"the mean squared error (MSE), rootmean-squared error (RMSE),均方误差(MSE)、均方根误差(RMSE)、",
"Taser, Pelin Yildirim",A novel multi-view ordinal classification approach for software bug prediction,EXPERT SYSTEMS,10.1111/exsy.13044,2022,"Software bug prediction aims to enhance software quality and testing efficiency by constructing predictive classification models using code properties. This enables the prompt detection of fault-prone modules. There are several machine learning-based software bug prediction studies, which mainly focus on single view data by disregarding the natural ordering relation among the class labels in the literature. Thus, these studies cause losing each view's own intrinsic structure and the inherent order of the labels that positively affect the prediction performance. To overcome this drawback, this study focuses on integrating ordering information and a multi-view learning strategy. This paper proposes a novel approach multi-view ordinal classification (MVOC), which learns from different views (complexity, coupling, cohesion, inheritance and scale) of the software dataset separately and predicts software bugs taking the inherent order of class labels (non-buggy, less buggy and more buggy) into consideration. To demonstrate its prediction performance, the MVOC approach was executed on the 40 different real-world software datasets using six different classification algorithms as base learners. In the experiments, the MVOC approach was compared with traditional classifiers and their multi-view implementations in terms of precision, recall, f-measure and accuracy rate metrics. The results indicate that the MVOC approach presents better prediction performance on average than the multi-view-based and traditional classifiers. It is also observed from the results that the MVOC.RF model achieved the highest classification performance with an average accuracy rate of 85.65%.",3,本研究着重于整合排序信息和多视图学习策略。本文提出了一种新的多视图有序分类方法(MVOC)，该方法分别从软件数据集的不同视图(复杂性、耦合性、内聚性、继承性和规模)进行学习，并根据类标签的固有顺序(无bug、少bug和多bug)对软件bug进行预测,软件bug预测的目的是利用代码属性构建预测分类模型，提高软件质量和测试效率。这样可以及时发现容易出现故障的模块。目前已有一些基于机器学习的软件bug预测研究，这些研究主要集中在单视图数据上，忽略了类标签之间的自然顺序关系。因此，这些研究导致失去了每个视图自己的固有结构和标签的固有顺序，这些结构和顺序对预测性能有积极影响。,为了克服这一缺陷，本研究着重于整合排序信息和多视图学习策略。本文提出了一种新的多视图有序分类方法(MVOC)，该方法分别从软件数据集的不同视图(复杂性、耦合性、内聚性、继承性和规模)进行学习，并根据类标签的固有顺序(无bug、少bug和多bug)对软件bug进行预测。为了证明其预测性能，使用六种不同的分类算法作为基础学习器，在40个不同的实际软件数据集上执行了MVOC方法。在实验中，将MVOC方法与传统分类器及其多视图实现在准确率、召回率、f-measure和准确率指标上进行了比较。,结果表明，所构建的MVOC模型优于基于mv的分类器和传统的分类器。此外，从结果中可以看出，MVOC。RF模型在实验数据集上的分类性能最高，平均准确率为85.65%。实验结果表明，将排序信息与多视图学习策略相结合可以提高预测性能。,,版本内,使用五个不同的不相交的特征集(视图)，如复杂性(视图1)、耦合(视图2)、内聚(视图3)、继承(视图4)和规模(视图5)，创建了软件数据集(训练集)。捕获软件组件静态属性的静态度量包括面向过程的McCabe的圈复杂度度量、Halstead度量和面向对象的Chidamber和Kemerer (Ck)度量。,,,,在Tera-PROMISE存储库(PROMISE软件工程存储库，2015)中提供40个不同的真实软件缺陷数据集供公众使用,27-900个样本,公开,完成,JAVA,使用NB、MLP、SVM、DT (C4.5)、RF和AdaBoost算法作为基础学习器,类级,故障倾向,"precision, recall, f-measure and accuracy rate metrics.",
"Li, Chenlong; Yuan, Yuyu; Yang, Jincui",Causally Remove Negative Confound Effects of Size Metric for Software Defect Prediction,APPLIED SCIENCES-BASEL,10.3390/app12031387,2022,"Software defect prediction technology can effectively detect potential defects in the software system. The most common method is to establish machine learning models based on software metrics for prediction. However, most of the prediction models are proposed without considering the confounding effects of size metric. The size metric has unexpected correlations with other software metrics and introduces biases into prediction results. Suitably removing these confounding effects to improve the prediction model's performance is an issue that is still largely unexplored. This paper proposes a method that can causally remove the negative confounding effects of size metric. First, we quantify the confounding effects based on a causal graph. Then, we analyze each confounding effect to determine whether they are positive or negative, and only the negative confounding effects are removed. Extensive experimental results on eight data sets demonstrate the effectiveness of our proposed method. The prediction model's performance can, in general, be improved after removing the negative confounding effects of size metric.",3,本文提出了一种消除尺寸度量负混淆效应的方法,软件缺陷预测技术可以有效地检测软件系统中潜在的缺陷。最常见的方法是建立基于软件指标的机器学习模型进行预测。然而，大多数预测模型都没有考虑尺寸度量的混杂效应。大小度量与其他软件度量具有意想不到的相关性，并在预测结果中引入偏差。适当地去除这些混杂效应以提高预测模型的性能是一个很大程度上尚未探索的问题。,本文提出了一种消除尺寸度量负混淆效应的方法。首先，我们根据因果图量化了混淆效应。然后，我们对每个混杂效应进行分析，以确定它们是正面的还是负面的，仅去除负面的混杂效应。,大量的实验结果验证了CNCERM的有效性。与Logistic回归(LR)、线性混杂效应去除方法(LCERM) + LR和神经网络(NN)方法相比，CNCERM + LR在8个NASA数据集上对F1的处理效果最好。,,版本内,包含各种静态代码度量，包括McCabe和Halstead，这些度量从不同的角度指示代码的质量。,"Causally Removing Negative Confound Effects Method (CRNCEM).因果消除负面混淆效应法其中核心是Pearson coefficients，
使用基于相关性的方法来分析混杂效应的方向。我们知道，高相关性通常意味着一个软件度量对软件缺陷的预测能力很强。我们将CorXY (X与Y之间的相关性)与CorX ' Y (X '与Y之间的相关性)进行比较，如果CorXY较大，则表示Z损害了X的预测能力;换句话说，混淆有负面影响。应该消除这种混淆效应。反之，如果CorX 'Y较大，则说明Z增强了X的预测能力，混杂具有正向作用。这种混淆效应应该保留。
第一步是量化混淆效应的价值;第二步是分析混杂效应，然后去除不利于缺陷预测的负面混杂效应。",,,实验数据来自度量数据程序(MDP)存储库的8个清洗过的数据集,127-9277个模块,公开,完成,C/C++,逻辑回归,模块级,故障倾向,F1,
"Chen, Yong; Xu, Chao; He, Jing Selena; Xiao, Sheng; Shen, Fanfan",Compiler IR-Based Program Encoding Method for Software Defect Prediction,CMC-COMPUTERS MATERIALS & CONTINUA,10.32604/cmc.2022.026750,2022,"With the continuous expansion of software applications, people's requirements for software quality are increasing. Software defect prediction is an important technology to improve software quality. It often encodes the software into several features and applies the machine learning method to build defect prediction classifiers, which can estimate the software areas is clean or buggy. However, the current encoding methods are mainly based on the traditional manual features or the AST of source code. Traditional manual features are difficult to reflect the deep semantics of programs, and there is a lot of noise information in AST, which affects the expression of semantic features. To overcome the above deficiencies, we combined with the Convolutional Neural Networks (CNN) and proposed a novel compiler Intermediate Representation (IR) based program encoding method for software defect prediction (CIR-CNN). Specifically, our program encoding method is based on the compiler IR, which can eliminate a large amount of noise information in the syntax structure of the source code and facilitate the acquisition of more accurate semantic information. Secondly, with the help of data flow analysis, a Data Dependency Graph (DDG) is constructed on the compiler IR, which helps to capture the deeper semantic information of the program. Finally, we use the widely used CNN model to build a software defect prediction model, which can increase the adaptive ability of the method. To evaluate the performance of the CIR-CNN, we use seven projects from PROMISE datasets to set up comparative experiments. The experiments results show that, in WPDP, with our CIR-CNN method, the prediction accuracy was improved by 12% for the AST-encoded CNN-based model and by 20.9% for the traditional features-based LR model, respectively. And in CPDP, the AST-encoded DBNbased model was improved by 9.1% and the traditional features-based TCA+ model by 19.2%, respectively.",3,我们结合卷积神经网络(CNN)，提出了一种基于编译器中间表示(IR)的软件缺陷预测程序编码方法(cirr -CNN)。,随着软件应用的不断扩大，人们对软件质量的要求也越来越高。软件缺陷预测是提高软件质量的一项重要技术。它通常将软件编码为几个特征，并应用机器学习方法构建缺陷预测分类器，该分类器可以估计软件区域是干净的还是有缺陷的。然而，目前的编码方法主要是基于传统的手工特征或源代码的AST。传统的手工特征难以反映程序的深层语义，AST中存在大量的噪声信息，影响了语义特征的表达。,"为了克服上述不足，我们结合卷积神经网络(CNN)，提出了一种基于编译器中间表示(IR)的软件缺陷预测程序编码方法(cirr -CNN)。具体来说，我们的程序编码方法是基于编译器IR，可以消除源代码语法结构中的大量噪声信息，便于获取更准确的语义信息。其次，借助数据流分析，在编译器IR上构造数据依赖图(data Dependency Graph, DDG)，有助于捕获程序的深层语义信息。最后，利用广泛使用的CNN模型构建软件缺陷预测模型，提高了方法的自适应能力。为了评估cirr - cnn的性能，我们使用PROMISE数据集中的七个项目建立了对比实验。",我们的方法在WPDP和CPDP中都能取得很好的效果。在两个文件级缺陷预测任务，即项目内缺陷预测(WPDP)和跨项目缺陷预测(CPDP)上，研究了基于编译器ir的程序编码方法自动提取的特征的性能。在WPDP中，我们对七个开源项目的实验表明，在缺陷预测的F1分数方面，平均而言，cirr -CNN比基于ast的CNN和传统基于特征的方法分别提高了20.9%和12%。cirr - cnn与最先进的基于dbn的方法具有竞争力。在CPDP中，我们对10对开源项目的实验表明，平均而言，cirr - cnn比基于ast的DBN和传统的基于特征的TCA+方法分别提高了19.2%和9.1%。,然而，基于ast的程序语义捕获仍然存在一些不足。首先，Phan等[10]表明，具有相同语义的代码，如图1中的File1.c和File2.c，由于AST中每个节点的权值矩阵是根据AST中的位置确定的，因此AST的结构会发生变化，从而影响缺陷预测的性能。其次，AST不适合进行数据流分析等深度语义分析，影响软件缺陷特征的突出性。图2a和2b显示了两个代码片段，它们是从GitHub中Redis项目的提交信息中提取出来的。有bug的代码和干净的代码之间的唯一区别在于第11行不同的标志常量。这两个代码片段的AST结构将是相同的，唯一不同的节点是具有不同值的常量节点，当前基于AST的方法用于限制令牌的数量而忽略了它。因此，目前基于ast的方法将无法捕获图2a中的缺陷特征。此外，目前大多数基于ast的深度学习缺陷预测模型很少考虑变量的类型信息，而变量的类型信息也是程序语义的重要表达。,版本内/跨项目,IR(编译器通常设计一个结构良好的内部表示，称为中间表示(IR))，CFG、DDG,,为了获得更准确的程序语义信息以辅助软件缺陷预测，我们首先从IR中提取CFG，然后通过CFG构造程序的DDG。将DDG的每个节点编码为数值向量。与现有的主流方法类似，编码过程包括两个阶段:a)从节点中提取令牌;b)将令牌转换为数值向量。,"为了更好地分析和优化程序，编译器通常设计一个结构良好的内部表示，称为中间表示(IR)。Peng等[11]表明IR更适用于学习代码表示，而不是高级程序语言。
CFG是一个有向图，G = (V, E)，其中V是顶点集合{v1, v2，…， vn}， E是有向边的集合{<vi, vj>， <vk, vl>，…}。在CFG中，每个顶点代表一个基本块，它是一个线性IR序列，具有一个入口点(执行的第一个IR)和一个出口点(执行的最后一个IR)。有向边表示控制流路径。CFG可以显示进程中每个基本块对应的基本块之间的关系、动态执行状态和语句表。然而，它不能很好地处理基本块中指令之间的关系
DDG也是一个有向图，G = (V, E)，其中V是顶点集合{v1, v2，…， vn}， E是有向边的集合{<vi, vj>， <vk, vl>，…}。然而，在DDG中，每个顶点表示一个IR，有向边表示数据依赖关系。我们用IRi表示程序中的第i个IR。如果IRi必须在IRj之前执行，那么从IRi到IRj之间有一条有向边。",我们从PROMISE数据存储库中收集Java项目,103-800个文件,公开,完成,JAVA,CNN+逻辑回归作为最终分类器,文件级,故障倾向,F1 score,
"Gupta, Mansi; Rajnish, Kumar; Bhattacharjee, Vandana",Cognitive Complexity and Graph Convolutional Approach Over Control Flow Graph for Software Defect Prediction,IEEE ACCESS,10.1109/ACCESS.2022.3213844,2022,"The software engineering community is working to develop reliable metrics to improve software quality. It is estimated that understanding the source code accounts for 60% of the software maintenance effort. Cognitive informatics is important in quantifying the degree of difficulty or the efforts made by developers to understand the source code. Several empirical studies were conducted in 2003 to assign cognitive weights to each possible basic control structure of software, and these cognitive weights are used by several researchers to evaluate the cognitive complexity of software systems. In this paper, an effort has been made to categorize the Control Flow Graphs (CFGs) nodes according to their node features. In our case, we extracted seven unique features from the program, and each unique feature was assigned an integer value that we evaluated through Cognitive Complexity Measures (CCMs). We then incorporated CCMs' results as a node feature value in CFGs and generated the same based on the node connectivity for a graph. In order to obtain the feature representation of the graph, a node vector matrix is then created for the graph and passed to the Graph Convolutional Network (GCN). We prepared our data sets using GCN output and then built Deep Neural Network Defect Prediction (DNN-DP) and Convolutional Neural Network Defect Prediction (CNN-DP) models to predict software defects. The Python programming language is used, along with Keras and TensorFlow. Three hundred twenty Python programs were written by our talented UG and PG students, and all experiments were carried out during laboratory classes. Together with three skilled lab programmers, they compiled and ran each individual program and detected defect/no-defect programs before categorizing them into three different classes, namely Simple, Medium, and Complex programs. Accuracy, Receiver Operating Characteristics (ROC), Area Under Curve (AUC), F-measure, Precision and hyper-parameter tuning procedures are used to evaluate the approaches. The experimental results show that the proposed models outperformed state-of-the-art methods such as Nave Bayes (NB), Decision Tree (DT), Support Vector Machine (SVM), and Random Forest (RF) in all evaluation criteria.",3,根据控制流图节点的特征对控制流图节点进行了分类。在我们的案例中，我们从程序中提取了7个独特的特征，,软件工程社区正在努力开发可靠的度量来改进软件质量。据估计，理解源代码占软件维护工作的60%。认知信息学在量化开发人员理解源代码的难度或付出的努力方面非常重要。2003年进行了几项实证研究，为每个可能的软件基本控制结构分配认知权重，并使用这些认知权重来评估软件系统的认知复杂性。,"本文根据控制流图节点的特征对控制流图节点进行了分类。在我们的案例中，我们从程序中提取了7个独特的特征，并且每个独特的特征都被分配了一个整数值，我们通过认知复杂性度量(Cognitive Complexity Measures, CCMs)对其进行评估。然后，我们将CCMs的结果作为CFGs中的节点特征值，并根据图的节点连通性生成相同的节点特征值。为了获得图的特征表示，然后为图创建节点向量矩阵并传递给图卷积网络(GCN)。我们使用GCN输出准备数据集，然后构建深度神经网络缺陷预测(DNN-DP)和卷积神经网络缺陷预测(CNN-DP)模型来预测软件缺陷。使用Python编程语言，以及Keras和TensorFlow。我们优秀的UG和PG学生编写了320个Python程序，所有实验都是在实验课上进行的。与三个熟练的实验室程序员一起，他们编译并运行每个单独的程序，并检测缺陷/无缺陷程序，然后将它们分为三个不同的类别，即简单、中等和复杂程序。准确度、受试者工作特征(ROC)、曲线下面积(AUC)、f测量、精度和超参数调谐程序用于评估方法。",实验结果表明，所提出的模型在所有评价标准上都优于最先进的方法，如朴素贝叶斯(NB)、决策树(DT)、支持向量机(SVM)和随机森林(RF)。,传统的方法集中于创建和融合程序特性。大多数产品指标都是基于源代码的统计数据。例如，Halstead度量通过计算运算符和操作数的数量来确定[2]，Chidamber和Kemerer (CK)度量通过计算函数和继承的数量来确定[3]，McCabe度量通过检查程序的控制流图来计算程序的复杂性[4]。,版本内,"CFG：从源代码中提取特征(在我们的研究中，我们使用七个节点特征，即in(输入)，OUT(输出)，IF-THEN-ELSE(分支)，WHILE(迭代)，for(迭代)，EXP(表达式)和FC(函数调用)，并以给定的顺序[in, OUT, IF-THEN-ELSE, WHILE, for, EXP, FC]表示CFG中的节点。(b)为程序构建CFGs，生成节点特征值。(c)最后，为整个CFG创建节点向量矩阵，并将其传递给GCN进行自动学习特征。",Complexity Measures CCMs复杂性度量，并将ccm的结果作为cfg中的节点特征值，并基于图的节点连通性生成相同的值。为了获得图的特征表示，然后为图创建节点向量矩阵并传递给图卷积网络(GCN)。,,,我们优秀的UG和PG学生编写了320个Python程序用于缺陷预测模型分析，所有实验都是在实验课上进行的。,320个文件,私有,完成,python,图卷积网络(GCN)+CNN或DNN,文件级,故障倾向,"Precision, Recall, F-measure, Accuracy, ROC, and AUC values.",
"Miholca, Diana-Lucia; Tomescu, Vlad-Ioan; Czibula, Gabriela",An in-Depth Analysis of the Software Features' Impact on the Performance of Deep Learning-Based Software Defect Predictors,IEEE ACCESS,10.1109/ACCESS.2022.3181995,2022,"Software Defects Prediction represents an essential activity during software development that contributes to continuously improving software quality and software maintenance and evolution by detecting defect-prone modules in new versions of a software system. In this paper, we are conducting an in-depth analysis on the software features' impact on the performance of deep learning-based software defect predictors. We further extend a large-scale feature set proposed in the literature for detecting defect-proneness, by adding conceptual software features that capture the semantics of the source code, including comments. The conceptual features are automatically engineered using Doc2Vec, an artificial neural network based prediction model. A broad evaluation performed on the Calcite software system highlights a statistically significant improvement obtained by applying deep learning-based classifiers for detecting software defects when using conceptual features extracted from the source code for characterizing the software entities.",3,在本文中，我们深入分析了软件特征对基于深度学习的软件缺陷预测器性能的影响。我们进一步扩展了文献中提出的用于检测,软件缺陷预测代表了软件开发过程中的一项基本活动，它通过检测软件系统新版本中容易出现缺陷的模块，有助于持续改进软件质量和软件维护与发展。,在本文中，我们深入分析了软件特征对基于深度学习的软件缺陷预测器性能的影响。我们进一步扩展了文献中提出的用于检测缺陷倾向的大规模特征集，通过添加捕获源代码语义的概念性软件特征，包括注释。概念特征使用Doc2Vec自动设计，Doc2Vec是一种基于人工神经网络的预测模型。,对Calcite软件系统进行的广泛评估强调了在使用从源代码中提取的概念特征来表征软件实体时，通过应用基于深度学习的分类器来检测软件缺陷而获得的统计显著改进。,"计算一个数据集预测的困难程度D. Zhang, J. Tsai, and G. Boetticher, ‘‘Improving credibility of machine learner models in software engineering,’’ in Proc. Adv. Mach. Learn. Appl. Softw. Eng., 2007, pp. 52C72.",版本内,Calcite数据集[10]中的4189个软件实体特征包括：?使用mecoSHARK[63]收集的静态代码度量。?使用mecoSHARK[63]计算的克隆度量。?基于PMD静态分析工具[64]产生的警告的度量。?使用coastSHARK[63]计算的AST节点计数。?过去六个月内不同类型的更改[65]和重构[66]的数量，分别使用changeSHARK和refSHARK[63]收集。Moser等人[67]、Hassan[68]和D'Ambros等人[31]提出的代码流失度量。,,为了提取与软件实体对应的概念向量，使用了无监督学习模型Doc2Vec和LSI。Doc2Vec[75]和LSI[76]，也被称为潜在语义分析(LSA)，都是旨在将可变长度的文本表示为捕获语义特征的固定长度数字向量的模型，但Doc2Vec是使用反向传播和随机梯度下降训练的基于预测的模型，而LSI是基于统计的计数模型。,,选择了Apache Calcite，一个开源动态数据管理框架[61]。软件的16个考虑版本是:1.0.0、1.1.0、1.2.9、1.3.0、1.4.0、1.5.0、1.6.0、1.7.0、1.8.0、1.9.0、1.10.0、1.11.0、1.12.0、1.13.0、1.14.0和1.15.0。,1075-1352个样本,公开,完成,JAVA,我们决定使用的深度学习分类器，用DL-FASTAI表示，是在FastAI机器学习库中实现的[78]。它由人工神经网络结合输入层的嵌入组成。该架构由1个输入，1个输出和2-4个隐藏层组成，具体取决于特征的数量。,模块级,故障倾向,Accuracy，Precision for the positive class，Precision for the negative class，Sensitivity，Area under the ROC curve (AUC)，Area under the Precision-Recall curve (AUPRC).，Matthews Correlation Coefficient (MCC)，F-score for the ‘‘+’’ class (F-score+，F-score for the ‘‘-’’ class，Overall F-score，Weighted F-score,
"Thirumoorthy, Karpagalingam; Britto J, Jerold John",A feature selection model for software defect prediction using binary Rao optimization algorithm,APPLIED SOFT COMPUTING,10.1016/j.asoc.2022.109737,2022,"In this digital world, using software has become an important part of daily life and business. The software must be rigorously tested in order to avert a financial crisis. The defect-free software enhances the functionality of the business. Predicting software defects in advance is a crucial task in the software industry. The aim of Software Defect Prediction (SDP) is to locate the possible software bugs. This paper proposes a hybrid feature selection (filter-wrapper) approach based on the multicriteria decision making (MCDM) method and the Rao optimization method for selecting the more informative features to improve the software defect prediction rate. The proposed work measures the fitness of the candidate solution by using the defect prediction rate and the feature selection ratio. The performance of the proposed method is evaluated using three popular benchmark NASA datasets (PC5, JM1, and KC1) and compared with the state-of-the-art methods. The proposed feature subset selection scheme identifies the most significant feature subset for defect prediction with an average accuracy of 95% on the benchmark datasets. According to the experimental results, the proposed hybrid approach outperforms the standard strategy in terms of defect prediction rate. (c) 2022 Elsevier B.V. All rights reserved.",3,本文提出了一种基于多准则决策(MCDM)方法和Rao优化方法的混合特征选择(filter-wrapper)方法，用于选择信息更丰富的特征，以提高软件缺陷预测率。0,在这个数字世界中，使用软件已经成为日常生活和商业的重要组成部分。为了避免金融危机，这些软件必须经过严格的测试。无缺陷的软件增强了业务的功能。在软件行业中，提前预测软件缺陷是一项至关重要的任务。软件缺陷预测(SDP)的目的是定位可能存在的软件缺陷。,本文提出了一种基于多准则决策(MCDM)方法和Rao优化方法的混合特征选择(filter-wrapper)方法，用于选择信息更丰富的特征，以提高软件缺陷预测率。提出的工作通过使用缺陷预测率和特征选择比来度量候选方案的适应度。使用三个流行的NASA基准数据集(PC5、JM1和KC1)对所提出方法的性能进行了评估，并与最先进的方法进行了比较。,提出的特征子集选择方案在基准数据集上识别最重要的缺陷预测特征子集，平均准确率为95%。实验结果表明，该混合方法在缺陷预测率方面优于标准策略。,Filter method:基于Filter的方法[6]将Information Gain、Gini index等评分方法应用于所有的feature。它计算每个特征的显著性得分。最后，它使用显著性排名来选择评价最高的特征。?包装器方法:基于包装器的策略的主要目标是选择特征的最佳子集[7]。基于包装器的方法依赖于特定的监督学习算法。,版本内,21个度量,"在初步筛选中，采用了五种著名的过滤方法:互信息(MI)、信息增益(IG)、救济(Relief)、卡方(CHI)和增益比(GR)。每种过滤方法为每个特征分配一个显著的分数。我们使用TOPSIS(H. Ching-Lai, Y. Kwangsun, Methods for multiple attribute decision making, 1981, pp. 58C191, http://dx.doi.org/10.1007/978-3-642-48318-9_3.)计算基于五种过滤方法得分(标准)的最终显著得分。
基于混合Rao优化的包装器方法将进一步检查组合的特征。R. Venkata Rao, Rao algorithms: Three metaphor-less simple algorithms for solving optimization problems, Int. J. Ind. Eng. Comput. (2020) 107C130, http://dx.doi.org/10.5267/j.ijiec.2019.6.002.",,"LOC (m1), cyclomatic complexity (m2), essential complexity (m3), design complexity (m4), difficulty (m8), and effort measures (m10) are significant metrics for software defect prediction.
可以注意到，所提出的特征选择方法获得了较小的特征选择比率。结果表明了所提出的特征选择方法的优越性。",NASA基准数据集(PC5、JM1和KC1),2109-17000个样本,公开,完成,未知,"SVM,NB",模块级,故障倾向,"accuracy(success rate), macro averaged precision(P), macro averaged recall(R), and macro averaged F-Score(F1).",
"Uddin, Md Nasir; Li, Bixin; Ali, Zafar; Kefalas, Pavlos; Khan, Inayat; Zada, Islam",Software defect prediction employing BiLSTM and BERT-based semantic feature,SOFT COMPUTING,10.1007/s00500-022-06830-5,2022,"Recent years, software defect prediction systems are becoming quite popular since they improve software reliability by identifying the potential bugs in the code. Several models were introduced in literature that aim to support the developers. Unfortunately, these models consider the manually constructed code features and input into machine learning-based classifiers. Moreover, these baseline approaches ignore the semantic and contextual information of the source code. With this paper we present a software defect prediction model that address all these issues. The model employs bidirectional long-short term memory network (BiLSTM) and BERT-based semantic feature (SDP-BB) that captures the semantic features of code to predict defects in the corresponding software. In particular, it utilizes the BiLSTM to exploit contextual information from the embedded token vectors learned through BERT model. Moreover, it utilizes an attention mechanism to capture salient features of the nodes. This is done through a data augmentation technique for generating more training data. We evaluated our approach against state-of-the-art models using ten open-source projects in terms of F1-score in fault prediction. The experiments evaluated the performance of full-token and AST-node data processing methods conducting the length of coverage on each project from 50 to 90% in both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) experiments. The results indicate that the proposed method outperforms competing models.",3,在本文中，我们提出了一个解决所有这些问题的软件缺陷预测模型。该模型采用双向长短期记忆网络(BiLSTM)和基于bert的语义特征(SDP-BB)来捕获代码的语义特征，从而预测相应软件中的缺陷。,近年来，软件缺陷预测系统变得非常流行，因为它们通过识别代码中的潜在错误来提高软件的可靠性。文献中介绍了几个旨在支持开发人员的模型。不幸的是，这些模型考虑了人工构建的代码特征，并将其输入到基于机器学习的分类器中。此外，这些基线方法忽略了源代码的语义和上下文信息。,在本文中，我们提出了一个解决所有这些问题的软件缺陷预测模型。该模型采用双向长短期记忆网络(BiLSTM)和基于bert的语义特征(SDP-BB)来捕获代码的语义特征，从而预测相应软件中的缺陷。特别地，它利用BiLSTM从通过BERT模型学习的嵌入式令牌向量中挖掘上下文信息。此外，它利用注意机制来捕捉节点的显著特征。这是通过生成更多训练数据的数据增强技术完成的。根据故障预测的f1分，我们使用10个开源项目对最先进的模型进行了评估。实验评估了全令牌和ast节点数据处理方法在项目内缺陷预测(WPDP)和跨项目缺陷预测(CPDP)实验中对每个项目的覆盖长度从50%到90%的性能。,结果表明，该方法优于竞争模型。,,项目内/跨项目,,,我们使用BERT (Devlin et al. 2019)(一种高级语言表示模型)预训练大型Java源代码，以确保可以很好地训练令牌以进行软件缺陷预测。然后用Bi-LSTM提取特征,与ast节点相比，全令牌数据处理方法提供了更高的性能，特别是对于广泛的覆盖长度,PROMISE存储库,176-830个文件,公开,完成,JAVA,逻辑回归,文件级,故障倾向,"Precision, Recall, and F1-score,",
"Mohammad, Uzma Ghulam; Imtiaz, Salma; Shakya, Manoj; Almadhor, Ahmad; Anwar, Fareeha",An Optimized Feature Selection Method Using Ensemble Classifiers in Software Defect Prediction for Healthcare Systems,WIRELESS COMMUNICATIONS & MOBILE COMPUTING,10.1155/2022/1028175,2022,"The healthcare systems are extensively being used with increased focus on safety of patients. Software engineering for healthcare applications is an emerging research area. Detecting defects is a critical step of software development process of healthcare applications. The performance of the Software Defect Prediction model (SDP) depends on the features of healthcare system; irrelevant features decrease the performance of the model. An optimized feature selection technique is needed to recognize and remove the irrelevant features. In this study, a new optimized feature selection technique, i.e., multiobjective Harris Hawk Optimization (HHO), is proposed for binary classification problem with Adaptive Synthetic Sampling (ADASYN) Technique. Multiobjective HHO is proposed with two main objectives, one to reduce the total amount of selected features and the other to maximize the performance of the proposed model. The multiobjective feature selection technique helps to find the optimal solution to achieve the desired objectives and increase the classification performance in terms of accuracy, AUC, precision, recall, and F1-measure. The study conducts an experiment on a healthcare dataset. Six different search techniques (RF, SVM, bagging, adaptive boosting, voting, and stacking) are implemented on the dataset. The proposed model helps to predict the software defects with a significant classification accuracy of 0.990 and AUC score of 0.992.",3,提出了一种新的优化特征选择技术，即多目标Harris Hawk优化(HHO)。提出了多目标HHO，主要有两个目标，一个是减少所选特征的总量，另一个是最大化所提模型的性能。多目标特征选择技术有助于找到实现预期目标的最优,医疗保健系统正在广泛使用，越来越关注患者的安全。医疗保健应用程序的软件工程是一个新兴的研究领域。缺陷检测是医疗保健应用软件开发过程中的关键步骤。软件缺陷预测模型(SDP)的性能取决于医疗保健系统的特征;不相关的特征会降低模型的性能。需要一种优化的特征选择技术来识别和去除不相关的特征。,针对自适应合成采样(ADASYN)技术的二分类问题，提出了一种新的优化特征选择技术，即多目标Harris Hawk优化(HHO)。提出了多目标HHO，主要有两个目标，一个是减少所选特征的总量，另一个是最大化所提模型的性能。多目标特征选择技术有助于找到实现预期目标的最优解，并在准确率、AUC、精密度、召回率和F1-measure方面提高分类性能。该研究在一个医疗数据集上进行了一项实验。在数据集上实现了六种不同的搜索技术(RF、SVM、bagging、adaptive boosting、voting和stacking)。,"RF作为基本分类器和Adaboost作为集成分类器在基于AUC的医疗保健软件缺陷预测中表现更好，而RF和堆叠在准确性方面表现优于其他分类器。提出的模型有助于预测软件缺陷，分类精度为0.990,AUC得分为0.992。得到的结果清楚地表明，所提出的模型是最好的医疗保健软件缺陷预测。",,版本内,19个特征,多目标特征选择技术Harris Hawk Optimization有助于找到达到预期目标的最优解，提高分类性能。最近提出了一种以鹰的追逐行为为动机的HHO算法。它被证明是一种有效的元启发式技术，用于识别特征选择等困难的优化问题[46]。HHO算法由[48]提出，具有哈里斯鹰的协作行为和追逐风格，对猎物进行猛扑。,,,医疗保健数据集用于实验(https://www.kaggle.com/datasets/iqrayousaf/ healthcare- datasetfor -defects-prediction)。,109个文件,公开,未知,未知,"RF, SVM as a base classifiers and ensemble classifiers bagging, Adaboost, Voting and Stacking",未知,故障倾向,"precision, recall, and F1-measure",每个分类器具有不同度量是怎么选择出来的
"Vashisht, Rohit; Rizvi, Syed Afzal Murtaza",Feature Engineering to Heterogeneous Cross Software Projects Defect Prediction: A Novel Framework,ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING,10.1007/s13369-022-07337-9,2023,"Heterogeneous cross-project defect prediction (HCPDP) aims to predict defects in a target project with limited historical defect data via a defect prediction (DP) model trained with defect data of another source project. The accuracy of a DP model is highly dependent on the set of features selected in feature engineering (FE) phase. The study evaluates the effectiveness of proposed four-phase HCPDP framework with more focus on FE phase using the stacking-based ensemble learning method. Auto-encoder (AE), a deep learning-based FE technique is used for the proposed analysis. In addition, two novel techniques to deal with imbalance dataset and to determine correlation between features are also proposed in this paper. For comparative analysis, accuracy, recall, F-score and area under curve (AUC) are used as the output parameters. To compare DP model's output with or without FE phase, ten prediction pairs from four open source projects have been considered. The experimental results show that the AE technique is able to reduce the number of features by an average of 50% as compared to data-driven approaches. Also, the proposed model gave better performance in comparison with traditional heterogeneous models with highest AUC of 0.8901.",3,在特征工程(FE)阶段选择的特征集对DP模型的精度有很大的影响。本研究使用基于堆叠的集成学习方法评估了所提出的四阶段HCPDP框架的有效性，重点关注了FE阶段。,异质跨项目缺陷预测(HCPDP)的目的是通过一个缺陷预测(DP)模型，通过另一个源项目的缺陷数据训练，在有限的历史缺陷数据下预测目标项目中的缺陷。在特征工程(FE)阶段选择的特征集对DP模型的精度有很大的影响。,本研究使用基于堆叠的集成学习方法评估了所提出的四阶段HCPDP框架的有效性，重点关注了FE阶段。自动编码器(AE)是一种基于深度学习的有限元分析技术。此外，本文还提出了两种处理不平衡数据集和确定特征间相关性的新技术。为了进行对比分析，输出参数采用准确率、召回率、f分和曲线下面积(AUC)。为了比较有或没有FE阶段的DP模型的输出，我们考虑了来自四个开源项目的十个预测对。,实验结果表明，与数据驱动方法相比，AE技术能够将特征数量平均减少50%。与传统的异构模型相比，该模型具有更好的性能，AUC最高为0.8901。,,版本内/跨项目,总共有61个度量，包括17个源代码度量、5个过去缺陷度量、5种变化熵度量、17种源代码熵度量和17种源码流失度量,,"自动编码器（AE），一种基于深度学习的有限元技术被应用于实现HCPDP-AE模型的第二阶段。AE技术的使用原理是提取一个低维的特征集，该特征集可以使用编码-解码模型再现原始输入。使用这种技术的目的是一种无监督的学习技术；
为了解决传统度量匹配方法的这一缺点，本文提出了一种新的度量匹配方法，即基于块的度量匹配技术(CBMMT)，将这一异构预测系统中最关键和最热门的部分结合起来。CBMMT本质上也是随机的，它检查每个实例块的度量匹配，并选择显示CCV大于阈值的强相关特征对的最大数量的块进行DP模型的训练。这样，HCPDP-AE最重要的一步就可以通过CBMMT有效实施",,该研究使用了来自四个开源存储库的16个公开可用和广泛使用的数据集，包括AEEEM、ReLink、SOFTLAB和NASA，,36-1800个样本,公开,完成,JAVA等,"采用线性径向基函数核(RBFK)支持向量机(SVM)对WPDP模型进行训练。,
CPDP:使用基于堆叠的集成学习（SBEL）对模型进行训练，其中两个基本模型使用K近邻（KNN）和随机森林（RF）进行训练，一个元模型使用逻辑回归（LR）进行训练。",文件级,故障倾向,Accuracy Recall AUC F-Score,
"Elmishali, Amir; Kalech, Meir",Issues-Driven features for software fault prediction,INFORMATION AND SOFTWARE TECHNOLOGY,10.1016/j.infsof.2022.107102,2023,"Context: Software systems are an integral part of almost every modern industry. Unfortunately, the more complex the software, the more likely it will fail. A promising strategy is applying fault prediction models to predict which components may be defective. Since features are essential to the prediction model's success, extracting significant features can improve the model's accuracy. Previous research studies used software metrics as features in fault prediction models. One disadvantage of these features is that they measure the code developed rather than the requirements. On the other hand, faults are frequently the result of a mismatch between the software's behavior and its needs. Objective: We present a novel paradigm for constructing features that consider the requirements as well by combining novel requirement metrics, called Issues-Driven features, and traditional code metrics. Method: We experimentally compare the performance of Issues-Driven features and state-of-the-art traditional features on 86 open-source projects from two organizations. Results: The results show that Issues-Driven features are significantly better than state-of-the-art features and achieve an improvement of 6 to 13 percent in terms of AUC. Conclusions: The study concludes that integrating the requirements into fault prediction features overcomes the limitations of traditional software metrics that are agnostic to the requirements of the software.",3,我们通过结合新的需求度量(称为问题驱动的特性)和传统的代码度量，为构造考虑需求的特性提供了一个新的范例,如今，软件系统是任何现代工业的重要组成部分。不幸的是，软件越复杂，失败的可能性就越大。一个很有前途的策略是使用故障预测模型来预测哪些组件可能出现故障。特征是预测成功的关键因素，提取重要特征可以提高模型的准确性。在文献中，软件度量被用作特征来构建故障预测模型。当软件的行为与要求不同时，就会出现故障。然而，软件度量被设计用来度量开发的代码，而不是它满足的需求。,在本文中，我们提出了一种新的范例来构建结合了软件度量和需求细节的特性，我们称之为问题驱动特性。,结果表明，问题驱动的特征在这两个类别中都明显优于传统特征，并且在AUC方面实现了6%到13%的改进。,"产品特性――产品度量是使用最终开发的软件产品的各种特性来计算的。这些指标通常用于检查软件产品是否确认某些规范或代码约定。从广义上讲，产品度量可以分为传统度量、面向对象度量和动态度量。-传统特性-这些特性是在软件工程出现的最初几天设计的，被称为传统指标。它们主要包括大小和复杂性度量，例如代码行数和函数数。-面向对象特性-这些特性是专门为面向对象程序设计的软件复杂性度量。它们包括诸如内聚和耦合级别以及继承深度之类的度量。―动态特性―动态度量是指依赖于从程序执行中收集的特性的一组度量。这些度量揭示了软件组件在执行期间的行为，并用于度量程序、组件和系统的特定运行时属性。与从静态非执行模型中计算出的静态度量相反，动态度量用于识别在运行时耦合程度最高和/或最复杂的对象。这些度量为设计的质量提供了不同的指示。
过程特性――过程特性指的是一组依赖于软件开发生命周期中收集的特性的度量标准。例如，组件被修改的次数，从最后一次修改经过的时间，等等。与产品度量相反，过程特性被设计用来度量开发过程的质量，而不是最终产品的质量。它们有助于提供一组导致长期软件过程改进的过程度量。",跨版本,"Chidamber and Kemerer metrics suite [6] (CK), 2. Halstead complexity metrics [8] (HALSTEAD),
Lorenz and Kidd OO features [9] (LK), 4. MOOD features [7] (MOOD).
17 process features : 1. code delta and change metrics (such as number of changes and type of changes) [10], 2. Time difference between commits [11; 12] 3. developer based features [11; 13].",我们建议将问题和代码属性结合起来，作为它们所处理的问题属性的函数来计算代码度量。我们称这些新特性为“问题驱动特性”。一个问题可以用它来表示:(1)类型(bug修复、改进或新特性)，(2)优先级(主要、次要、次要)，以及(3)严重性(阻塞、正常、增强)。,,我们评估了Rathure等人[4]中列出的过程特性集，如代码增量、代码流失和变更度量。我们将使用这些特征训练的模型的结果与使用这些特征的问题驱动变体训练的模型的结果进行比较。所有度量的结果表明，问题驱动的特征优于文献中使用的过程特征。此外，86%(86个项目中的74个)的项目中，问题驱动的特性比其他特性表现得更好。结果的显著性水平为p < 0.01。,我们评估了来自开源组织的86个用Java编写的项目，这些项目使用Git版本控制系统和问题跟踪系统(JIRA或BUGZILLA)来管理它们的源代码。,未知,公开,完成,JAVA,随机森林,文件级,故障倾向,"precision, recall and the area under the ROC curve (AUC)",
"Anju, A. J.; Judith, J. E.",Adaptive recurrent neural network for software defect prediction with the aid of quantum theory- particle swarm optimization,MULTIMEDIA TOOLS AND APPLICATIONS,10.1007/s11042-022-14065-7,2023,"With the proliferation of software programs, predicting defects has become a big concern. Therefore, to overcome this challenge, this research introduces a new Optimized Deep Learning model. The software defect is predicted using the new Adaptive Recurrent Neural network (ARNN), wherein the hyper-parameters (weight) function is fine-tuned using the new Levy-Flight Integrated Cuckoo Search Optimization (LICSO) model to accurately predict the defects. First, the data is pre-processed via box-cox transformation. The outcomes of the pre-processed data are then subjected to a Feature Selection technique, wherein the relevant features are selected using the new Quantum Theory-Particle Swarm Optimization (QPSO-FS). Finally, ARNN is utilized to predict the software defects. To validate the performance of the proposed approach evaluation metrics are considered such as detection Accuracy, Precision, Recognition error, Sensitivity, Specificity, F1-Score, and Processing time are evaluated and tested. As per the acquired results, the projected model outperforms the existing models. The projected model has recorded the highest accuracy level as 96.48%.",3,本研究引入了一种新的优化深度学习模型。使用新的自适应递归神经网络(ARNN)预测软件缺陷，其中超参数(权重)函数使用新的Levy-Flight集成布谷鸟搜索优化(LICSO)模型进行微调，以准确预测缺陷，其中使用新的量子理论-粒子群优化(QPSO-FS)选择相关特征。,随着软件程序的激增，预测缺陷已经成为一个大问题。,因此，为了克服这一挑战，本研究引入了一种新的优化深度学习模型。使用新的自适应递归神经网络(ARNN)预测软件缺陷，其中超参数(权重)函数使用新的Levy-Flight集成布谷鸟搜索优化(LICSO)模型进行微调，以准确预测缺陷。首先，通过box-cox变换对数据进行预处理。然后将预处理数据的结果进行特征选择技术，其中使用新的量子理论-粒子群优化(QPSO-FS)选择相关特征。最后，利用人工神经网络对软件缺陷进行预测。为了验证所提出的方法的性能，评估指标被考虑，如检测准确性，精度，识别误差，灵敏度，特异性，F1-Score和处理时间进行评估和测试。,所得结果表明，预测模型优于现有模型。预测模型的准确率最高，达到96.48%。,,版本内,"22 (5 different lines of code measure, % 3 McCabe metrics, 4 base Halstead measures, 8 derived % Halstead measures, a branch-count, and 1 goal field)",量子理论粒子群优化(QPSO-FS)Quantum Theory-Particle Swarm Opti+Y149mization (QPSO-FS).,,,"即JM1数据集：Kaggle数据集(https://www.kaggle)。com/ semustafacevik/softw-defects -prediction?select=about+JM1+Dataset.txt)用于此分析，其中包括10,885个实例和22个属性。",10855个实例,公开,完成,C,"deep ARNN classifier-RNN的改进
本研究使用cuckoo搜索优化技术和levy飞行模型来优化ARNN框架中的权重值。这反过来又实现了识别软件缺陷的准确预测模型。",方法级,故障倾向,"Accuracy, Precision, F1-Score, Specificity, Sensitivity, Processing Time, and Error",
"Guo, Shikai; Wang, Jiahui; Xu, Zhihao; Huang, Lin; Li, Hui; Chen, Rong",Feature transfer learning by reinforcement learning for detecting software defect,SOFTWARE-PRACTICE & EXPERIENCE,10.1002/spe.3152,2023,"Software defects, produced inevitably in software projects, seriously affect the efficiency of software testing and maintenance. An appealing solution is the software defect prediction (SDP) that has achieved good performance in many software projects. However, the difference between features and the difference of the same feature between training data and test data may degrade defect prediction performance if such differences violate the model's assumption. To address this issue, we propose a SDP method based on feature transfer learning (FTL), which performs a transformation sequence for each feature in order to map the original features to another feature space. Specifically, FTL first uses the reinforcement learning scheme that automatically learns a strategy for transferring the potential feature knowledge from the training data. Then, we use the learned feature knowledge to inspire the transformation of the test data. The classifier is trained by the transformed training data and predicts defects for transformed test data. We evaluate the validity of FTL on 43 projects from PROMISE and NASA MDP using three classifiers, logistic regression, random forest, and Naive Bayes (NB). Experimental results indicate that FTL is better than the original classifiers and has the best performance on the NB classifier. For PROMISE, after using FTL, the average results of F1-score, AUC, MCC are 0.601, 0.757, and 0.350 respectively, which are 24.9%, 2.6%, and 16.7% higher than the original NB classifier results. The number of projects with improved performance accounts for 83.87%, 83.87%, and 64.52%. Similarly, FTL performs well on NASA MDP. Besides, compared with four feature engineering (FE) methods, FTL achieves an excellent improvement on most projects and the average performance is also better than or close to the FE methods.",3,我们提出了一种基于特征迁移学习(FTL)的SDP方法，该方法对每个特征执行一个转换序列，以便将原始特征映射到另一个特征空间。具体来说，FTL首先使用强化学习方案，该方案自动学习从训练数据中转移潜在特征知识的策略。然后，我们使用学习到的特征知识来启发测试数据的转换。,软件缺陷是软件项目中不可避免的产生，严重影响了软件测试和维护的效率。一个吸引人的解决方案是软件缺陷预测(SDP)，它在许多软件项目中取得了很好的效果。然而，如果特征之间的差异以及训练数据与测试数据之间相同特征的差异违反了模型的假设，则可能会降低缺陷预测的性能。,为了解决这个问题，我们提出了一种基于特征迁移学习(FTL)的SDP方法，该方法对每个特征执行一个转换序列，以便将原始特征映射到另一个特征空间。具体来说，FTL首先使用强化学习方案，该方案自动学习从训练数据中转移潜在特征知识的策略。然后，我们使用学习到的特征知识来启发测试数据的转换。分类器通过转换后的训练数据进行训练，并对转换后的测试数据进行缺陷预测。我们使用逻辑回归、随机森林和朴素贝叶斯(NB)三种分类器对来自PROMISE和NASA MDP的43个项目的FTL有效性进行了评估。,实验结果表明，FTL分类器优于原始分类器，在NB分类器上具有最佳性能。对于PROMISE，使用FTL后，F1-score、AUC、MCC的平均结果分别为0.601、0.757、0.350，比原始NB分类器结果分别提高了24.9%、2.6%、16.7%。业绩改善的项目数量分别为83.87%、83.87%和64.52%。同样，FTL在NASA MDP上表现良好。此外，与四种特征工程(FE)方法相比，FTL在大多数项目上都取得了很好的改进，平均性能也优于或接近FE方法。,,版本内,每个实例都有一个干净或有缺陷的标签和不同数量的特征，从21到39。,,"我们提出了一种新的基于特征迁移学习(FTL)的SDP方法。FTL方法对每个特征执行动作转换序列。所有的特征被映射到一个新的空间，使得缺陷实例和干净实例之间的距离更大，两类的内部分布更密集。
基于强化学习，从训练数据中学习潜在特征知识，获得自动特征知识转移策略。学习到的特征变换序列可以在数据分布方面启发测试数据的传递，有助于解决异构特征问题，提高缺陷预测性能。然后，使用转换后的训练数据训练分类器，并对转换后的测试数据进行缺陷预测。",对于所有项目的平均性能，FTL高于或接近基线，FTL在项目数量上具有绝对优势。可见，FTL是一种更稳定、应用更广泛的方法，可以有效地提高缺陷预测性能。,PROMISE和NASA MDP数据存储库。,100-10000个类,公开,完成,JAVA等,"强化学习(RL)+分类器包括LR,16随机森林(RF)28和朴素贝叶斯(NB)29方法。",类级,故障倾向,F1-score; (2) area under curve (AUC); (3) Matthews correlation coefficient (MCC).,
